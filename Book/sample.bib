@INPROCEEDINGS{Adalgeirsson2010,
  author = {Adalgeirsson, Sigurdur O and Breazeal, Cynthia},
  title = {{MeBot}: a robotic platform for socially embodied presence},
  booktitle = {Proceedings of the 5th {ACM/IEEE} international conference on Human-robot
	interaction},
  year = {2010},
  series = {HRI '10},
  pages = {15--22},
  month = {\#mar\#},
  publisher = {IEEE Press},
  institution = {IEEE Press},
  keywords = {embodied videoconferencing, robot-mediated communication, telepresence,
	human robot interaction;litsurvey.bib},
  location = {Osaka, Japan}
}

@INPROCEEDINGS{Adamczyk2007,
  author = {Adamczyk, Piotr D and Twidale, Michael B},
  title = {Supporting multidisciplinary collaboration: requirements from novel
	{HCI} education},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {1073--1076},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {low fidelity prototyping, design tools, social bookmarking, design
	education, multidisciplinary collaboration;litsurvey.bib},
  location = {San Jose, California, USA}
}

@ARTICLE{aiken2020zooming,
  author = {Aiken, Adam},
  title = {Zooming in on privacy concerns: Video app Zoom is surging in popularity.
	In our rush to stay connected, we need to make security checks and
	not reveal more than we think},
  journal = {Index on Censorship},
  year = {2020},
  volume = {49},
  pages = {24--27},
  number = {2},
  publisher = {SAGE Publications Sage UK: London, England}
}

@INPROCEEDINGS{Al_Moubayed2012,
  author = {Al Moubayed, Samer and Edlund, Jens and Beskow, Jonas},
  title = {Taming Mona Lisa: Communicating Gaze Faithfully In 2d And 3d Facial
	Projections},
  year = {2012},
  volume = {1},
  pages = {25},
  keywords = {litsurvey.bib}
}

@ARTICLE{Al-Hazaimeh2019,
  author = {Al-Hazaimeh, Obaida M and Al-Nawashi, Malek and Saraee, Mohamad},
  title = {Geometrical-based approach for robust human image detection},
  journal = {Multimedia Tools and Applications},
  year = {2019},
  volume = {78},
  pages = {7029--7053},
  number = {6},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Al-Hazaimeh2019_Article_Geometrical-basedApproachForRo.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{Al-Saidi2009,
  author = {Al-Saidi, A and Avis, N J and Grimstead, I J and Rana, O F},
  title = {Distributed Collaborative Visualization Using Light Field Rendering},
  booktitle = {2009 9th {IEEE/ACM} International Symposium on Cluster Computing
	and the Grid},
  year = {2009},
  pages = {609--614},
  month = {\#may\#},
  abstract = {Interactive distributed visualization is an emerging technology with
	numerous applications. However, many of the present approaches of
	interactive distributed visualization are based on the traditional
	polygonal processing graphics pipeline. Our research is centred on
	investigating an alternative method using image-based rendering (IBR)
	which uses (multiple) images of the scene instead of a 3D geometrical
	representation. A key advantage to the use of IBR techniques is that
	the bandwidth required is independent of scene complexity and is
	therefore predictable given knowledge of the desired final image
	resolution. In this paper, we describe our IBR based interactive
	distributed visualization platform involving light field rendering
	and present results which indicate the scalability of our approach
	to accommodate multiple collaborative users. To our knowledge this
	is the first system to demonstrate deployment of interactive light
	field rendering to large numbers of distributed users.},
  institution = {IEEE},
  keywords = {computational geometry;data visualisation;groupware;image representation;image
	resolution;interactive systems;rendering (computer graphics);distributed
	collaborative visualization;light field rendering;interactive distributed
	visualization;polygonal processing graphics pipeline;image-based
	rendering;3D geometrical representation;scene complexity;image resolution;Collaboration;Visualization;Rendering
	(computer graphics);Layout;Geometry;Distributed computing;Application
	software;Pipelines;Bandwidth;Image resolution;Visualization;Distributed
	Collaborative Environment;Distributed Systems;Client/Server;Distributed
	Applications.;litsurvey.bib}
}

@INPROCEEDINGS{Allard2006,
  author = {Allard, J and Franco, J and Menier, C and Boyer, E and Raffin, B},
  title = {The {GrImage} Platform: A Mixed Reality Environment for Interactions},
  booktitle = {Fourth {IEEE} International Conference on Computer Vision Systems
	({ICVS'06})},
  year = {2006},
  pages = {46--46},
  month = {\#jan\#},
  abstract = {In this paper, we present a scalable architecture to compute, visualize
	and interact with 3D dynamic models of real scenes. This architecture
	is designed for mixed reality applications requiring such dynamic
	models, tele-immersion for instance. Our system consists in 3 main
	parts: the acquisition, based on standard firewire cameras; the computation,
	based on a distribution scheme over a cluster of PC and using a recent
	shape-from-silhouette algorithm which leads to optimally precise
	3D models; the visualization, which is achieved on a multiple display
	wall. The proposed distribution scheme ensures scalability of the
	system and hereby allows control over the number of cameras used
	for acquisition, the frame-rate, or the number of projectors used
	for high resolution visualization. To our knowledge this is the first
	completely scalable vision architecture for real time 3D modeling,
	from acquisition to visualization through computation. Experimental
	results show that this framework is very promising for real time
	3D interactions.},
  institution = {IEEE},
  keywords = {Virtual reality;Visualization;Computer architecture;Firewire;Cameras;Layout;Computer
	displays;Distributed computing;Clustering algorithms;Three dimensional
	displays;litsurvey.bib}
}

@Article{bastian2021hedging,
  author    = {Bastian-Pinto, Carlos L and Araujo, Felipe V de S and Brand{\~a}o, Luiz E and Gomes, Leonardo L},
  journal   = {Renewable and Sustainable Energy Reviews},
  title     = {Hedging renewable energy investments with Bitcoin mining},
  year      = {2021},
  pages     = {110520},
  volume    = {138},
  publisher = {Elsevier},
}

@ARTICLE{Allen_Joseph2014,
  author = {Allen Joseph, A and Beck, Tammy and Scott Cliff, W and Rogelberg
	Steven, G},
  title = {Understanding workplace meetings: A qualitative taxonomy of meeting
	purposes},
  journal = {Management Research Review},
  year = {2014},
  volume = {37},
  pages = {791--814},
  number = {9},
  month = {\#jan\#},
  abstract = {Purpose-- The purpose of this study is to propose a taxonomy of meeting
	purpose. Meetings are a workplace activity that deserves increased
	attention from researchers and practitioners. Previous researchers
	attempted to develop typologies of meeting purpose with limited success.
	Through a comparison of classification methodologies, the authors
	consider a taxonomy as the appropriate classification scheme for
	meeting purpose. The authors then utilize the developed taxonomy
	to investigate the frequency with which a representative sample of
	working adults engaged in meetings of these varying purposes. Their
	proposed taxonomy provides relevant classifications for future research
	on meetings as well and serves as a useful tool for managers seeking
	to use and evaluate the effectiveness of meetings within their organizations.
	Design/methodology/approach-- This study employs an inductive methodology
	using discourse analysis of qualitative meeting descriptions to develop
	a taxonomy of meeting purpose. The authors discourse analysis utilizes
	open-ended survey responses from a sample of working adults (n =
	491). Findings-- The authors categorical analysis of open-ended questions
	resulted in a 16-category taxonomy of meeting purpose. The two most
	prevalent meeting purpose categories in this sample were ``to discuss
	ongoing projects'' at 11.6 per cent and ``to routinely discuss the
	state of the business'' at 10.8 per cent. The two least common meeting
	purpose categories in this sample were ``to brainstorm for ideas
	or solutions'' at 3.3 per cent and ``to discuss productivity and
	efficiencies'' at 3.7 per cent. The taxonomy was analyzed across
	organizational type and employee job level to identify differences
	between those important organizational and employee characteristics.
	Research limitations/implications-- The data suggested that meetings
	were institutionalized in organizations, making them useful at identifying
	differences between organizations as well as differences in employees
	in terms of scope of responsibility. Researchers and managers should
	consider the purposes for which they call meetings and how that manifests
	their overarching organizational focus, structure and goals. Originality/value--
	This is the first study to overtly attempt to categorize the various
	purposes for which meetings are held. Further, this study develops
	a taxonomy of meeting purposes that will prove useful for investigating
	the different types of meeting purposes in a broad range of organizational
	types and structures.},
  keywords = {litsurvey.bib},
  publisher = {Emerald Group Publishing Limited}
}

@ARTICLE{Alspaugh2018,
  author = {Alspaugh, Sara and Zokaei, Nava and Liu, Andrea and Jin, Cindy and
	Hearst, Marti A},
  title = {Futzing and moseying: Interviews with professional data analysts
	on exploration practices},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {22--31},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440815.pdf:PDF},
  publisher = {IEEE}
}

@BOOK{ammous2018bitcoin,
  title = {The bitcoin standard: the decentralized alternative to central banking},
  publisher = {John Wiley \& Sons},
  year = {2018},
  author = {Ammous, Saifedean},
  file = {:../../../literature_repository/bitcoin/The Bitcoin Standard.pdf:PDF}
}

@ARTICLE{oxford2021salvador,
  author = {Oxford Analytica},
  title = {El Salvador bitcoin experiment comes with risks},
  journal = {Emerald Expert Briefings},
  year = {2021},
  number = {oxan-db},
  publisher = {Oxford Analytica}
}

@INPROCEEDINGS{Andersen2019,
  author = {Andersen, Benjamin JH and Davis, Arran TA and Weber, Gerald and W{\"u}nsche,
	Burkhard C},
  title = {Immersion or Diversion: Does Virtual Reality Make Data Visualisation
	More Effective?},
  booktitle = {2019 International Conference on Electronics, Information, and Communication
	(ICEIC)},
  year = {2019},
  pages = {1--7},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08706403.pdf:PDF}
}

@INPROCEEDINGS{Anstis1969,
  author = {Anstis, Stuart M and Mayhew, John W and Morley, Tania},
  title = {The Perception of Where a Face or Television Portrait is Looking},
  year = {1969},
  volume = {82},
  pages = {474--489},
  publisher = {JSTOR},
  keywords = {litsurvey.bib}
}

@PHDTHESIS{Antley2014-en,
  author = {Antley, Angus},
  title = {Human Balance Behaviour in Immersive Virtual Environments},
  school = {UCL (University College London)},
  year = {2014},
  keywords = {litsurvey.bib}
}

@BOOK{antonopoulos2017mastering,
  title = {Mastering Bitcoin: Programming the open blockchain},
  publisher = {" O'Reilly Media, Inc."},
  year = {2017},
  author = {Antonopoulos, Andreas M},
  file = {:../../../literature_repository/bitcoin/Mastering-bitcoin-2nd.pdf:PDF}
}

@INPROCEEDINGS{Aoki2003,
  author = {Aoki, Paul M and Romaine, Matthew and Szymanski, Margaret H and Thornton,
	James D and Wilson, Daniel and Woodruff, Allison},
  title = {The mad hatter's cocktail party: a social mobile audio space supporting
	multiple simultaneous conversations},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2003},
  series = {CHI '03},
  pages = {425--432},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {floor management, audio space, conversation analysis;litsurvey.bib},
  location = {Ft. Lauderdale, Florida, USA}
}

@BOOK{Argyle1988,
  title = {Bodily communication},
  publisher = {Methuen},
  year = {1988},
  author = {Argyle, Michael},
  keywords = {litsurvey.bib}
}

@Book{Argyle1976,
  author    = {Argyle, Michael and Cook, Mark},
  publisher = {Cambridge University Press},
  title     = {Gaze and Mutual Gaze},
  year      = {1976},
  month     = {\#jan\#},
  keywords  = {litsurvey.bib},
  language  = {en},
}

@INPROCEEDINGS{Argyle1965,
  author = {Argyle, Michael and Dean, Janet},
  title = {Eye-contact, Distance And Affiliation},
  year = {1965},
  pages = {289--304},
  publisher = {JSTOR},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Argyle1976,
  author = {Argyle, Michael and Graham, Jean Ann},
  title = {The Central Europe Experiment: Looking at Persons and Looking at
	Objects},
  year = {1976},
  volume = {1},
  pages = {6--16},
  keywords = {litsurvey.bib},
  language = {en}
}

@BOOK{Argyle1969,
  title = {Gaze, Mutual Gaze, and Proximity},
  year = {1969},
  author = {Argyle, Michael and Ingham, Roger},
  keywords = {litsurvey.bib}
}

@ARTICLE{Arvey2009,
  author = {Arvey, Richard D},
  title = {Why face-to-face business meetings matter},
  journal = {White Paper for the Hilton Group},
  year = {2009},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Atzpadin2004,
  author = {Atzpadin, Nicole and Kauff, Peter and Schreer, Oliver},
  title = {Stereo Analysis By Hybrid Recursive Matching For Real-time Immersive
	Video Conferencing},
  year = {2004},
  volume = {14},
  pages = {321--334},
  publisher = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Avrahami2007,
  author = {Avrahami, Daniel and Fogarty, James and Hudson, Scott E},
  title = {Biases in human estimation of interruptibility: effects and implications
	for practice},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {50--60},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {interruptibility, ubiquitous computing, availability, awareness, computer
	mediated communication, context aware computing;litsurvey.bib},
  location = {San Jose, California, USA}
}

@ARTICLE{Axon2019,
  author = {Axon, Louise and Happa, Jassim and Goldsmith, Michael and Creese,
	Sadie},
  title = {Hearing attacks in network data: An effectiveness study},
  journal = {Computers \& Security},
  year = {2019},
  volume = {83},
  pages = {367--388},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0167404818303377-main.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Back2014,
  author = {Back, Adam and Corallo, Matt and Dashjr, Luke and Friedenbach, Mark
	and Maxwell, Gregory and Miller, Andrew and Poelstra, Andrew and
	Tim{\'o}n, Jorge and Wuille, Pieter},
  title = {Enabling blockchain innovations with pegged sidechains},
  journal = {URL: http://www. opensciencereview. com/papers/123/enablingblockchain-innovations-with-pegged-sidechains},
  year = {2014},
  volume = {72},
  file = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\bitcoin\\sidechains.pdf:PDF}
}

@ARTICLE{back2002hashcash,
  author = {Back, Adam and others},
  title = {Hashcash-a denial of service counter-measure},
  year = {2002}
}

@InProceedings{Bailenson2002,
  author   = {Bailenson, Jeremy N and Beall, Andrew C and Blascovich, Jim},
  title    = {Gaze And Task Performance In Shared Virtual Environments},
  year     = {2002},
  pages    = {313--320},
  volume   = {13},
  keywords = {copresence, mutual gaze, organizational behaviour, presence, video conferencing;litsurvey.bib},
}

@ARTICLE{Bailenson2003,
  author = {Bailenson, Jeremy N and Blascovich, Jim and Beall, Andrew C and Loomis,
	Jack M},
  title = {Interpersonal distance in immersive virtual environments},
  journal = {Pers. Soc. Psychol. Bull.},
  year = {2003},
  volume = {29},
  pages = {819--833},
  number = {7},
  month = {\#jul\#},
  abstract = {Digital immersive virtual environment technology (IVET) enables behavioral
	scientists to conduct ecologically realistic experiments with near-perfect
	experimental control. The authors employed IVET to study the interpersonal
	distance maintained between participants and virtual humans. In Study
	1, participants traversed a three-dimensional virtual room in which
	a virtual human stood. In Study 2, a virtual human approached participants.
	In both studies, participant gender, virtual human gender, virtual
	human gaze behavior, and whether virtual humans were allegedly controlled
	by humans (i.e., avatars) or computers (i.e., agents) were varied.
	Results indicated that participants maintained greater distance from
	virtual humans when approaching their fronts compared to their backs.
	In addition, participants gave more personal space to virtual agents
	who engaged them in mutual gaze. Moreover, when virtual humans invaded
	their personal space, participants moved farthest from virtual human
	agents. The advantages and disadvantages of IVET for the study of
	human behavior are discussed.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Sage Publications}
}

@INPROCEEDINGS{Bailenson2003,
  author = {Bailenson, Jeremy N and Blascovich, Jim and Beall, Andrew C and Loomis,
	Jack M},
  title = {Interpersonal Distance In Immersive Virtual Environments},
  year = {2003},
  volume = {29},
  pages = {819--833},
  publisher = {Sage Publications},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Bailenson2001,
  author = {Bailenson, Jeremy N and Blascovich, Jim and Beall, Andrew C and Loomis,
	Jack M},
  title = {Equilibrium theory revisited: Mutual gaze and personal space in virtual
	environments},
  year = {2001},
  volume = {10},
  pages = {583--598},
  publisher = {MIT Press},
  keywords = {litsurvey.bib}
}

@ARTICLE{Bailenson2006,
  author = {Bailenson, Jeremy N and Yee, Nick and Merget, Dan and Schroeder,
	Ralph},
  title = {The Effect of Behavioral Realism and Form Realism of {Real-Time}
	Avatar Faces on Verbal Disclosure, Nonverbal Disclosure, Emotion
	Recognition, and Copresence in Dyadic Interaction},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2006},
  volume = {15},
  pages = {359--372},
  number = {4},
  month = {\#aug\#},
  abstract = {Abstract The realism of avatars in terms of behavior and form is critical
	to the development of collaborative virtual environments. In the
	study we utilized state of the art, real-time face tracking technology
	to track and render facial expressions unobtrusively in a desktop
	CVE. Participants in dyads interacted with each other via either
	a video-conference (high behavioral realism and high form realism),
	voice only (low behavioral realism and low form realism), or an ?emotibox?
	that rendered the dimensions of facial expressions abstractly in
	terms of color, shape, and orientation on a rectangular polygon (high
	behavioral realism and low form realism). Verbal and non-verbal self-disclosure
	were lowest in the videoconference condition while self-reported
	copresence and success of transmission and identification of emotions
	were lowest in the emotibox condition. Previous work demonstrates
	that avatar realism increases copresence while decreasing self-disclosure.
	We discuss the possibility of a hybrid realism solution that maintains
	high copresence without lowering self-disclosure, and the benefits
	of such an avatar on applications such as distance learning and therapy.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Baker1977,
  author = {Baker, Harlyn},
  title = {{Three-Dimensional} Modeling},
  year = {1977},
  volume = {2},
  pages = {649},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Balogh2010,
  author = {Balogh, Tibor and Kov{\'a}cs, P{\'e}ter Tam{\'a}s},
  title = {Real-time {3D} light field transmission},
  booktitle = {{Real-Time} Image and Video Processing 2010},
  year = {2010},
  volume = {7724},
  pages = {772406},
  month = {\#may\#},
  publisher = {International Society for Optics and Photonics},
  abstract = {Although capturing and displaying stereo 3D content is now commonplace,
	information-rich light-field video content capture, transmission
	and display are much more challenging, resulting in at least one
	order of magnitude increase in complexity even in the simplest cases.
	We present an end-to-end system capable of capturing and real-time
	displaying of high-quality light-field video content on various HoloVizio
	light-field displays, providing very high 3D image quality and continuous
	motion parallax. The system is compact in terms of number of computers,
	and provides superior image quality, resolution and frame rate compared
	to other published systems. To generate light-field content, we have
	built a camera system with a large number of cameras and connected
	them to PC computers. The cameras were in an evenly spaced linear
	arrangement. The capture PC was directly connected through a single
	gigabit Ethernet connection to the demonstration 3D display, supported
	by a PC computation cluster. For the task of dense light field displaying
	massively parallel reordering and filtering of the original camera
	images is required. We were utilizing both CPU and GPU threads for
	this task. On the GPU we do the light-field conversion and reordering,
	filtering and the YUV-RGB conversion. We use OpenGL 3.0 shaders and
	2D texture arrays to have easy access to individual camera images.
	A network-based synchronization scheme is used to present the final
	rendered images.},
  conference = {Real-Time Image and Video Processing 2010},
  keywords = {Lightfield; Light-field; 3D video; HoloVizio; 3D capture; Rendering;
	Camera array; 3D display; ; ; ; ; ; ; ; ;litsurvey.bib}
}

@INPROCEEDINGS{Balogh2010,
  author = {Balogh, Tibor and Kov{\'a}cs, P{\'e}ter Tam{\'a}s},
  title = {Real-time {3D} light field transmission},
  booktitle = {{Real-Time} Image and Video Processing 2010},
  year = {2010},
  volume = {7724},
  pages = {772406},
  month = {\#may\#},
  publisher = {International Society for Optics and Photonics},
  abstract = {Although capturing and displaying stereo 3D content is now commonplace,
	information-rich light-field video content capture, transmission
	and display are much more challenging, resulting in at least one
	order of magnitude increase in complexity even in the simplest cases.
	We present an end-to-end system capable of capturing and real-time
	displaying of high-quality light-field video content on various HoloVizio
	light-field displays, providing very high 3D image quality and continuous
	motion parallax. The system is compact in terms of number of computers,
	and provides superior image quality, resolution and frame rate compared
	to other published systems. To generate light-field content, we have
	built a camera system with a large number of cameras and connected
	them to PC computers. The cameras were in an evenly spaced linear
	arrangement. The capture PC was directly connected through a single
	gigabit Ethernet connection to the demonstration 3D display, supported
	by a PC computation cluster. For the task of dense light field displaying
	massively parallel reordering and filtering of the original camera
	images is required. We were utilizing both CPU and GPU threads for
	this task. On the GPU we do the light-field conversion and reordering,
	filtering and the YUV-RGB conversion. We use OpenGL 3.0 shaders and
	2D texture arrays to have easy access to individual camera images.
	A network-based synchronization scheme is used to present the final
	rendered images.},
  conference = {Real-Time Image and Video Processing 2010},
  keywords = {Lightfield; Light-field; 3D video; HoloVizio; 3D capture; Rendering;
	Camera array; 3D display; ; ; ; ; ; ; ; ; ; ;litsurvey.bib}
}

@INPROCEEDINGS{Bandyopadhyay2001,
  author = {Bandyopadhyay, D and Raskar, R and Fuchs, H},
  title = {Dynamic shader lamps : painting on movable objects},
  booktitle = {Proceedings {IEEE} and {ACM} International Symposium on Augmented
	Reality},
  year = {2001},
  pages = {207--216},
  month = {\#oct\#},
  publisher = {IEEE Comput. Soc},
  abstract = {The authors present a Dynamic Spatially Augmented Reality system for
	augmenting movable 3D objects in an indoor environment using multiple
	projectors. We describe a real-time system for applying virtual paint
	and textures to real objects simply by direct physical manipulation
	of the object and a ``paint brush'' stylus. We track the objects
	and the ``paint brush'', and illuminate the objects with images that
	remain registered as they move, to create the illusion of material
	properties. The system is simple to use and we hope it may herald
	new applications in diverse fields such as visualization, tele-immersion,
	art and architecture. The system currently works with tracked objects
	whose geometry was pre-acquired and models created manually, but
	it is possible to extend it by adding cameras to the environment,
	to acquire object geometry automatically and use vision-based tracking
	for the object and paintbrush. Plus colour plates.},
  keywords = {augmented reality;real-time systems;image registration;computer graphics;dynamic
	shader lamps;Dynamic Spatially Augmented Reality system;movable 3D
	objects;indoor environment;multiple projectors;real-time system;virtual
	paint;virtual textures;real objects;direct physical manipulation;paint
	brush stylus;material properties;visualization;tele-immersion;art;tracked
	objects;cameras;object geometry;vision-based tracking;Lamps;Painting;Paints;Brushes;Geometry;Augmented
	reality;Indoor environments;Real time systems;Material properties;Visualization;litsurvey.bib}
}

@INPROCEEDINGS{Bardram2012,
  author = {Bardram, Jakob and Gueddana, Sofiane and Houben, Steven and Nielsen,
	S{\o}ren},
  title = {{ReticularSpaces}: activity-based computing support for physically
	distributed and collaborative smart spaces},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {2845--2854},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {smart spaces, nomadic computing, multiple display environments, distributed
	user interfaces, collaboration;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@INPROCEEDINGS{Bartneck2009,
  author = {Bartneck, Christoph and Kanda, Takayuki and Ishiguro, Hiroshi and
	Hagita, Norihiro},
  title = {My robotic doppelg{\"a}nger-A critical look at the uncanny valley},
  booktitle = {Robot and Human Interactive Communication, 2009.},
  year = {2009},
  pages = {269--276},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Bartneck2007,
  author = {Bartneck, C and Kanda, T and Ishiguro, H and Hagita, N},
  title = {Is The Uncanny Valley An Uncanny Cliff?},
  booktitle = {{RO-MAN} 2007 - The 16th {IEEE} International Symposium on Robot
	and Human Interactive Communication},
  year = {2007},
  pages = {368--373},
  month = {\#aug\#},
  abstract = {The uncanny valley theory proposed by Mori in 1970 has been a hot
	topic in human robot interaction research, in particular since the
	development of increasingly human-like androids and computer graphics.
	In this paper we describe an empirical study that attempts to plot
	Mori's hypothesized curve. In addition, the influence of framing
	on the users' perception of the stimuli was investigated. Framing
	had no significant influence on the measurements. The pictures of
	robots and humans were rated independently of whether the participants
	knew a particular picture showed a robot or human. Anthropomorphism
	had a significant influence on the measurements, but not even pictures
	of real humans were rated as likeable as the pictures of humanoids
	or toy robots. As a result we suggest the existence of an uncanny
	cliff model as an alternative to the uncanny valley model. However,
	this study focused on the perception of pictures of robots and the
	results, including the suggested model, may be different for the
	perception of movies of moving robots or the perception of standing
	right in front of a moving robot.},
  institution = {IEEE},
  keywords = {humanoid robots;man-machine systems;uncanny valley theory;human robot
	interaction research;human-like android;computer graphics;anthropomorphism;toy
	robots;Human robot interaction;Humanoid robots;Motion pictures;Service
	robots;Intelligent robots;Anthropomorphism;Communication industry;Computer
	industry;Computer graphics;Animation;litsurvey.bib}
}

@ARTICLE{Bartneck2009,
  author = {Bartneck, Christoph and Kuli{\'c}, Dana and Croft, Elizabeth and
	Zoghbi, Susana},
  title = {Measurement instruments for the anthropomorphism, animacy, likeability,
	perceived intelligence, and perceived safety of robots},
  journal = {International journal of social robotics},
  year = {2009},
  volume = {1},
  pages = {71--81},
  number = {1},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@ARTICLE{Batch2017,
  author = {Batch, Andrea and Elmqvist, Niklas},
  title = {The interactive visualization gap in initial exploratory data analysis},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2017},
  volume = {24},
  pages = {278--287},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08017577.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Baumgart1975,
  author = {Baumgart, Bruce G},
  title = {A polyhedron representation for computer vision},
  booktitle = {Proceedings of the May 19-22, 1975, national computer conference
	and exposition},
  year = {1975},
  series = {AFIPS '75},
  pages = {589--596},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {Anaheim, California}
}

@INPROCEEDINGS{Bautista2008,
  author = {Bautista, Jeanette and Carenini, Giuseppe},
  title = {An empirical evaluation of interactive visualizations for preferential
	choice},
  booktitle = {Proceedings of the working conference on Advanced visual interfaces},
  year = {2008},
  pages = {207--214},
  organization = {ACM},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/p207-bautista.pdf:PDF}
}

@INPROCEEDINGS{Beck2011,
  author = {Beck, Dennis and Fishwick, Paul and Kamhawi, Rasha and Coffey, Amy
	Jo and Henderson, Julie},
  title = {Synthesizing presence: A multidisciplinary review of the literature},
  year = {2011},
  volume = {3},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Beck2013,
  author = {Beck, Stephan and Kunert, Andre and Kulik, Alexander and Froehlich,
	Bernd},
  title = {Immersive group-to-group telepresence},
  year = {2013},
  volume = {19},
  pages = {616--625},
  publisher = {IEEE},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Bekkering2006,
  author = {Bekkering, Ernst and Shim, J P},
  title = {Trust in videoconferencing},
  month = {\#jul\#},
  year = {2006},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Bekkering2006,
  author = {Bekkering, Ernst and Shim, J P},
  title = {Trust In Videoconferencing},
  year = {2006},
  volume = {49},
  pages = {103--107},
  publisher = {ACM},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Belhumeur1993,
  author = {Belhumeur, Peter N},
  title = {A binocular stereo algorithm for reconstructing sloping, creased,
	and broken surfaces in the presence of half-occlusion},
  booktitle = {Computer Vision, 1993. Proceedings., Fourth International Conference
	on},
  year = {1993},
  pages = {431--438},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Benford1995-ln,
  author = {Benford, Steve and Bowers, John and Fahl{\'e}n, Lennart E and Greenhalgh,
	Chris and Snowdon, Dave},
  title = {{User embodiment in collaborative virtual environments}},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1995},
  series = {CHI '95},
  pages = {242--249},
  address = {USA},
  month = {\#may\#},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  keywords = {litsurvey.bib},
  location = {Denver, Colorado, USA}
}

@UNPUBLISHED{Benford1998-hw,
  author = {Benford, Steve and Greenhalgh, Chris and Reynard, Gail and Brown,
	Chris and Koleva, Boriana},
  title = {Understanding and constructing shared spaces with mixed-reality boundaries},
  month = {\#sep\#},
  year = {1998},
  keywords = {telepresence, shared spaces, media-spaces, CSCW, virtual reality,
	mixed reality, video, collaborative virtual environments, augmented
	reality;litsurvey.bib}
}

@INCOLLECTION{Benford1995,
  author = {Benford, Steve and Mariani, John},
  title = {Virtual environments for data sharing and visualisation—populated
	information terrains},
  booktitle = {Interfaces to Database Systems (IDS94)},
  publisher = {Springer},
  year = {1995},
  pages = {168--182},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Virtual Environments for Data Sharing and Visu.pdf:PDF}
}

@INCOLLECTION{Benford1995a,
  author = {Benford, Steve and Mariani, John},
  title = {Virtual environments for data sharing and visualisation—populated
	information terrains},
  booktitle = {Interfaces to Database Systems (IDS94)},
  publisher = {Springer},
  year = {1995},
  pages = {168--182},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Virtual Enviroments for Data Sharing and Visua.pdf:PDF}
}

@ARTICLE{Benjamin2012,
  author = {Benjamin, L O K},
  title = {Shader lamps virtual patients: the physical manifestation of virtual
	patients},
  journal = {Medicine Meets Virtual Reality 19: NextMed},
  year = {2012},
  volume = {173},
  pages = {372},
  keywords = {litsurvey.bib},
  publisher = {IOS Press}
}

@INPROCEEDINGS{Benko2012,
  author = {Benko, Hrvoje and Jota, Ricardo and Wilson, Andrew},
  title = {{MirageTable}: freehand interaction on a projected augmented reality
	tabletop},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {199--208},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {projector-camera system, spatial augmented reality, shared task space,
	3d interaction, 3d teleconferencing, depth camera, projective textures,
	3d digitization;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@INPROCEEDINGS{Benko2014,
  author = {Benko, Hrvoje and Wilson, Andrew D and Zannier, Federico},
  title = {Dyadic projected spatial augmented reality},
  booktitle = {Proceedings of the 27th annual {ACM} symposium on User interface
	software and technology},
  year = {2014},
  series = {UIST '14},
  pages = {645--655},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {depth cameras, augmented reality, projector camera system;litsurvey.bib},
  location = {Honolulu, Hawaii, USA}
}

@INPROCEEDINGS{Bente1998,
  author = {Bente, Gary and Donaghy, W C and Suwelack, Dorit},
  title = {Sex Differences In Body Movement And Visual Attention: An Integrated
	Analysis Of Movement And Gaze In Mixed-sex Dyads},
  year = {1998},
  volume = {22},
  keywords = {litsurvey.bib}
}

@ARTICLE{Berger1975,
  author = {Berger, Charles R and Calabrese, Richard J},
  title = {Some Explorations in Initial Interaction and Beyond: Toward a Developmental
	Theory of Interpersonal Communication},
  journal = {Hum. Commun. Res.},
  year = {1975},
  volume = {1},
  pages = {99--112},
  number = {2},
  month = {\#dec\#},
  abstract = {Abstract. This paper provides a theoretical perspective for dealing
	with the initial entry stage of interpersonal interaction. The seven
	axioms and 21 theorems},
  keywords = {interpersonal relations;litsurvey.bib},
  publisher = {Oxford Academic}
}

@Misc{solidPages,
  author    = {Berners-Lee, Tim},
  title     = {Solid Project Web Page},
  year      = {2016},
  owner     = {its352},
  timestamp = {2021.12.02},
  url       = {https://www.solidproject.org},
}

@MISC{semanticWeb,
  author = {Berners-Lee, Tim; Fischetti, Mark},
  title = {Weaving the web},
  howpublished = {\url{https://archive.org/details/isbn_9780062515872/mode/2up}},
  year = {1999},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@INPROCEEDINGS{Beyer2011,
  author = {Beyer, Gilbert and Alt, Florian and M{\"u}ller, J{\"o}rg and Schmidt,
	Albrecht and Isakovic, Karsten and Klose, Stefan and Schiewe, Manuel
	and Haulsen, Ivo},
  title = {Audience behavior around large interactive cylindrical screens},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {1021--1030},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {public displays, cylindrical screens, interactive surfaces, digital
	columns, non-planar screens, display formats;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@ARTICLE{Bezrukova2009,
  author = {Bezrukova, Katerina and Jehn, Karen A and Zanutto, Elaine L and Thatcher,
	Sherry M B},
  title = {Do Workgroup Faultlines Help or Hurt? A Moderated Model of Faultlines,
	Team Identification, and Group Performance},
  journal = {Organization Science},
  year = {2009},
  volume = {20},
  pages = {35--50},
  number = {1},
  month = {\#feb\#},
  abstract = {In this study we examine a moderated model of group faultlines, team
	identification, and group performance outcomes. We extend research
	on faultlines by showing how different faultline bases (social category
	and information-based faultlines) may have differential effects on
	the performance of groups. In addition to faultline strength (the
	extent of demographic alignment across members within a group), we
	examine the distance between faultline-based subgroups (e.g., two
	members of age 20 are closer in age to two members of an opposing
	subgroup of age 25 than of two members of age 50). We test our model
	using an archival field methodology and multiple-source data (qualitative
	and quantitative) from 76 workgroups in a Fortune 500 information-processing
	company. Our results revealed that groups with social category faultlines
	had low team discretionary awards. Faultline distance further exacerbated
	the negative effects of strength in groups with social category faultlines
	and produced similarly negative effects in groups with information-based
	faultlines. Team identification served as a moderator enhancing performance
	of groups with information-based faultlines.},
  keywords = {litsurvey.bib},
  publisher = {INFORMS}
}

@INPROCEEDINGS{Bhardwaj2019,
  author = {Bhardwaj, Priti and Baliyan, Niyati},
  title = {Hadoop based Analysis and Visualization of Diabetes Data through
	Tableau},
  booktitle = {2019 Twelfth International Conference on Contemporary Computing (IC3)},
  year = {2019},
  pages = {1--5},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08844873.pdf:PDF}
}

@InProceedings{Biocca1997,
  author   = {Biocca, Frank},
  title    = {The Cyborg Dilemma : Embodiment in Virtual Environments},
  year     = {1997},
  pages    = {12--26},
  keywords = {be explosive, cyborgs, embodiment, human-computer interaction, it casts long, lighting the horizon as, note, part of keynote, presence, the following text was, virtual reality;litsurvey.bib},
}

@ARTICLE{Biocca1997,
  author = {Biocca, Frank},
  title = {The Cyborg's Dilemma: Progressive Embodiment in Virtual Environments},
  journal = {J. Comput. Mediat. Commun.},
  year = {1997},
  volume = {3},
  pages = {0--0},
  number = {2},
  month = {\#sep\#},
  abstract = {Abstract. How does the changing representation of the body in virtual
	environments affect the mind? This article considers how virtual
	reality interfaces are e},
  keywords = {litsurvey.bib},
  publisher = {Oxford Academic}
}

@INPROCEEDINGS{Biocca2003,
  author = {Biocca, Frank and Harms, Chad and Burgoon, Judee},
  title = {Toward a more robust theory and measure of social presence: Review
	and suggested criteria},
  year = {2003},
  volume = {12},
  pages = {456--480},
  publisher = {MIT press},
  keywords = {litsurvey.bib}
}

@ARTICLE{Biocca2003,
  author = {Biocca, Frank and Harms, Chad and Burgoon, Judee K},
  title = {Toward a More Robust Theory and Measure of Social Presence: Review
	and Suggested Criteria},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2003},
  volume = {12},
  pages = {456--480},
  number = {5},
  month = {\#oct\#},
  abstract = {At a time of increased social usage of net and collaborative applications,
	a robust and detailed theory of social presence could contribute
	to our understanding of social behavior in mediated environments,
	allow researchers to predict and measure differences among media
	interfaces, and guide the design of new social environments and interfaces.
	A broader theory of social presence can guide more valid and reliable
	measures. The article reviews, classifies, and critiques existing
	theories and measures of social presence. A set of criteria and scope
	conditions is proposed to help remedy limitations in past theories
	and measures and to provide a contribution to a more robust theory
	and measure of social presence.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Biocca2003,
  author = {Biocca, Frank and Harms, Chad and Burgoon, Judee K},
  title = {Toward a More Robust Theory and Measure of Social Presence: Review
	and Suggested Criteria},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2003},
  volume = {12},
  pages = {456--480},
  number = {5},
  month = {\#oct\#},
  abstract = {At a time of increased social usage of net and collaborative applications,
	a robust and detailed theory of social presence could contribute
	to our understanding of social behavior in mediated environments,
	allow researchers to predict and measure differences among media
	interfaces, and guide the design of new social environments and interfaces.
	A broader theory of social presence can guide more valid and reliable
	measures. The article reviews, classifies, and critiques existing
	theories and measures of social presence. A set of criteria and scope
	conditions is proposed to help remedy limitations in past theories
	and measures and to provide a contribution to a more robust theory
	and measure of social presence.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Blanche2010,
  author = {Blanche, P-A and Bablumian, A and Voorakaranam, R and Christenson,
	C and Lin, W and Gu, T and Flores, D and Wang, P and Hsieh, W-Y and
	Kathaperumal, M and Rachwal, B and Siddiqui, O and Thomas, J and
	Norwood, R a and Yamamoto, M and Peyghambarian, N},
  title = {Holographic three-dimensional telepresence using large-area photorefractive
	polymer},
  year = {2010},
  volume = {468},
  pages = {80--83},
  abstract = {Holography is a technique that is used to display objects or scenes
	in three dimensions. Such three-dimensional (3D) images, or holograms,
	can be seen with the unassisted eye and are very similar to how humans
	see the actual environment surrounding them. The concept of 3D telepresence,
	a real-time dynamic hologram depicting a scene occurring in a different
	location, has attracted considerable public interest since it was
	depicted in the original Star Wars film in 1977. However, the lack
	of sufficient computational power to produce realistic computer-generated
	holograms and the absence of large-area and dynamically updatable
	holographic recording media have prevented realization of the concept.
	Here we use a holographic stereographic technique and a photorefractive
	polymer material as the recording medium to demonstrate a holographic
	display that can refresh images every two seconds. A 50\textbackslashquotesinglbase{\"A}{\^a}Hz
	nanosecond pulsed laser is used to write the holographic pixels.
	Multicoloured holographic 3D images are produced by using angular
	multiplexing, and the full parallax display employs spatial multiplexing.
	3D telepresence is demonstrated by taking multiple images from one
	location and transmitting the information via Ethernet to another
	location where the hologram is printed with the quasi-real-time dynamic
	3D display. Further improvements could bring applications in telemedicine,
	prototyping, advertising, updatable 3D maps and entertainment.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Blandford2008,
  author = {Blandford, Ann and Cox, Anna and Cairns, Paul},
  title = {Controlled Experiments},
  year = {2008},
  keywords = {litsurvey.bib}
}

@InProceedings{Blascovich2002,
  author    = {Blascovich, Jim},
  booktitle = {Proceedings of the 4th international conference on Collaborative virtual environments},
  title     = {A theoretical model of social influence for increasing the utility of collaborative virtual environments},
  year      = {2002},
  address   = {New York, NY, USA},
  month     = {\#sep\#},
  pages     = {25--30},
  publisher = {Association for Computing Machinery},
  series    = {CVE '02},
  keywords  = {agency, behavioral realism, self-relevance, social influence;litsurvey.bib},
  location  = {Bonn, Germany},
}

@ARTICLE{Bloom2015,
  author = {Bloom, Nicholas and Liang, James and Roberts, John and Ying, Zhichun
	Jenny},
  title = {Does working from home work? Evidence from a Chinese experiment},
  journal = {Q. J. Econ.},
  year = {2015},
  volume = {130},
  pages = {165--218},
  number = {1},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Bo_Shu2008,
  author = {{Bo Shu} and {Xianjie Qiu} and {Zhaoqi Wang}},
  title = {{Hardware-based camera calibration and {3D} modelling under circular
	motion}},
  booktitle = {2008 {IEEE} Computer Society Conference on Computer Vision and Pattern
	Recognition Workshops},
  year = {2008},
  pages = {1--6},
  month = {\#jun\#},
  abstract = {In this paper, we present a combined camera calibration and image
	based modeling method using an iterative optimization of shape from
	silhouette under circular motion. By minimizing the difference between
	the projections of reconstructed visual hull and the silhouette images
	using graphics hardware, the optimization can finally converge to
	accurate camera parameters and realistic visual hull efficiently
	and robustly. Using this method, we can automatically create photorealistic
	3D models directly from images.},
  keywords = {image motion analysis;image reconstruction;image sensors;optimisation;realistic
	images;solid modelling;hardware-based camera calibration;photorealistic
	3D modelling;circular motion;image based modeling method;iterative
	optimization;reconstructed visual hull;silhouette image;graphics
	hardware;Cameras;Calibration;Iterative methods;Optimization methods;Shape;Image
	reconstruction;Graphics;Hardware;Image converters;Robustness;litsurvey.bib}
}

@ARTICLE{Bock2008,
  author = {Bock, Simon W and Dicke, Peter and Thier, Peter},
  title = {How precise is gaze following in humans?},
  journal = {Vision Res.},
  year = {2008},
  volume = {48},
  pages = {946--957},
  number = {7},
  month = {\#mar\#},
  abstract = {Gaze following is the basis of joint visual attention. We investigated
	the capability of human 'receivers' to single out one of many objects,
	defined by the gaze of a human or computer 'sender'. Deviations from
	the sender's target were normally distributed and judgements were
	highly accurate. Accuracy of gaze following under binocular and monocular
	vision of the receiver did not differ, but performance was poorer
	when only one of the sender's eyes was visible. Two types of systematic
	bias could be identified: upward bias and cardinal-axis bias. In
	summary, human gaze following is not only very precise but also surprisingly
	robust to manipulations of the sender cues available for guiding
	the receiver's eyes.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Elsevier}
}

@ARTICLE{Bohannon2013,
  author = {Bohannon, Leanne S and Herbert, Andrew M and Pelz, Jeff B and Rantanen,
	Esa M},
  title = {Eye contact and video-mediated communication: A review},
  journal = {Displays},
  year = {2013},
  volume = {34},
  pages = {177--185},
  number = {2},
  month = {\#apr\#},
  abstract = {A relatively new form of human communication, video-conferencing has
	become more popular as video technology improves and with increasing
	demands for real-time communication across greater distances. The
	full effects of video-conferencing on human communication are still
	being explored. Video-conferencing is presumed to be a somewhat richer
	form of communication than email and telephone, but not quite as
	informative as face-to-face communication. This review explores research
	into the influence of eye contact on communication and how video-conferencing
	mediates both verbal and non-verbal interactions. Facilitation of
	eye contact is a challenge that must be addressed so that video-conferencing
	can approach the rich interactions of face-to-face communication.},
  keywords = {Video-conferencing; Eye contact; Communication; Eye-tracking; Display;
	Laptop;litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Boker2011,
  author = {Boker, Steven M and Cohn, Jeffrey F and Theobald, Barry-John and
	Matthews, Iain and Mangini, Michael and Spies, Jeffrey R and Ambadar,
	Zara and Brick, Timothy R},
  title = {Something in the way we move: Motion dynamics, not perceived sex,
	influence head movements in conversation},
  journal = {J. Exp. Psychol. Hum. Percept. Perform.},
  year = {2011},
  volume = {37},
  pages = {874--891},
  number = {3},
  month = {\#jun\#},
  abstract = {During conversation, women tend to nod their heads more frequently
	and more vigorously than men. An individual speaking with a woman
	tends to nod his or her head more than when speaking with a man.
	Is this due to social expectation or due to coupled motion dynamics
	between the speakers? We present a novel methodology that allows
	us to randomly assign apparent identity during free conversation
	in a video-conference, thereby dissociating apparent sex from motion
	dynamics. The method uses motion-tracked synthesized avatars that
	are accepted by naive participants as being live video. We find that
	1) motion dynamics affect head movements but that apparent sex does
	not; 2) judgments of sex are driven almost entirely by appearance;
	and 3) ratings of masculinity and femininity rely on a combination
	of both appearance and dynamics. Together, these findings are consistent
	with the hypothesis of separate perceptual streams for appearance
	and biological motion. In addition, our results are consistent with
	a view that head movements in conversation form a low level perception
	and action system that can operate independently from top-down social
	expectations.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {American Psychological Association}
}

@INPROCEEDINGS{Bolton2012,
  author = {Bolton, John and Kim, Kibum and Vertegaal, Roel},
  title = {A comparison of competitive and cooperative task performance using
	spherical and flat displays},
  booktitle = {Proceedings of the {ACM} 2012 conference on Computer Supported Cooperative
	Work},
  year = {2012},
  series = {CSCW '12},
  pages = {529--538},
  address = {New York, NY, USA},
  month = {\#feb\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {shared space, organic user interfaces, collaboration, spherical displays;litsurvey.bib},
  location = {Seattle, Washington, USA}
}

@INPROCEEDINGS{Bondareva2004,
  author = {Bondareva, Yevgenia and Bouwhuis, Don},
  title = {Determinants of social presence in videoconferencing},
  booktitle = {{AVI2004} Workshop on Environments for Personalized Information Access},
  year = {2004},
  pages = {1--9},
  institution = {Citeseer},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Bondareva2004,
  author = {Bondareva, Yevgenia and Bouwhuis, Don},
  title = {Determinants of social presence in videoconferencing},
  booktitle = {{AVI2004} Workshop on Environments for Personalized Information Access},
  year = {2004},
  pages = {1--9},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Boote2005,
  author = {Boote, David N and Beile, Penny},
  title = {Scholars Before Researchers: On The Centrality Of The Dissertation
	Literature Review In Research Preparation},
  year = {2005},
  volume = {34},
  pages = {3--15},
  publisher = {Sage Publications},
  keywords = {litsurvey.bib}
}

@ARTICLE{Boote2005,
  author = {Boote, David N and Beile, Penny},
  title = {Scholars Before Researchers: On the Centrality of the Dissertation
	Literature Review in Research Preparation},
  journal = {Educ. Res.},
  year = {2005},
  volume = {34},
  pages = {3--15},
  number = {6},
  month = {\#aug\#},
  abstract = {A thorough, sophisticated literature review is the foundation and
	inspiration for substantial, useful research. The complex nature
	of education research demands such thorough, sophisticated reviews.
	Although doctoral education is a key means for improving education
	research, the literature has given short shrift to the dissertation
	literature review. This article suggests criteria to evaluate the
	quality of dissertation literature reviews and reports a study that
	examined dissertations at three universities. Acquiring the skills
	and knowledge required to be education scholars, able to analyze
	and synthesize the research in a field of specialization, should
	be the focal, integrative activity of predissertation doctoral education.
	Such scholarship is a prerequisite for increased methodological sophistication
	and for improving the usefulness of education research.},
  keywords = {litsurvey.bib},
  publisher = {American Educational Research Association}
}

@INPROCEEDINGS{Borovikov2000,
  author = {Borovikov, Eugene and Davis, Larry},
  title = {A distributed system for real-time volume reconstruction},
  booktitle = {Computer Architectures for Machine Perception, 2000. Proceedings.
	Fifth {IEEE} International Workshop on},
  year = {2000},
  pages = {183--189},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Bowman2012,
  author = {Bowman, Doug A and McMahan, Ryan P and Ragan, Eric D},
  title = {Questioning naturalism in {3D} user interfaces},
  month = {\#sep\#},
  year = {2012},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Boyer2003,
  author = {Boyer, Edmond and Franco, Jean-S{\'e}bastien},
  title = {A hybrid approach for computing visual hulls of complex objects},
  booktitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern
	Recognition},
  year = {2003},
  pages = {695--701},
  institution = {IEEE Computer Society Press},
  keywords = {litsurvey.bib}
}

@BOOK{Boyle2018,
  title = {Advances in visual computing},
  publisher = {Springer},
  year = {2018},
  author = {Boyle, George Bebis Richard and Koracin, Bahram Parvin Darko and
	Nefian, Paolo Remagnino {\"A}ra and Pascucci, Gopi Meenakshisundaram
	Valerio and Molineros, Jiri Zara Jose and Malzbender, Holger Theisel
	Thomas},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/2010_Book_AdvancesInVisualComputing.pdf:PDF}
}

@INPROCEEDINGS{Bradner2002,
  author = {Bradner, Erin and Mark, Gloria},
  title = {Why distance matters: effects on cooperation, persuasion and deception},
  booktitle = {Proceedings of the 2002 {ACM} conference on Computer supported cooperative
	work},
  year = {2002},
  series = {CSCW '02},
  pages = {226--235},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  keywords = {CSCW, cooperation, deception, distance collaboration, empirical study,
	instant messaging, video;litsurvey.bib},
  location = {New Orleans, Louisiana, USA}
}

@INPROCEEDINGS{Brooks1990,
  author = {Brooks, Frederick P and Ouh-Young, Ming and Batter, James J and Jerome
	Kilpatrick, P},
  title = {Project {GROPEHaptic} displays for scientific visualization},
  booktitle = {Proceedings of the 17th annual conference on Computer graphics and
	interactive techniques},
  year = {1990},
  volume = {24},
  series = {SIGGRAPH '90},
  pages = {177--185},
  address = {New York, NY, USA},
  month = {\#sep\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {Dallas, TX, USA}
}

@ARTICLE{Brown1992,
  author = {Brown, Rick},
  title = {Managing the “S curves of innovation},
  journal = {Journal of Business \& Industrial Marketing},
  year = {1992},
  file = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\bitcoin\\10-1108_08858629210035418.pdf:PDF},
  publisher = {MCB UP Ltd}
}

@INPROCEEDINGS{Bruckner2010,
  author = {Bruckner, Stefan and Gr{\"o}ller, M Eduard and Mueller, Klaus and
	Preim, Bernhard and Silver, Deborah},
  title = {Illustrative focus+ context approaches in interactive volume visualization},
  booktitle = {Dagstuhl Follow-Ups},
  year = {2010},
  volume = {1},
  organization = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Illustrative Focus + Context Approaches in Int.pdf:PDF}
}

@ARTICLE{Bruno2013,
  author = {Bruno, Nicola and Muzzolini, Michela},
  title = {Proxemics Revisited: Similar Effects of Arms Length on Men's and
	Women's Personal Distances},
  journal = {Universal Journal of Psychology},
  year = {2013},
  volume = {1},
  pages = {46--52},
  number = {2},
  keywords = {litsurvey.bib},
  publisher = {Horizon Research Publishing}
}

@BOOK{brunton2019digital,
  title = {Digital Cash: The Unknown History of the Anarchists, Utopians, and
	Technologists Who Created Cryptocurrency},
  publisher = {Princeton University Press},
  year = {2019},
  author = {Brunton, Finn},
  file = {:../../../literature_repository/bitcoin/Finn_Brunton_Digital_Cash__The_Unknown.pdf:PDF}
}

@ARTICLE{Buczak2015,
  author = {Buczak, Anna L and Guven, Erhan},
  title = {A survey of data mining and machine learning methods for cyber security
	intrusion detection},
  journal = {IEEE Communications Surveys \& Tutorials},
  year = {2015},
  volume = {18},
  pages = {1153--1176},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07307098.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Budhiraja2015,
  author = {Budhiraja, Pulkit and Sodhi, Rajinder and Jones, Brett and Karsch,
	Kevin and Bailey, Brian and Forsyth, David},
  title = {Where's My Drink? Enabling Peripheral Real World Interactions While
	Using {HMDs}},
  journal = {arXiv preprint arXiv:1502. 04744},
  year = {2015},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Bulling2013,
  author = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
  title = {{EyeContext}: recognition of high-level contextual cues from human
	visual behaviour},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {305--308},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  keywords = {eye movement analysis, electrooculography (eog), visual behaviour,
	context recognition;litsurvey.bib},
  location = {Paris, France}
}

@INPROCEEDINGS{Bulling2013,
  author = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
  title = {{EyeContext}: recognition of high-level contextual cues from human
	visual behaviour},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {305--308},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {eye movement analysis, electrooculography (eog), visual behaviour,
	context recognition;litsurvey.bib},
  location = {Paris, France}
}

@ARTICLE{Bulu2012,
  author = {Bulu, Saniye Tugba},
  title = {Place presence, social presence, co-presence, and satisfaction in
	virtual worlds},
  journal = {Comput. Educ.},
  year = {2012},
  volume = {58},
  pages = {154--161},
  number = {1},
  month = {\#jan\#},
  abstract = {This study investigated the relationship among three types of presences,
	including place presence, social presence, and co-presence in virtual
	worlds and their relationship with satisfaction and immersive tendencies
	of students. Students' scores on a subjective questionnaire were
	analyzed. The results indicated that there was a significant relationship
	among the place presence, social presence, and co-presence. While
	social presence seemed to affect the satisfaction most, place and
	co-presence also affected students' satisfaction in the virtual world.
	Moreover, immersive tendencies of the students were related to their
	place and co-presence but not to their social presence. Findings
	highlighted the important issues for the design of virtual world
	environments to increase presence and satisfaction of students.},
  keywords = {Distance education and telelearning; Interactive learning environments;
	Media in education; Multimedia/hypermedia systems; Simulations;litsurvey.bib},
  publisher = {Elsevier}
}

@BOOK{burnham1983rise,
  title = {The rise of the computer state},
  publisher = {Random House Inc.},
  year = {1983},
  author = {Burnham, David}
}

@BOOK{Butime2010,
  title = {{Application of Computer Vision to {3D} Reconstruction: A Survey
	of Reconstruction Methods}},
  publisher = {VDM Publishing},
  year = {2010},
  author = {Butime, J and Galo, L and Gutierrez, I},
  series = {A Survey of Reconstruction Methods},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Butscher2018,
  author = {Butscher, Simon and Hubenschmid, Sebastian and M{\"u}ller, Jens and
	Fuchs, Johannes and Reiterer, Harald},
  title = {Clusters, trends, and outliers: How immersive technologies can facilitate
	the collaborative analysis of multidimensional data},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing
	Systems},
  year = {2018},
  pages = {90},
  organization = {ACM},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/paper90.pdf:PDF}
}

@ARTICLE{Buxton2009,
  author = {Buxton, Bill},
  title = {Mediaspace--meaningspace--meetingspace},
  journal = {Media space 20+ years of mediated life},
  year = {2009},
  pages = {217--231},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@INPROCEEDINGS{Buxton1992,
  author = {Buxton, William},
  title = {Telepresence: Integrating shared task and person spaces},
  booktitle = {Proceedings of graphics interface},
  year = {1992},
  volume = {92},
  pages = {123--129},
  institution = {Canadian Information Processing Society Toronto, Canada},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Buxton1992,
  author = {Buxton, William},
  title = {Telepresence: Integrating shared task and person spaces},
  booktitle = {Proceedings of graphics interface},
  year = {1992},
  volume = {92},
  pages = {123--129},
  keywords = {litsurvey.bib}
}

@ARTICLE{Buxton1992,
  author = {Buxton, W},
  title = {Telepresence: integrating shared task and person spaces},
  journal = {Proceedings of Graphics Interface},
  year = {1992},
  keywords = {litsurvey.bib}
}

@ARTICLE{Buxton1997,
  author = {Buxton, W A S and Sellen, A J and Sheasby, M C},
  title = {{Interfaces for multiparty videoconferences}},
  journal = {Video Mediated Communication.},
  year = {1997},
  pages = {385--400},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Bocker1996,
  author = {B{\"o}cker, Martin and Blohm, Werner and M{\"u}hlbach, Lothar},
  title = {Anthropometric data on horizontal head movements in videocommunications},
  booktitle = {Conference Companion on Human Factors in Computing Systems},
  year = {1996},
  series = {CHI '96},
  pages = {95--96},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {Vancouver, British Columbia, Canada}
}

@ARTICLE{Caldwell1995,
  author = {Caldwell, Barrett S and Uang, Shiaw-Tsyr and Taha, Lilas H},
  title = {Appropriateness of communications media use in organizations: situation
	requirements and media characteristics},
  journal = {Behav. Inf. Technol.},
  year = {1995},
  volume = {14},
  pages = {199--207},
  number = {4},
  month = {\#jul\#},
  abstract = {Abstract The purpose of this paper is to examine media use in organizations
	as affected by situation requirements and media characteristics.
	This paper discusses the strength of four existing models describing
	communications media use in individuals and organizations. The paper
	also presents research which evaluated interactions of multiple situation
	variables affecting communications media appropriateness in a survey
	population. Participants rated die acceptability of each of twelve
	communications media in each of eight hypothetical organizational
	situations. Situations varied based on high or low levels of three
	factors: message urgency, amount of message content, and distance
	between communicators. Results indicated (1) situations have unique
	and significant contributions to media appropriateness; (2) appropriateness
	of media usage depends on the match between situation requirements
	and media characteristics, and (3) situation effects are more salient
	in some ?situation-dependent? media. Another survey of 1072 voice
	mail users confirmed die validity and reliability of these results.},
  keywords = {litsurvey.bib},
  publisher = {Taylor \& Francis}
}

@TECHREPORT{callas1998openpgp,
  author = {Callas, Jon and Donnerhacke, Lutz and Finney, Hal and Thayer, Rodney},
  title = {OpenPGP message format},
  institution = {RFC 2440, November},
  year = {1998}
}

@INPROCEEDINGS{Canny2011,
  author = {Canny, Apoorva Sachdev John},
  title = {{Triple-View}: Improving Persuasion in Group Video Conferencing through
	spatial Faithfulness},
  year = {2011},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Card2002,
  author = {Card, Stuart K and Nation, David},
  title = {Degree-of-interest trees: a component of an attention-reactive user
	interface.},
  booktitle = {AVI},
  year = {2002},
  volume = {2},
  pages = {231--245},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Degree-of-Interest Trees A Component of an Att.pdf:PDF}
}

@BOOK{Carlston2013,
  title = {The Oxford Handbook of Social Cognition},
  publisher = {OUP USA},
  year = {2013},
  author = {Carlston, Donal E},
  series = {Oxford Library of Psychology},
  month = {\#sep\#},
  abstract = {Social cognition, as a field, can be characterized as a distinct subarea
	of social psychology that examines all of the countless cognitive
	complexities, mental representations, and processes implicated in
	interaction, as well as an approach to studying interactions in the
	context of the groups, cultures, and societies to which they belong.
	Together these two facets of social cognition create one of the most
	influential and important social sciences to come along in some time.
	Providing a comprehensive review of major topics in the field of
	social cognition, The Oxford Handbook of Social Cognition expresses
	that excitement and fascination in describing the content and approach
	that constitute the field today. The 43 chapters included in this
	handbook cover: - central aspects of the field of social cognition,
	including its history and historically important foundational research
	areas (attribution, attitudes, impression formation, and prejudice/stereotyping),
	along with methodology - core issues relating to social cognitive
	representations and processes (including those that are visual, implicit,
	or automatic) and the stages of information processing (attention,
	perception, memory, and judgment, along with simulation and thought
	suppression) - applications of the social cognition approach to areas
	of social psychology, general psychology, and other disciplines,
	such as marketing, law, health and politics After more than 30 years,
	the vibrant field of social cognition continues to reign as one of
	psychology's most dominant approaches. The impressive chapters collected
	in this volume define the field and contribute enormously to our
	understanding of what social cognition is today.},
  keywords = {litsurvey.bib},
  language = {en}
}

@INPROCEEDINGS{Carranza2003,
  author = {Carranza, Joel and Theobalt, Christian and Magnor, Marcus A and Seidel,
	Hans-Peter},
  title = {Free-viewpoint video of human actors},
  booktitle = {{ACM} transactions on graphics ({TOG})},
  year = {2003},
  volume = {22},
  pages = {569--577},
  institution = {ACM},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Carranza2003,
  author = {Carranza, Joel and Theobalt, Christian and Magnor, Marcus A and Seidel,
	Hans-Peter},
  title = {{Free-viewpoint video of human actors}},
  booktitle = {Proceedings of the 30\textbackslashtextsuperscript{th} annual conference
	on Computer Graphics and Interactive Techniques ({SIGGRAPH} '03)},
  year = {2003},
  address = {San Diego},
  keywords = {litsurvey.bib}
}

@ARTICLE{casino2019systematic,
  author = {Casino, Fran and Dasaklis, Thomas K and Patsakis, Constantinos},
  title = {A systematic literature review of blockchain-based applications:
	Current status, classification and open issues},
  journal = {Telematics and informatics},
  year = {2019},
  volume = {36},
  pages = {55--81},
  publisher = {Elsevier}
}

@ARTICLE{Chartrand1999,
  author = {Chartrand, T L and Bargh, J A},
  title = {The chameleon effect: the perception-behavior link and social interaction},
  journal = {J. Pers. Soc. Psychol.},
  year = {1999},
  volume = {76},
  pages = {893--910},
  number = {6},
  month = {\#jun\#},
  abstract = {The chameleon effect refers to nonconscious mimicry of the postures,
	mannerisms, facial expressions, and other behaviors of one's interaction
	partners, such that one's behavior passively and unintentionally
	changes to match that of others in one's current social environment.
	The authors suggest that the mechanism involved is the perception-behavior
	link, the recently documented finding (e.g., J. A. Bargh, M. Chen,
	\& L. Burrows, 1996) that the mere perception of another's behavior
	automatically increases the likelihood of engaging in that behavior
	oneself. Experiment 1 showed that the motor behavior of participants
	unintentionally matched that of strangers with whom they worked on
	a task. Experiment 2 had confederates mimic the posture and movements
	of participants and showed that mimicry facilitates the smoothness
	of interactions and increases liking between interaction partners.
	Experiment 3 showed that dispositionally empathic individuals exhibit
	the chameleon effect to a greater extent than do other people.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {American Psychological Association}
}

@ARTICLE{chaum1985security,
  author = {Chaum, David},
  title = {Security without identification: Transaction systems to make big
	brother obsolete},
  journal = {Communications of the ACM},
  year = {1985},
  volume = {28},
  pages = {1030--1044},
  number = {10},
  publisher = {ACM New York, NY, USA}
}

@INPROCEEDINGS{Chen2002,
  author = {Chen, Milton},
  title = {Leveraging the asymmetric sensitivity of eye contact for videoconference},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2002},
  series = {CHI '02},
  pages = {49--56},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {eye contact, gaze perception, videoconferencing;litsurvey.bib},
  location = {Minneapolis, Minnesota, USA}
}

@ARTICLE{Chen2018,
  author = {Chen, Wei and Guo, Fangzhou and Han, Dongming and Pan, Jacheng and
	Nie, Xiaotao and Xia, Jiazhi and Zhang, Xiaolong},
  title = {Structure-based suggestive exploration: a new approach for effective
	exploration of large networks},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {555--565},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440813.pdf:PDF},
  publisher = {IEEE}
}

@Article{hafid2020scaling,
  author    = {Hafid, Abdelatif and Hafid, Abdelhakim Senhaji and Samih, Mustapha},
  journal   = {IEEE Access},
  title     = {Scaling blockchains: A comprehensive survey},
  year      = {2020},
  pages     = {125244--125262},
  volume    = {8},
  publisher = {IEEE},
}

@ARTICLE{Cheng2011,
  author = {Cheng, Hong and Zhou, Yang and Yu, Jeffrey Xu},
  title = {Clustering large attributed graphs: A balance between structural
	and attribute similarities},
  journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
  year = {2011},
  volume = {5},
  pages = {12},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/clustering/1921632.1921638.pdf:PDF},
  publisher = {ACM}
}

@INPROCEEDINGS{Cheung2003,
  author = {Cheung, G K M and Baker, S and Kanade, T},
  title = {{Visual hull alignment and refinement across time: a {3D} reconstruction
	algorithm combining shape-from-silhouette with stereo}},
  booktitle = {Proceedings of the {IEEE} Computer Society Conference on Computer
	Vision and Pattern Recognition ({CVPR} '03)},
  year = {2003},
  address = {Madison},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Cheung2000,
  author = {Cheung, German K M and Kanade, Takeo and Bouguet, J-Y and Holler,
	Mark},
  title = {A real time system for robust {3D} voxel reconstruction of human
	motions},
  booktitle = {Computer Vision and Pattern Recognition, 2000. Proceedings. {IEEE}
	Conference on},
  year = {2000},
  volume = {2},
  pages = {714--720},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@ARTICLE{Chien1986,
  author = {Chien, C H and Aggarwal, J K},
  title = {{Volume/surface octrees for the representation of three-dimensional
	objects}},
  journal = {Computer Vision, Graphics, and Image Processing},
  year = {1986},
  volume = {36},
  pages = {100--113},
  number = {1},
  month = {\#oct\#},
  abstract = {The octree structure for the representation of 3D objects is an extension
	of the quadtree representation of 2D (binary) images. It is generated
	from the 3D binary array of the object it represents. However, the
	acquisition of a 3D array is not a trivial problem. In this study,
	we propose a scheme to generate an octree of an object from its three
	orthogonal views (silhouettes) exploiting a volume intersection technique.
	A multi-level boundary search algorithm is developed to incorporate
	surface information into the octree representation. This makes the
	octree representation compact, informative, and especially useful
	for graphic displays and object recognition tasks. An algorithm is
	also designed for computing the moment of inertia matrix, which is
	useful for object recognition. All the algorithms developed in this
	study are essentially tree traversal procedures and therefore are
	suitable for implementation on parallel processors.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Cho1994,
  author = {Cho, Changsuk and Minamitani, Haruyuki},
  title = {{Obtaining 3-d shape from silhouette informations interpolated by
	photometric stereo}},
  booktitle = {Workshop on Machine Vision Applications ({MVA} '94)},
  year = {1994},
  pages = {147--150},
  address = {Kanagawa},
  publisher = {Citeseer},
  keywords = {litsurvey.bib}
}

@ARTICLE{Chovil1991,
  author = {Chovil, Nicole},
  title = {Discourse ?oriented facial displays in conversation},
  journal = {Research on Language and Social Interaction},
  year = {1991},
  volume = {25},
  pages = {163--194},
  number = {1-4},
  month = {\#jan\#},
  keywords = {litsurvey.bib},
  publisher = {Routledge}
}

@INPROCEEDINGS{Chu2010,
  author = {Chu, S and Hsiao, C},
  title = {{{OpenCL}: Make Ubiquitous Supercomputing Possible}},
  booktitle = {2010 {IEEE} 12th International Conference on High Performance Computing
	and Communications ({HPCC})},
  year = {2010},
  pages = {556--561},
  address = {Melbourne},
  month = {\#sep\#},
  publisher = {IEEE},
  abstract = {Due to the dramatic requirements of 3D games and applications, graphics
	processing unit (GPU) or general-purpose graphics processing unit
	(GPGPU) have become required components in the modern computer systems.
	While these devices enable high parallelism with huge amount of processing
	elements, the utilization of their capabilities in general scientific
	applications are still low due to their difficult programming paradigms.
	Therefore an open standard, OpenCL, is proposed to provide universal
	APIs and programming paradigms for various GPUs and accelerators.
	In this study, it adopts several benchmarks, with various computation
	characteristics, to demonstrate the capabilities of OpenCL with several
	platforms. These programs are parallelized by OpenMP and OpenCL,
	and then targeted on several GPUs and conventional servers. This
	paper also provides an example to illustrate the migration of the
	given program, from OpenMP to OpenCL. The presented experimental
	results show that these inexpensive GPUs will lead better performance
	than servers if adopt OpenCL paradigms. It will be the preliminary
	milestone of cheap supercomputing by the acceleration of GPUs that
	can be obtained ubiquitously.},
  keywords = {coprocessors;message passing;multiprocessing systems;parallel machines;parallel
	programming;ubiquitous computing;OpenCL;ubiquitous supercomputing;3D
	games;general-purpose graphics processing unit;programming paradigms;open
	standard;universal API;OpenMP;Computer architecture;Graphics processing
	unit;Instruction sets;Kernel;Microprocessors;Sun;Parallel Programming;OpenCL;OpenMP;GPU;GPGPU;Supercomputing;litsurvey.bib}
}

@INPROCEEDINGS{Ciger2004,
  author = {Ciger, Jan and Herbelin, Bruno and Thalmann, Daniel},
  title = {Evaluation of gaze tracking technology for social interaction in
	virtual environments},
  booktitle = {Proc. of the 2\textbackslashtextsuperscript{nd} Workshop on Modeling
	and Motion Capture Techniques for Virtual Environments ({CAPTECH'04})},
  year = {2004},
  institution = {Citeseer},
  keywords = {litsurvey.bib}
}

@ARTICLE{Clark2013,
  author = {Clark, Chris},
  title = {Bitcoin Internals: A Technical Guide to Bitcoin},
  journal = {Amazon Digital Services},
  year = {2013},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/Bitcoin Internals - Clark, Chris.pdf:PDF}
}

@INPROCEEDINGS{Colburn2000,
  author = {Colburn, Alex and Cohen, Michael F and Drucker, Steven},
  title = {The Role Of Eye Gaze In Avatar Mediated Conversational Interfaces},
  year = {2000},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Conati2014,
  author = {Conati, Cristina and Carenini, Giuseppe and Hoque, Enamul and Steichen,
	Ben and Toker, Dereck},
  title = {Evaluating the impact of user characteristics and different layouts
	on an interactive visualization for decision making},
  booktitle = {Computer Graphics Forum},
  year = {2014},
  volume = {33},
  number = {3},
  pages = {371--380},
  organization = {Wiley Online Library},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/EuroVis14-CameraReady.pdf:PDF}
}

@Article{Cook1977,
  author    = {Cook, Mark},
  journal   = {Am. Sci.},
  title     = {Gaze and mutual gaze in social encounters},
  year      = {1977},
  number    = {3},
  pages     = {328--333},
  volume    = {65},
  abstract  = {Reviews research on gaze and mutual gaze in social interaction and
	discusses techniques of measurement. The perception of different
	patterns is described, as well as the linkage between gaze and speech,
	deviant problems of gaze in psychiatric cases, and cross-cultural
	differences. Data are drawn principally from experimental research,
	but literary and anthropological sources are included where appropriate.
	It is concluded that gaze is one of the main nonverbal signals and
	that knowledge of its uses has important practical implications for
	treatment and training in social skills and for the design of communications
	equipment. (33 ref) (PsycINFO Database Record (c) 2010 APA, all rights
	reserved)},
  keywords  = {eye contact, gaze \& mutual gaze social interaction, interpersonal interaction, literature review, nonverbal communication, research;litsurvey.bib},
  publisher = {Society of the Sigma Xi},
}

@MISC{Cooke_undated,
  author = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
  title = {{IMAGE-BASED} {RENDERING} {FOR} {TELECONFERENCE} {SYSTEMS}},
  keywords = {litsurvey.bib}
}

@ARTICLE{Cooke2002,
  author = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
  title = {Image-based rendering for teleconference systems},
  year = {2002},
  keywords = {litsurvey.bib},
  publisher = {V{\'a}clav Skala-UNION Agency}
}

@INPROCEEDINGS{Cooke2002,
  author = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
  title = {Multiple Narrow-baseline System For Immersive Teleconferencing},
  booktitle = {{Video/Image} Processing and Multimedia Communications 4\textbackslashtextsuperscript{th}
	{EURASIP-IEEE} Region 8 International Symposium on {VIPromCom}},
  year = {2002},
  pages = {367--370},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@MISC{Cooke2002,
  author = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
  title = {Image-based rendering for teleconference systems},
  year = {2002},
  keywords = {litsurvey.bib},
  publisher = {UNION Agency}
}

@INPROCEEDINGS{Cooke2000,
  author = {Cooke, Eddie and Schreer, Oliver and Pasewaldt, Bernhard and Kauff,
	Peter},
  title = {Extension of incomplete 3d for arbitrary multi-view-synthesis},
  booktitle = {{VMV}},
  year = {2000},
  pages = {205--212},
  keywords = {litsurvey.bib}
}

@ARTICLE{Cordeil2016,
  author = {Cordeil, Maxime and Dwyer, Tim and Klein, Karsten and Laha, Bireswar
	and Marriott, Kim and Thomas, Bruce H},
  title = {Immersive collaborative analysis of network connectivity: Cave-style
	or head-mounted display?},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2016},
  volume = {23},
  pages = {441--450},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07539620.pdf:PDF},
  publisher = {IEEE}
}

@MISC{costigan2018world,
  author = {Costigan, Sean S},
  title = {World Without Mind: The Existential Threat of Big Tech (Franklin
	Foer)},
  year = {2018},
  publisher = {Springer}
}

@INPROCEEDINGS{Coughlan2006,
  author = {Coughlan, T and Johnson, P},
  title = {Interaction in creative tasks: Ideation, Representation and Evaluation
	in Composition', paper presented to the},
  booktitle = {Proceedings of the {SIGCHI} conference on Human Factors in computing
	systems},
  year = {2006},
  keywords = {litsurvey.bib}
}

@ARTICLE{Criminisi2007,
  author = {Criminisi, Antonio and Blake, Andrew and Rother, Carsten and Shotton,
	Jamie and Torr, Philip H S},
  title = {Efficient dense stereo with occlusions for new view-synthesis by
	four-state dynamic programming},
  journal = {Int. J. Comput. Vis.},
  year = {2007},
  volume = {71},
  pages = {89--110},
  number = {1},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@ARTICLE{Criminisi2007,
  author = {Criminisi, Antonio and Blake, Andrew and Rother, Carsten and Shotton,
	Jamie and Torr, Philip H S},
  title = {Efficient dense stereo with occlusions for new view-synthesis by
	four-state dynamic programming},
  journal = {Int. J. Comput. Vis.},
  year = {2007},
  volume = {71},
  pages = {89--110},
  number = {1},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@INPROCEEDINGS{Criminisi2003,
  author = {{Criminisi} and {Shotton} and {Blake} and {Torr}},
  title = {{Gaze manipulation for one-to-one teleconferencing}},
  booktitle = {Proceedings Ninth {IEEE} International Conference on Computer Vision},
  year = {2003},
  pages = {191--198 vol.1},
  address = {Nice},
  month = {\#oct\#},
  abstract = {A new algorithm is proposed for novel view generation in one-to-one
	teleconferencing applications. Given the video streams acquired by
	two cameras placed on either side of a computer monitor, the proposed
	algorithm synthesizes images from a virtual camera in arbitrary position
	(typically located within the monitor) to facilitate eye contact.
	Our technique is based on an improved, dynamic-programming, stereo
	algorithm for efficient novel-view generation. The two main contributions
	are: i) a new type of three-plane graph for dense-stereo dynamic-programming,
	that encourages correct occlusion labeling; ii) a compact geometric
	derivation for novel-view synthesis by direct projection of the minimum-cost
	surface. Furthermore, we present a novel algorithm for the temporal
	maintenance of a background model to enhance the rendering of occlusions
	and reduce temporal artefacts (flicker); and a cost aggregation algorithm
	that acts directly on our three-dimensional matching cost space.
	Examples are given that demonstrate the robustness of the new algorithm
	to spatial and temporal artefacts for long stereo video streams.
	These include demonstrations of synthesis of cyclopean views of extended
	conversational sequences. We further demonstrate synthesis from a
	freely translating virtual camera.},
  keywords = {teleconferencing;video coding;video cameras;dynamic programming;rendering
	(computer graphics);image sequences;image matching;hidden feature
	removal;computational geometry;gaze manipulation;one-to-one teleconferencing;video
	stream;virtual camera;novel-view generation;three-plane graph;dense-stereo
	dynamic-programming;occlusion labeling;minimum-cost surface;background
	model temporal maintenance;cost aggregation algorithm;three-dimensional
	matching cost space;spatial artefact;temporal artefact;cyclopean
	view synthesis;conversational sequence;Teleconferencing;Cameras;Streaming
	media;Costs;Application software;Computer displays;Computerized monitoring;Heuristic
	algorithms;Labeling;Robustness;litsurvey.bib}
}

@PHDTHESIS{Cruz-Neira1995,
  author = {Cruz-Neira, Carolina},
  title = {{Virtual reality based on multiple projection screens: the cave and
	its applications to computational science and engineering}},
  school = {University of Illinois, Chicago},
  year = {1995},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Cuddihy2000,
  author = {Cuddihy, Elisabeth and Walters, Deborah},
  title = {Embodied interaction in social virtual environments},
  booktitle = {Proceedings of the third international conference on Collaborative
	virtual environments},
  year = {2000},
  series = {CVE '00},
  pages = {181--188},
  address = {New York, NY, USA},
  month = {\#sep\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {interactivity models, user interface, presence, embodiment;litsurvey.bib},
  location = {San Francisco, California, USA}
}

@ARTICLE{Daas2015,
  author = {Daas, Piet JH and Puts, Marco J and Buelens, Bart and van den Hurk,
	Paul AM},
  title = {Big data as a source for official statistics},
  journal = {Journal of Official Statistics},
  year = {2015},
  volume = {31},
  pages = {249--262},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/[Journal of Official Statistics] Big Data as a.pdf:PDF},
  publisher = {De Gruyter Open}
}

@ARTICLE{dai1998b,
  author = {Dai, Wei},
  title = {b-money, 1998},
  journal = {URL http://www. weidai. com/bmoney. txt.(Last access: 08.04. 2019)},
  year = {1998}
}

@INPROCEEDINGS{Dalsgaard2011,
  author = {Dalsgaard, Peter and Halskov, Kim},
  title = {3d projection on physical objects: design insights from five real
	life cases},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {1041--1050},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {visual effects, exhibitions, architecture, design, augmented reality,
	projection, cultural heritage, 3d;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@ARTICLE{Darken2003,
  author = {Darken, Rudolph P and Sullivan, Joseph A and Lennerton, Mark},
  title = {A chromakey augmented virtual environment for deployable training},
  year = {2003},
  keywords = {litsurvey.bib}
}

@BOOK{Davies2004,
  title = {{Machine vision: theory, algorithms, practicalities}},
  publisher = {Elsevier},
  year = {2004},
  author = {Davies, E R},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Debevec1996,
  author = {Debevec, Paul E and Taylor, Camillo J and Malik, Jitendra},
  title = {{Modeling and rendering architecture from photographs: a hybrid geometry-
	and image-based approach}},
  booktitle = {Proceedings of the 23rd annual conference on Computer graphics and
	interactive techniques},
  year = {1996},
  series = {SIGGRAPH '96},
  pages = {11--20},
  address = {New York, NY, USA},
  month = {\#aug\#},
  publisher = {Association for Computing Machinery},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Deckers2011,
  author = {Deckers, Eva and Wensveen, Stephan and Ahn, Rene and Overbeeke, Kees},
  title = {Designing for perceptual crossing to improve user involvement},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {1929--1938},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {research through design, designing for perceptual crossing, phenomenology;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@INPROCEEDINGS{Deckers2013,
  author = {Deckers, Eva and Wensveen, Stephan and Levy, Pierre and Ahn, Rene},
  title = {Designing for perceptual crossing: designing and comparing three
	behaviors},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {1901--1910},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {perceptual crossing, perceptive qualities, product behavior, research
	through design, design theory, phenomenology;litsurvey.bib},
  location = {Paris, France}
}

@ARTICLE{Delaunay1934,
  author = {Delaunay, B},
  title = {{Sur la sphere vide}},
  journal = {Biol. Bull. Acad. Sci. USSR},
  year = {1934},
  volume = {6},
  pages = {793--800},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Dennis1990,
  author = {Dennis, Alan R and Easton, Annette C and Easton, George K and George,
	Joey F and Nunamaker, J F},
  title = {Ad hoc versus established groups in an electronic meeting system
	environment},
  booktitle = {System Sciences, 1990., Proceedings of the {Twenty-Third} Annual
	Hawaii International Conference on},
  year = {1990},
  volume = {3},
  pages = {23--29},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@ARTICLE{Denstadli2012,
  author = {Denstadli, Jon Martin and Julsrud, Tom Erik and Hjorthol, Randi Johanne},
  title = {Videoconferencing as a mode of communication: A comparative study
	of the use of videoconferencing and face-to-face meetings},
  journal = {Journal of Business and Technical Communication},
  year = {2012},
  volume = {26},
  pages = {65--91},
  number = {1},
  keywords = {litsurvey.bib},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@INPROCEEDINGS{Desai2011,
  author = {Desai, M and Tsui, K M and Yanco, H A and Uhlik, C},
  title = {Essential features of telepresence robots},
  booktitle = {2011 {IEEE} Conference on Technologies for Practical Robot Applications},
  year = {2011},
  pages = {15--20},
  month = {\#apr\#},
  abstract = {Telepresence robots are mobile robot platforms capable of providing
	two way audio and video communication. Recently there has been a
	surge in companies designing telepresence robots. We conducted a
	series of user studies at Google in Mountain View with two different
	commercially available telepresence robots. Based on the data collected
	from these user studies, we present a set of guidelines for designing
	telepresence robots. These essential guidelines pertain to video,
	audio, user interface, physical features, and autonomous behaviors.},
  institution = {IEEE},
  keywords = {mobile robots;teleconferencing;telerobotics;user interfaces;video
	communication;virtual reality;telepresence robots;mobile robot;audio
	communication;video communication;Google;Mountain View;user interface;physical
	features;autonomous behaviors;Legged locomotion;Driver circuits;Cameras;Navigation;Robot
	vision systems;litsurvey.bib}
}

@ARTICLE{diffie1976new,
  author = {Diffie, Whitfield and Hellman, Martin},
  title = {New directions in cryptography},
  journal = {IEEE transactions on Information Theory},
  year = {1976},
  volume = {22},
  pages = {644--654},
  number = {6},
  publisher = {IEEE}
}

@ARTICLE{dimara2017conceptual,
  author = {Dimara, Evanthia and Bezerianos, Anastasia and Dragicevic, Pierre},
  title = {Conceptual and methodological issues in evaluating multidimensional
	visualizations for decision support},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year = {2017},
  volume = {24},
  pages = {749--759},
  number = {1},
  file = {:../../../literature_repository/Data Visualisation/08019855.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Ding2007,
  author = {Ding, Xianghua and Erickson, Thomas and Kellogg, Wendy A and Levy,
	Stephen and Christensen, James E and Sussman, Jeremy and Wolf, Tracee
	Vetting and Bennett, William E},
  title = {An empirical study of the use of visually enhanced voip audio conferencing:
	the case of {IEAC}},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {1019--1028},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {social proxy, conference call, social visualization, voice, social
	translucence, VoIP, telephony, audio conferencing;litsurvey.bib},
  location = {San Jose, California, USA}
}

@ARTICLE{Dinov2016,
  author = {Dinov, Ivo D and Heavner, Ben and Tang, Ming and Glusman, Gustavo
	and Chard, Kyle and Darcy, Mike and Madduri, Ravi and Pa, Judy and
	Spino, Cathie and Kesselman, Carl and others},
  title = {Predictive big data analytics: a study of Parkinson’s disease using
	large, complex, heterogeneous, incongruent, multi-source and incomplete
	observations},
  journal = {PloS one},
  year = {2016},
  volume = {11},
  pages = {e0157077},
  number = {8},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Study of parkinsions disease.pdf:PDF},
  publisher = {Public Library of Science}
}

@INPROCEEDINGS{Divorra2010,
  author = {Divorra, O and Civit, Jaume and Zuo, F and Belt, H and Feldmann,
	I and Chreer, O and Yellin, E and Ijsselsteijn, W and van Eijk, R
	and Espinola, D and {Others}},
  title = {Towards 3D-aware telepresence: Working on technologies behind the
	scene},
  year = {2010},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Dodds2008,
  author = {Dodds, T J and Ruddle, R A},
  title = {Mobile Group Dynamics in {Large-Scale} Collaborative Virtual Environments},
  booktitle = {2008 {IEEE} Virtual Reality Conference},
  year = {2008},
  pages = {59--66},
  month = {\#mar\#},
  abstract = {We have developed techniques called mobile group dynamics (MGDs),
	which help groups of people to work together while they travel around
	large-scale virtual environments. MGDs explicitly showed the groups
	that people had formed themselves into, and helped people move around
	together and communicate over extended distances. The techniques
	were evaluated in the context of an urban planning application, by
	providing one batch of participants with MGDs and another with an
	interface based on conventional collaborative virtual environments
	(CVEs). Participants with MGDs spent nearly twice as much time in
	close proximity (within 10m of their nearest neighbor), communicated
	seven times more than participants with a conventional interface,
	and exhibited real-world patterns of behavior such as staying together
	over an extended period of time and regrouping after periods of separation.
	The study has implications for CVE designers, because it shows how
	MGDs improves groupwork in CVEs.},
  institution = {IEEE},
  keywords = {groupware;mobile computing;virtual reality;mobile group dynamics;large-scale
	collaborative virtual environments;urban planning;collaborative interaction;Large-scale
	systems;Collaboration;Virtual environment;Collaborative work;Virtual
	reality;Collaborative software;Computer interfaces;Computer networks;Distributed
	computing;Mobile computing;Collaborative interaction;experimental
	methods;distributed VR;usability;C.2.4 [Computer-Computer Communication
	Networks]: Distributed Systems\?\`Distributed applications;H.1.2
	[Models and Principles]: User/Machine Systems\?\`Human factors;Software
	psychology;H.5.1 [Information Interfaces and Presentation]: Multimedia
	Information Systems\?\`Artificial, augmented and virtual realities;H.5.3
	[Information Interfaces and Presentation]: Group and Organization
	Interfaces\?\`Collaborative computing;Computer-supported cooperative
	work;Synchronous interaction;I.3.7 [Computer Graphics]: Three Dimensional
	Graphics and Realism\?\`Virtual Reality;litsurvey.bib}
}

@INPROCEEDINGS{Doleisch2003,
  author = {Doleisch, Helmut and Gasser, Martin and Hauser, Helwig},
  title = {Interactive feature specification for focus+ context visualization
	of complex simulation data},
  booktitle = {VisSym},
  year = {2003},
  volume = {3},
  pages = {239--248},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Interactive Feature Specication for Focus+Cont.pdf:PDF}
}

@ARTICLE{Doleisch2002,
  author = {Doleisch, Helmut and Hauser, Helwig},
  title = {Smooth brushing for focus+ context visualization of simulkation data
	in 3D},
  year = {2002},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/SMOOTH BRUSHING FOR FOCUS + CONTEXT VISUALIZAT.pdf:PDF},
  publisher = {UNION Agency}
}

@ARTICLE{Dolling2019,
  author = {Dolling, Carmen},
  title = {Visualizing US Animal Shelter Outcomes},
  year = {2019},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/carmendolling.pdf:PDF}
}

@UNPUBLISHED{Dou2016,
  author = {Dou, Mingsong and Khamis, Sameh and Degtyarev, Yury and Davidson,
	Philip and Fanello, Sean Ryan and Kowdle, Adarsh and Escolano, Sergio
	Orts and Rhemann, Christoph and Kim, David and Taylor, Jonathan and
	Kohli, Pushmeet and Tankovich, Vladimir and Izadi, Shahram},
  title = {{Fusion4D}: real-time performance capture of challenging scenes},
  month = {\#jul\#},
  year = {2016},
  keywords = {4D reconstruction, real-time, nonrigid, multi-view;litsurvey.bib},
  number = {Article 114}
}

@ARTICLE{Dourish1996,
  author = {Dourish, Paul and Adler, Annette and Bellotti, Victoria and Henderson,
	Austin},
  title = {Your place or mine? Learning from long-term use of {Audio-Video}
	communication},
  journal = {Comput. Support. Coop. Work},
  year = {1996},
  volume = {5},
  pages = {33--62},
  number = {1},
  month = {\#mar\#},
  abstract = {Workstations and personal computers are increasingly being delivered
	with the ability to handle multimedia data; more and more of us are
	linked by high-speed digital networks. With multimedia communication
	environments becoming more commonplace, what have we learned from
	earlier experiences with prototype media environments? This paper
	reports on some of our experiences as developers, researchers and
	users of flexible, networked, multimedia computer environments, or
	``media spaces''. It focusses on the lessons we can learn from extended,
	long-term use of media spaces, with connections that last not hours
	or days, but months or years. We take as our starting point a set
	of assumptions which differ from traditional analytical perspectives.
	In particular, we begin from the position that that real-world baseline
	is not always an appropriate point of comparison for new media technologies;
	that a set of complex and intricate communicative behaviours arise
	over time; and that media spaces connect not only individuals, but
	the wider social groups of which they form part. We outline a framework
	based on four perspectives --- individual, interactional, communal
	and societal --- from which to view the behaviour of individuals
	and groups linked by multimedia environments. On the basis of our
	long-term findings, we argue for a view of media spaces which, first,
	focuses on a wider interpretation of media space interaction than
	the traditional view of person-to-person connections, and, second,
	emphasises emergent communicative practices, rather than looking
	for the transfer of face-to-face behaviours.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Du2017,
  author = {Du, Yuheng and Herzog, Alexander and Luckow, Andre and Nerella, Ramu
	and Gropp, Christopher and Apon, Amy},
  title = {Representativeness of latent dirichlet allocation topics estimated
	from data samples with application to common crawl},
  booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
  year = {2017},
  pages = {1418--1427},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Representativeness of Latent Dirichlet Allocat.pdf:PDF}
}

@ARTICLE{Duckworth2014,
  author = {Duckworth, Tobias and Roberts, David J},
  title = {Parallel processing for real-time {3D} reconstruction from video
	streams},
  journal = {Journal of real-time image processing},
  year = {2014},
  volume = {9},
  pages = {427--445},
  number = {3},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@ARTICLE{Duckworth2012,
  author = {Duckworth, Tobias and Roberts, David J},
  title = {{3DRecon}, a utility for {3D} reconstruction from video},
  journal = {Joint Virtual Conference of ICAT - EGVE - EuroVR (JVRC '12)},
  year = {2012},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Duckworth2011,
  author = {Duckworth, T and Roberts, D J},
  title = {Accelerated polyhedral visual hulls using {OpenCL}},
  booktitle = {2011 {IEEE} Virtual Reality Conference},
  year = {2011},
  pages = {203--204},
  address = {Singapore},
  month = {\#mar\#},
  abstract = {We present a method for reconstruction of the visual hull (VH) of
	an object in real-time from multiple video streams. A state of the
	art polyhedral reconstruction algorithm is accelerated by implementing
	it for parallel execution on a multi-core graphics processor (GPU).
	The time taken to reconstruct the VH is measured for both the accelerated
	and non-accelerated implementations of the algorithm, over a range
	of image resolutions and number of cameras. The results presented
	are of relevance to researchers in the field of 3D reconstruction
	at interactive frame rates (real-time), for applications such as
	telepresence.},
  keywords = {computer graphic equipment;coprocessors;image reconstruction;video
	signal processing;virtual reality;polyhedral visual hull;visual hull
	reconstruction;video streams;polyhedral reconstruction algorithm;multicore
	graphics processor;graphics processing unit;image resolution;3D reconstruction;telepresence
	application;Cameras;Three dimensional displays;Image edge detection;Graphics
	processing unit;Solid modeling;Visualization;Image resolution;Reconstruction
	algorithms;Parallel processing;Virtual reality;litsurvey.bib}
}

@INPROCEEDINGS{Duckworth2011,
  author = {Duckworth, T and Roberts, D J},
  title = {Camera Image Synchronisation in Multiple Camera {Real-Time} {3D}
	Reconstruction of Moving Humans},
  booktitle = {2011 {IEEE/ACM} 15th International Symposium on Distributed Simulation
	and Real Time Applications},
  year = {2011},
  pages = {138--144},
  address = {Salford},
  month = {\#sep\#},
  publisher = {IEEE Computer Society},
  abstract = {We present an analysis of the requirement for input synchronisation
	in a multi-camera 3D reconstruction system for real-time applications
	such as telepresence.{\^A} Synchronisation of the cameras at the
	acquisition stage is universally used to ensure the images feeding
	the reconstruction algorithm were taken at the same time.{\^A} However,
	this requirement adds delays to the reconstruction pipeline, therefore
	increasing the end to end latency of the system.{\^A} While this
	has not been a significant problem for many of the applications of
	3D reconstruction, it is for its application to tele-presence. Furthermore,
	synchronising the firing of cameras adds much financial cost to the
	system. Using real camera images of moving humans, we study the effect
	removing synchronisation has on the output reconstructed model over
	a range of camera configurations and relative frame delays.{\^A}
	From this we determine the synchronisation requirements for a 3D
	reconstruction telepresence system in terms of the maximum time between
	camera frames that gives rise to acceptable results.},
  keywords = {image reconstruction;image sensors;telecontrol;virtual reality;camera
	image synchronisation;multiple camera real-time 3D reconstruction
	system;3D reconstruction telepresence system;input synchronisation;reconstruction
	pipeline;camera frames;Cameras;Synchronization;Image reconstruction;Three
	dimensional displays;Delay;Visualization;Shape;Tele-immersion;telepresence;3D
	reconstruction;synchronization;litsurvey.bib}
}

@ARTICLE{Duffy2010,
  author = {Duffy, Christine and McEuen, Mary Beth},
  title = {The future of meetings: the case for face-to-face},
  year = {2010},
  keywords = {litsurvey.bib}
}

@ARTICLE{Dyck2008,
  author = {Dyck, Miriam and Winbeck, Maren and Leiberg, Susanne and Chen, Yuhan
	and Gur, Ruben C and Mathiak, Klaus},
  title = {Recognition profile of emotions in natural and virtual faces},
  journal = {PLoS One},
  year = {2008},
  volume = {3},
  pages = {e3628},
  number = {11},
  month = {\#nov\#},
  abstract = {BACKGROUND: Computer-generated virtual faces become increasingly realistic
	including the simulation of emotional expressions. These faces can
	be used as well-controlled, realistic and dynamic stimuli in emotion
	research. However, the validity of virtual facial expressions in
	comparison to natural emotion displays still needs to be shown for
	the different emotions and different age groups. METHODOLOGY/PRINCIPAL
	FINDINGS: Thirty-two healthy volunteers between the age of 20 and
	60 rated pictures of natural human faces and faces of virtual characters
	(avatars) with respect to the expressed emotions: happiness, sadness,
	anger, fear, disgust, and neutral. Results indicate that virtual
	emotions were recognized comparable to natural ones. Recognition
	differences in virtual and natural faces depended on specific emotions:
	whereas disgust was difficult to convey with the current avatar technology,
	virtual sadness and fear achieved better recognition results than
	natural faces. Furthermore, emotion recognition rates decreased for
	virtual but not natural faces in participants over the age of 40.
	This specific age effect suggests that media exposure has an influence
	on emotion recognition. CONCLUSIONS/SIGNIFICANCE: Virtual and natural
	facial displays of emotion may be equally effective. Improved technology
	(e.g. better modelling of the naso-labial area) may lead to even
	better results as compared to trained actors. Due to the ease with
	which virtual human faces can be animated and manipulated, validated
	artificial emotional expressions will be of major relevance in future
	research and therapeutic applications.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Public Library of Science}
}

@INPROCEEDINGS{Edigo1988,
  author = {Edigo, C},
  title = {Videoconferencing as a technology to support group work: A review
	of its failure},
  booktitle = {Proceedings of the {ACM} conf. on {Computer-Supported} Cooperative
	Work},
  year = {1988},
  keywords = {litsurvey.bib}
}

@ARTICLE{egger2017htc,
  author = {Egger, Jan and Gall, Markus and Wallner, J{\"u}rgen and Boechat,
	Pedro and Hann, Alexander and Li, Xing and Chen, Xiaojun and Schmalstieg,
	Dieter},
  title = {HTC Vive MeVisLab integration via OpenVR for medical applications},
  journal = {PloS one},
  year = {2017},
  volume = {12},
  pages = {e0173972},
  number = {3},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/volumeMedical/pone.0173972.pdf:PDF},
  publisher = {Public Library of Science}
}

@ARTICLE{Ehsan2017,
  author = {Ehsan, Humaira and Sharaf, Mohamed A and Chrysanthis, Panos K},
  title = {Efficient recommendation of aggregate data visualizations},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year = {2017},
  volume = {30},
  pages = {263--277},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08081825.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Van_Eijk2010,
  author = {van Eijk, R and Kuijsters, A and Dijkstra, K and IJsselsteijn, W
	A},
  title = {Human sensitivity to eye contact in {2D} and {3D} videoconferencing},
  booktitle = {2010 Second International Workshop on Quality of Multimedia Experience
	({QoMEX})},
  year = {2010},
  pages = {76--81},
  month = {\#jun\#},
  abstract = {Gaze awareness and eye contact serve important functions in social
	interaction. In order to maintain those functions in 2D and 3D videoconferencing
	systems, human sensitivity to eye contact and gaze direction needs
	to be taken into account in the design of such systems. Here we experimentally
	investigate human perception of eye contact and gaze direction in
	2D and 3D, using a within-subjects design. Our results indicate that
	the disparity between the optical axis of the camera and the looking
	direction of a looker (a photographed face) should be at most 1.2°
	in horizontal direction, and 1.7° in vertical direction to support
	eye contact. Maximum tolerable offsets for the perception of eye
	contact are independent of (monoscopic or stereoscopic) display conditions.
	Asymmetric sensitivity to eye contact is explained by the underestimation
	of the vertical component of a looker's gaze direction.},
  institution = {IEEE},
  keywords = {teleconferencing;video communication;visual perception;human sensitivity;2D
	videoconferencing;3D videoconferencing;gaze awareness;eye contact
	perception;within-subject design;camera optical axis;looking direction;looker
	gaze direction;Humans;Teleconferencing;Cameras;Optical sensors;Eyes;Displays;Games;Industrial
	engineering;Technological innovation;Optical feedback;Eye contact;gaze
	direction;perception;3D;videoconferencing;litsurvey.bib}
}

@INPROCEEDINGS{Eisemann2008,
  author = {Eisemann, Martin and De Decker, Bert and Magnor, Marcus and Bekaert,
	Philippe and De Aguiar, Edilson and Ahmed, Naveed and Theobalt, Christian
	and Sellent, Anita},
  title = {Floating textures},
  booktitle = {Computer Graphics Forum},
  year = {2008},
  volume = {27},
  pages = {409--418},
  institution = {Wiley Online Library},
  keywords = {litsurvey.bib}
}

@ARTICLE{Eisenbart2016,
  author = {Eisenbart, Boris and Garbuio, Massimo and Mascia, Daniele and Morandi,
	Federica},
  title = {Does scheduling matter? When unscheduled decision making results
	in more effective meetings},
  journal = {Journal of Strategy and Management},
  year = {2016},
  volume = {9},
  pages = {15--38},
  number = {1},
  month = {\#jan\#},
  abstract = {Purpose-- Managers spend a great deal of time in meetings making decisions
	critical to organisational success, yet the design aspects of meetings
	remain largely understudied. The purpose of this paper is to elaborate
	on the potential impact of one critical design aspect of meetings
	-- namely, whether a decision to be taken (or the meeting in general)
	was scheduled or not -- on the use of distributed information, information
	elaboration, conflict, speed of decision making, and, ultimately,
	decision-making effectiveness. Design/methodology/approach-- The
	research presented in this paper combines a literature review with
	empirical data obtained from questionnaires and direct observation
	of decision making meetings on organisational issues in a hospital.
	One meeting was scheduled, the other two were unscheduled. A second
	questionnaire was administered 12 months after the respective decision
	making meetings to explore and evaluate the efficiency of the decisions
	made and their implementation. Findings-- This paper suggests that
	a scheduled meeting with a shared agenda of all decisions to be taken
	may induce decision makers to form opinions upfront at the meeting,
	with these opinions eventually serving as sources of conflict during
	group discussion. Because of the nature of the conflict generated,
	these meetings are more likely to run long and to not deliver the
	expected outcomes. Originality/value-- The study contributes to the
	debate on group decision-making processes by examining the effect
	of meeting scheduling on information elaboration and conflict in
	real-world decision-making settings. Although robust evidence has
	supported the existence of relationships between information elaboration,
	conflict, and decision-making effectiveness, previous studies have
	mainly focused on the effects of these processes during scheduled
	meetings and experimental settings. The findings of the present study
	show the effect of meeting scheduling on decision-making effectiveness
	in real-world settings.},
  keywords = {litsurvey.bib},
  publisher = {Emerald Group Publishing Limited}
}

@ARTICLE{Ekman1993,
  author = {Ekman, P},
  title = {Facial expression and emotion},
  journal = {Am. Psychol.},
  year = {1993},
  volume = {48},
  pages = {384--392},
  number = {4},
  month = {\#apr\#},
  abstract = {Cross-cultural research on facial expression and the developments
	of methods to measure facial expression are briefly summarized. What
	has been learned about emotion from this work on the face is then
	elucidated. Four questions about facial expression and emotion are
	discussed: What information does an expression typically convey?
	Can there be emotion without facial expression? Can there be a facial
	expression of emotion without emotion? How do individuals differ
	in their facial expressions of emotion?},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {American Psychological Association}
}

@ARTICLE{Eldes2013,
  author = {Eldes, Osman and Ak{\c s}it, Kaan and Urey, Hakan},
  title = {Multi-view autostereoscopic projection display using rotating screen},
  journal = {Opt. Express},
  year = {2013},
  volume = {21},
  pages = {29043--29054},
  number = {23},
  month = {\#nov\#},
  abstract = {A new technique for multi-view autostereoscopic projection display
	is proposed, and demonstrated. The technique uses two mobile projectors,
	a rotating retro-reflective diffuser screen, and a head-tracking
	camera. As two dynamic viewing slits are created at the viewer's
	position, the slits can track the position of the eyes by rotating
	the screen. The display allows a viewer to move approximately 700
	mm along the horizontal axis, and 500 mm along the vertical axis
	with an average crosstalk below 5 \%. Two screen prototypes with
	different diffusers have been tried, and they provide luminance levels
	of 60 Cd/m2, and 160 Cd/m2 within the viewing field.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Optical Society of America}
}

@ARTICLE{Engle1987,
  author = {Engle, Robert F and Granger, Clive WJ},
  title = {Co-integration and error correction: representation, estimation,
	and testing},
  journal = {Econometrica: journal of the Econometric Society},
  year = {1987},
  pages = {251--276},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/1913236.pdf:PDF},
  publisher = {JSTOR}
}

@INPROCEEDINGS{Erickson2010,
  author = {Erickson, Thomas and Kellogg, W A},
  title = {Telepresence in Virtual Conferences: An Empirical Comparison of Distance
	Collaboration Technologies},
  year = {2010},
  pages = {1--6},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Erickson2011,
  author = {Erickson, Thomas and Shami, N Sadat and Kellogg, Wendy A and Levine,
	David W},
  title = {Synchronous interaction among hundreds: an evaluation of a conference
	in an avatar-based virtual environment},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {503--512},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {collaborative virtual environment, synchronous interaction, virtual
	world, spatialized audio, CVE, virtual conference, CMC, second life;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@INPROCEEDINGS{Ess2008,
  author = {Ess, A and Leibe, B and Schindler, K and Van Gool, L},
  title = {A mobile vision system for robust multi-person tracking},
  booktitle = {2008 {IEEE} Conference on Computer Vision and Pattern Recognition},
  year = {2008},
  pages = {1--8},
  month = {\#jun\#},
  abstract = {We present a mobile vision system for multi-person tracking in busy
	environments. Specifically, the system integrates continuous visual
	odometry computation with tracking-by-detection in order to track
	pedestrians in spite of frequent occlusions and egomotion of the
	camera rig. To achieve reliable performance under real-world conditions,
	it has long been advocated to extract and combine as much visual
	information as possible. We propose a way to closely integrate the
	vision modules for visual odometry, pedestrian detection, depth estimation,
	and tracking. The integration naturally leads to several cognitive
	feedback loops between the modules. Among others, we propose a novel
	feedback connection from the object detector to visual odometry which
	utilizes the semantic knowledge of detection to stabilize localization.
	Feedback loops always carry the danger that erroneous feedback from
	one module is amplified and causes the entire system to become instable.
	We therefore incorporate automatic failure detection and recovery,
	allowing the system to continue when a module becomes unreliable.
	The approach is experimentally evaluated on several long and difficult
	video sequences from busy inner-city locations. Our results show
	that the proposed integration makes it possible to deliver stable
	tracking performance in scenes of previously infeasible complexity.},
  keywords = {computer vision;feedback;image sequences;tracking;video signal processing;mobile
	vision system;multiperson tracking;continuous visual odometry computation;tracking-by-detection;pedestrian
	tracking;egomotion;camera rig;pedestrian detection;depth estimation;cognitive
	feedback loops;automatic failure detection;video sequences;Machine
	vision;Layout;Feedback loop;Object detection;Mobile robots;Noise
	robustness;Cameras;Data mining;Detectors;Video sequences;litsurvey.bib}
}

@ARTICLE{Esteban2002,
  author = {Esteban, C H and Schmitt, F},
  title = {{Multi-stereo 3d object reconstruction}},
  journal = {International Symposium on 3D Processing, Visualization, and Transmission
	(3DPVT '02)},
  year = {2002},
  pages = {159--166},
  keywords = {litsurvey.bib}
}

@ARTICLE{faccia2019accounting,
  author = {Faccia, Alessio and Mosteanu, Narcisa Roxana},
  title = {Accounting and blockchain technology: from double-entry to triple-entry},
  journal = {The Business \& Management Review},
  year = {2019},
  volume = {10},
  pages = {108--116},
  number = {2},
  publisher = {Centre for Business \& Economic Research}
}

@INPROCEEDINGS{Fagel2010,
  author = {Fagel, Sascha and Bailly, G{\'e}rard and Elisei, Fr{\'e}d{\'e}ric
	and Lelong, Am{\'e}lie},
  title = {On the importance of eye gaze in a face-to-face collaborative task},
  booktitle = {Proceedings of the 3rd international workshop on Affective interaction
	in natural environments},
  year = {2010},
  series = {AFFINE '10},
  pages = {81--86},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {face-to-face interaction, head motion, eye gaze;litsurvey.bib},
  location = {Firenze, Italy}
}

@ARTICLE{Fairchild2017,
  author = {Fairchild, A J and Campion, S P and Garc{\'\i}a, A S and Wolff, R
	and Fernando, T and Roberts, D J},
  title = {A Mixed Reality Telepresence System for Collaborative Space Operation},
  journal = {IEEE Trans. Circuits Syst. Video Technol.},
  year = {2017},
  volume = {27},
  pages = {814--827},
  number = {4},
  month = {\#apr\#},
  abstract = {This paper presents a mixed reality (MR) system that results from
	the integration of a telepresence system and an application to improve
	collaborative space exploration. The system combines free viewpoint
	video with immersive projection technology to support nonverbal communication
	(NVC), including eye gaze, interpersonal distance, and facial expression.
	Importantly, these features can be interpreted together as people
	move around the simulation, maintaining a natural social distance.
	The application is a simulation of Mars, within which the collaborators
	must come to agreement over; for example, where the Rover should
	land and go. The first contribution is the creation of an MR system
	supporting contextualization of NVC. Two technological contributions
	are prototyping a technique to subtract a person from a background
	that may contain physical objects and/or moving images and a lightweight
	texturing method for multiview rendering, which provides balance
	in terms of visual and temporal quality. A practical contribution
	is the demonstration of pragmatic approaches to sharing space between
	display systems of distinct levels of immersion. A research tool
	contribution is a system that allows comparison of conventional authored
	and video-based reconstructed avatars, within an environment that
	encourages exploration and social interaction. Aspects of system
	quality, including the communication of facial expression and end-to-end
	latency are reported.},
  keywords = {aerospace computing;avatars;digital simulation;face recognition;feature
	extraction;gaze tracking;groupware;image texture;rendering (computer
	graphics);space research;video signal processing;mixed reality telepresence
	system;collaborative space exploration improvement;free viewpoint
	video;immersive projection technology;nonverbal communication;NVC;eye
	gaze;interpersonal distance;facial expression;Mars simulation;MR
	system;moving images;lightweight texturing method;multiview rendering;temporal
	quality;visual quality;display systems;video-based reconstructed
	avatars;social interaction;end-to-end latency;Three-dimensional displays;Virtual
	reality;Space exploration;Rendering (computer graphics);Space research;Collaborative
	work;3D video-based reconstruction;background-foreground segmentation;computer-supported
	collaborative work;mixed reality (MR);space science;telepresence;litsurvey.bib},
  publisher = {IEEE}
}

@ARTICLE{Fairchild2017,
  author = {Fairchild, A J and Campion, S P and Garc{\'\i}a, A S and Wolff, R
	and Fernando, T and Roberts, D J},
  title = {A Mixed Reality Telepresence System for Collaborative Space Operation},
  journal = {IEEE Trans. Circuits Syst. Video Technol.},
  year = {2017},
  volume = {27},
  pages = {814--827},
  number = {4},
  month = {\#apr\#},
  abstract = {This paper presents a mixed reality (MR) system that results from
	the integration of a telepresence system and an application to improve
	collaborative space exploration. The system combines free viewpoint
	video with immersive projection technology to support nonverbal communication
	(NVC), including eye gaze, interpersonal distance, and facial expression.
	Importantly, these features can be interpreted together as people
	move around the simulation, maintaining a natural social distance.
	The application is a simulation of Mars, within which the collaborators
	must come to agreement over; for example, where the Rover should
	land and go. The first contribution is the creation of an MR system
	supporting contextualization of NVC. Two technological contributions
	are prototyping a technique to subtract a person from a background
	that may contain physical objects and/or moving images and a lightweight
	texturing method for multiview rendering, which provides balance
	in terms of visual and temporal quality. A practical contribution
	is the demonstration of pragmatic approaches to sharing space between
	display systems of distinct levels of immersion. A research tool
	contribution is a system that allows comparison of conventional authored
	and video-based reconstructed avatars, within an environment that
	encourages exploration and social interaction. Aspects of system
	quality, including the communication of facial expression and end-to-end
	latency are reported.},
  keywords = {aerospace computing;avatars;digital simulation;face recognition;feature
	extraction;gaze tracking;groupware;image texture;rendering (computer
	graphics);space research;video signal processing;mixed reality telepresence
	system;collaborative space exploration improvement;free viewpoint
	video;immersive projection technology;nonverbal communication;NVC;eye
	gaze;interpersonal distance;facial expression;Mars simulation;MR
	system;moving images;lightweight texturing method;multiview rendering;temporal
	quality;visual quality;display systems;video-based reconstructed
	avatars;social interaction;end-to-end latency;Three-dimensional displays;Virtual
	reality;Space exploration;Rendering (computer graphics);Space research;Collaborative
	work;3D video-based reconstruction;background-foreground segmentation;computer-supported
	collaborative work;mixed reality (MR);space science;telepresence;litsurvey.bib},
  publisher = {IEEE}
}

@Other{Fan,
  abstract   = {Journal of Visualization, https://doi.org/10.1007/s12650-018-0525-z},
  author     = {Xin Fan and Chenlu Li and Xiaoju Dong},
  doi        = {10.1007/s12650-018-0525-z},
  file       = {:C\:/Users/its352/Docear/projects/Big data/literature_repository/Data Visuaisation/s12650-018-0525-z.pdf:PDF},
  keywords   = {Real-time analysis, Network security visualization, Machine learning, Incremental learning, Pattern recognition},
  publishers = {Springer Berlin Heidelberg},
  title      = {A real-time network security visualization system based on incremental learning (ChinaVis 2018)},
}

@MISC{Fastcompany2020,
  author = {{Fastcompany}},
  title = {Why working from home might be here to stay},
  howpublished = {\url{https://www.fastcompany.com/90480501/the-incredibly-simple-reason-working-from-home-could-be-here-to-stay}},
  year = {2020},
  keywords = {litsurvey.bib}
}

@BOOK{Faugeras2001,
  title = {{The Geometry of Multiple Images: The Laws That Govern The Formation
	of Images of A Scene and Some of Their Applications}},
  publisher = {MIT Press},
  year = {2001},
  author = {Faugeras, Olivier and Luong, Quang-Tuan and Papadopoulou, T},
  keywords = {litsurvey.bib}
}

@ARTICLE{Faugeras1984,
  author = {Faugeras, O D and Hebert, M and Mussi, P and Boissonnat, J D},
  title = {{Polyhedral approximation of {3-D} objects without holes}},
  journal = {Computer Vision, Graphics, and Image Processing},
  year = {1984},
  volume = {25},
  pages = {169--183},
  number = {2},
  month = {\#feb\#},
  abstract = {An efficient way of building a polyhedral approximation of a set of
	points in 3-D space is described. The points are the vertices of
	a planar graph embedded in a surface of genus 0 and are obtained
	by a laser range finder. The technique presented here is a generalization
	of an existing algorithm (R. Duda and P. Hart, Pattern Classification
	and Scene Analysis, Wiley-Interscience, New York 1973) for the polygonal
	approximation of a simple curve in 2-D space.},
  keywords = {litsurvey.bib}
}

@ARTICLE{Fayard2007,
  author = {Fayard, Anne-Laure and Weeks, John},
  title = {Photocopiers and Water-coolers: The Affordances of Informal Interaction},
  journal = {Organization Studies},
  year = {2007},
  volume = {28},
  pages = {605--634},
  number = {5},
  month = {\#may\#},
  abstract = {There has been increasing recognition of the importance of informal
	interactions in organizations, but research examining the effects
	of the physical environment on informal interaction has produced
	contradictory results and practical attempts to control the level
	of informal interaction by design have been marked by unintended
	consequences. Drawing on a qualitative study of informal interactions
	observed in photocopier rooms in three organizations, this paper
	builds on the work of ecological psychologist James Gibson to develop
	a theory of the affordances of informal interaction. The affordances
	of an environment are the possibilities for action called forth by
	it to a perceiving subject. Research on affordances has typically
	focused on the affordances of individual behavior. We introduce the
	notion of social affordances and identify the social and physical
	characteristics that produce the propinquity, privacy, and social
	designation necessary for an environment to afford informal interactions.
	The theory of social affordances provides a lens through which to
	reinterpret the conflicting results of previous studies and to reexamine
	the seemingly simple water-cooler around which the organization gathers.},
  keywords = {litsurvey.bib},
  publisher = {SAGE Publications Ltd}
}

@INPROCEEDINGS{Feldmann2009,
  author = {Feldmann, I and Atzpadin, N and Schreer, O and -. Pujol-Acolado,
	J and -. Landabaso, J and Escoda, O D},
  title = {Multi-view depth estimation based on visual-hull enhanced Hybrid
	Recursive Matching for {3D} video conference systems},
  booktitle = {2009 16th {IEEE} International Conference on Image Processing ({ICIP})},
  year = {2009},
  pages = {745--748},
  month = {\#nov\#},
  abstract = {This paper discusses the problem of high quality depth map estimation
	for real-time systems. Our work is based on the European FP7 project
	3DPresence which aims to build a multi-view and multiuser 3D videoconferencing
	system. Based on new multi-view auto-stereoscopic display technology
	the remote conferees will be rendered as an integral part of a three
	dimensional virtual shared environment. In order to create the related
	views for the 3D displays as well as to virtually correct the eye
	contact problem robust depth maps are required. For this purpose,
	in this paper we will discuss the fusion of two competing approaches
	which have, from a camera configuration point of view, contrary to
	each other properties. Namely, we will combine the volumetric Visual
	Hull (VH) approach with the stereo matching based Hybrid Recursive
	Matching (HRM) to a new method which benefits from the advantages
	of both techniques and discards their weak points.},
  institution = {IEEE},
  keywords = {real-time systems;stereo image processing;video signal processing;multiview
	depth estimation;visual hull;hybrid recursive matching;3D video conference
	systems;depth map estimation;real time systems;auto stereoscopic
	display technology;three dimensional virtual shared environment;3D
	displays;eye contact problem;Recursive estimation;Videoconference;Cameras;Layout;Image
	reconstruction;Teleconferencing;Three dimensional displays;Human
	resource management;Real time systems;Robustness;Depth estimation;Visual-Hull;HRM;stereo-matching;real-time;litsurvey.bib}
}

@ARTICLE{Fels2000,
  author = {Fels, D I and Weiss, P L},
  title = {Toward determining an attention-getting device for improving interaction
	during video-mediated communication},
  journal = {Comput. Human Behav.},
  year = {2000},
  volume = {16},
  pages = {189--198},
  number = {2},
  month = {\#mar\#},
  abstract = {Video-mediated communication is becoming a more common and effective
	means of interpersonal communication including work-related activities,
	distance education, telemedicine, and access to public information.
	Although the issue of `attention getting' and its importance for
	interpersonal interaction is well recognized in the video-mediated
	communication literature there is very little empirical evidence
	as to the relative effectiveness of the various attributes of attention-getting
	signals. The objective of this study was to compare the response
	times and error rates of four attention-getting devices which were
	suitable for a particular application of video-mediated communication
	in the educational sector. Twelve subjects (eight female and four
	male), classroom instructors aged 35--55 years, participated in the
	study. Four attention-getting devices were tested in this experiment:
	a red light, a yellow rotating light, a wire hand, and a fan with
	ribbon streamers. Each device was tested three times in three different
	classrooms during an actual class with actual instructors (the subjects).
	A one-way analysis of variance demonstrated a significant difference
	in response time for the four devices with the yellow light and the
	metal hand being fastest. This preliminary study points out the importance
	of empirically testing the effectiveness of attention-getting devices
	of differing characteristics since, of the four devices tested here,
	two could be expected to elicit the most immediate response from
	a communication partner.},
  keywords = {Video-mediated communication; Attention-getting device; Children and
	computing;litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Feng2018,
  author = {Feng, Mi and Peck, Evan and Harrison, Lane},
  title = {Patterns and pace: Quantifying diverse exploration behavior with
	visualizations on the web},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {501--511},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08454489.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Ferscha1999,
  author = {Ferscha, Alois and Johnson, James},
  title = {Distributed interaction in virtual spaces},
  booktitle = {Distributed Interactive Simulation and {Real-Time} Applications,
	1999. Proceedings. 3rd IEEE International Workshop on},
  year = {1999},
  pages = {5--13},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Fish1993,
  author = {Fish, Robert S and Kraut, Robert E and Root, Robert W and Rice, Ronald
	E},
  title = {Video as a technology for informal communication},
  month = {\#jan\#},
  year = {1993},
  keywords = {groupware, collaboration, videoconferencing, informal communication,
	videophone;litsurvey.bib}
}

@INPROCEEDINGS{Fish1992,
  author = {Fish, Robert S and Kraut, Robert E and Root, Robert W and Rice, Ronald
	E},
  title = {Evaluating video as a technology for informal communication},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1992},
  series = {CHI '92},
  pages = {37--48},
  address = {New York, NY, USA},
  month = {\#jun\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {informal meetings, video, group work, collaboration, desktop videoconferencing;litsurvey.bib},
  location = {Monterey, California, USA}
}

@ARTICLE{Flood1958,
  author = {Flood, Merrill M},
  title = {Some Experimental Games},
  journal = {Manage. Sci.},
  year = {1958},
  volume = {5},
  pages = {5--26},
  number = {1},
  month = {\#oct\#},
  abstract = {This paper reports the results of six experiments and analyses performed
	to explore the applicability of the non-constant-sum case of the
	theories of von Neumann-Morgenstern, and others, to the actual behavior
	of people playing games or involved in bargaining situations. The
	paper suggests directions in which the theory of games might be modified
	and extended to improve its applicability and usefulness. A ?split-the-difference
	principle? is suggested to augment the usual theory, so as to specify
	the exact amount of payments to be made in an ordinary two-person
	bargaining situation such as the sale of a used car. The application
	of this principle seems satisfactory in the experiments. One experiment
	suggests that, in a sequence of trials in the same game situation,
	people tend to start near an equilibrium point and then try to find
	a better equilibrium, if there is one. The experiments show examples
	of non-optimal behavior of the bargainers when the judgment necessary
	to estimate the relevant payoff is obscure. A fair division of five
	parcels of objects among five players when each player attaches different
	values to the parcels is outlined and computed, and the effect of
	coalitions is discussed.},
  keywords = {litsurvey.bib},
  publisher = {INFORMS}
}

@INPROCEEDINGS{Fonnet2018,
  author = {Fonnet, Adrien and Vigier, Toinon and Prie, Yannick and Cliquet,
	Gregoire and Picarougne, Fabien},
  title = {Axes and Coordinate Systems Representations for Immersive Analytics
	of Multi-Dimensional Data},
  booktitle = {2018 International Symposium on Big Data Visual and Immersive Analytics
	(BDVA)},
  year = {2018},
  pages = {1--10},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08533892.pdf:PDF}
}

@MISC{France242020,
  author = {{France24}},
  title = {Zoom deemed insecure},
  howpublished = {\url{https://www.france24.com/en/20200416-not-a-safe-platform-india-bans-zoom-for-government-use}},
  year = {2020},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Franco2003,
  author = {Franco, J-S and Boyer, E},
  title = {Exact polyhedral visual hulls},
  booktitle = {Procedings of the British Machine Vision Conference 2003},
  year = {2003},
  volume = {1},
  pages = {32.1--32.10},
  publisher = {British Machine Vision Association},
  conference = {British Machine Vision Conference 2003},
  keywords = {litsurvey.bib},
  location = {Norwich}
}

@INPROCEEDINGS{Franco2004,
  author = {Franco, J-S and M{\'e}nier, Cl{\'e}ment and Boyer, Edmond and Raffin,
	Bruno},
  title = {A distributed approach for real time {3D} modeling},
  booktitle = {Computer Vision and Pattern Recognition Workshop, 2004. {CVPRW'04}.
	Conference on},
  year = {2004},
  pages = {31--31},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@ARTICLE{Franco2009,
  author = {Franco, Jean-S{\'e}bastien and Boyer, Edmond},
  title = {Efficient polyhedral modeling from silhouettes},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2009},
  volume = {31},
  pages = {414--427},
  number = {3},
  month = {\#mar\#},
  abstract = {Modeling from silhouettes is a popular and useful topic in computer
	vision. Many methods exist to compute the surface of the visual hull
	from silhouettes, but few address the problem of ensuring sane topological
	properties of the surface, such as manifoldness. This article provides
	an efficient algorithm to compute such a surface in the form of a
	polyhedral mesh. It relies on a small number of geometric operations
	to compute a visual hull polyhedron in a single pass. Such simplicity
	enables the algorithm to combine the advantages of being fast, producing
	pixel-exact surfaces, and repeatably yield manifold and watertight
	polyhedra in general experimental conditions with real data, as verified
	with all datasets tested. The algorithm is fully described, its complexity
	analyzed and modeling results given.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {IEEE}
}

@BOOK{franco2014understanding,
  title = {Understanding bitcoin},
  publisher = {Wiley Online Library},
  year = {2014},
  author = {Franco, Pedro},
  file = {:../../../literature_repository/bitcoin/Understanding Bitcoin Cryptography - Pedro Franco.pdf:PDF}
}

@ARTICLE{Fu2018,
  author = {Fu, Jianwen and Xue, Jingfeng and Wang, Yong and Liu, Zhenyan and
	Shan, Chun},
  title = {Malware visualization for fine-grained classification},
  journal = {IEEE Access},
  year = {2018},
  volume = {6},
  pages = {14510--14523},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08290767.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Fuchs2002,
  author = {Fuchs, H and Kelshikar, N and Mulligan, J and Daniilidis, K},
  title = {{3D} {Tele-Collaboration} over internet 2},
  booktitle = {International Workshop on Immersive Telepresence ({ITP} '02)},
  year = {2002},
  address = {Juan Les Pin},
  keywords = {litsurvey.bib}
}

@ARTICLE{Fulk1987,
  author = {Fulk, Janet and Steinfield, Charles W and Schmitz, Joseph and Power,
	J Gerard},
  title = {A Social Information Processing Model of Media Use in Organizations},
  journal = {Communic. Res.},
  year = {1987},
  volume = {14},
  pages = {529--552},
  number = {5},
  month = {\#oct\#},
  abstract = {This article presents a model of how social influence processes affect
	individuals' attitudes toward communication media and media use behavior.
	The model integrates two areas of research. One body of work posits
	that media use patterns are the outcome of objectively rational choices.
	These choices involve evaluating communication options and selecting
	an appropriate medium to match the communication requirements of
	the task. The second perspective is social information processing
	theory (Salancik \& Pfeffer, 1978). This approach proposes that attitudes
	and behaviors are partially determined by information embedded in
	the social context. The synthesis of these perspectives asserts that
	media characteristics and attitudes are in part socially constructed.
	Furthermore, attitudes are influenced by attributions based on observations
	of one's own past behavior. This model is shown to explain a wider
	range of existing empirical findings. Also, new propositions are
	derived to guide future research. This social construction model
	of media use has significant implications for the design, conduct,
	and reporting of future research in organizations.},
  keywords = {litsurvey.bib},
  publisher = {SAGE Publications Inc}
}

@ARTICLE{Fullwood2006,
  author = {Fullwood, Chris and Doherty-Sneddon, Gwyneth},
  title = {Effect of gazing at the camera during a video link on recall},
  journal = {Appl. Ergon.},
  year = {2006},
  volume = {37},
  pages = {167--175},
  number = {2},
  month = {\#mar\#},
  abstract = {The impact of looking into the camera during a presentation over a
	video link (resulting in the perception of mutual gaze) on information
	recall was investigated. In a face-to-face context mutual gaze has
	been shown to facilitate the encoding and subsequent recall of information
	[Fry, R., Smith, G.F., 1975. The effects of feedback and eye contact
	on performance of a digit-coding task. J. Soc. Psychol. 96, 145-146;
	Otteson, J.D., Otteson, C.R., 1980. Effect of teacher's gaze on children's
	story recall. Percept. Motor Skill. 50, 35-42; Sherwood, J.V., 1988.
	Facilitative effects of gaze upon learning. Percept. Motor Skill.
	64 (3 Part 2), 1275-1278]. One explanation for these findings is
	that gaze acts as an arousal stimulus, which increases attentional
	focus and therefore enhances memory [Kelley, D.H., Gorham, J., 1988.
	Effects of immediacy on recall of information. Commun. Edu. 37(3),
	198-207]. Two studies were conducted in order to test whether gazing
	at the camera during video-mediated presentations resulted in similar
	benefits as mutual gaze in a face-to-face context. In study 1 a confederate
	presented information about two fictitious soap products. In one
	condition, the confederate gazed at the camera for 30\% of the presentation,
	therefore giving the participants the impression that he was gazing
	in their direction. In the other condition the confederate did not
	gaze at the camera. Participants viewed the sales presentations from
	both conditions. In the condition where gaze was directed at the
	camera, participants recalled significantly more information about
	the sales presentation. Study 2 employed the same pre-recorded sales
	presentations used in study 1, however they were delivered to the
	participants under audio-only conditions (therefore, the image was
	switched off). Results from study 2 indicated no recall differences
	between the two conditions. Findings from these studies would seem
	to indicate that the perception of gaze aversion over a video link
	(a consequence of the salesman not looking into the camera) has a
	negative impact on information recall. This has practical implications
	for video-mediated presentations. In a distance learning environment
	lecturers could be advised to look into the camera in order to promote
	more efficient learning in students.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Furche2016,
  author = {Furche, Tim and Gottlob, Georg and Libkin, Leonid and Orsi, Giorgio
	and Paton, Norman W},
  title = {Data Wrangling for Big Data: Challenges and Opportunities.},
  booktitle = {EDBT},
  year = {2016},
  volume = {16},
  pages = {473--478},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Data Wrangling for Big Data_ Challenges andOpp.pdf:PDF}
}

@BOOK{Furneaux2018,
  title = {Investigating Cryptocurrencies: Understanding, Extracting, and Analyzing
	Blockchain Evidence},
  publisher = {John Wiley \& Sons},
  year = {2018},
  author = {Furneaux, Nick},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/Nick_Furneaux_Investigating_Cryptocurrencies_.pdf:PDF}
}

@INPROCEEDINGS{Garae2018,
  author = {Garae, Jeffery and Ko, Ryan KL and Apperley, Mark},
  title = {A Full-Scale Security Visualization Effectiveness Measurement and
	Presentation Approach},
  booktitle = {2018 17th IEEE International Conference On Trust, Security And Privacy
	In Computing And Communications/12th IEEE International Conference
	On Big Data Science And Engineering (TrustCom/BigDataSE)},
  year = {2018},
  pages = {639--650},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08455963.pdf:PDF}
}

@InProceedings{Garau2001,
  author    = {Garau, Maia and Slater, Mel and Bee, Simon and Sasse, Martina Angela},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
  title     = {The impact of eye gaze on communication using humanoid avatars},
  year      = {2001},
  address   = {New York, NY, USA},
  month     = {\#mar\#},
  pages     = {309--316},
  publisher = {Association for Computing Machinery},
  series    = {CHI '01},
  keywords  = {avatars, cmc, collaborative virtual environments, communication, computer-mediated communication, cves, gaze, mediated, nonverbal behaviours; mediated communication; collaborative virtual enviroments (CVEs); computer-mediated communication (CMC);litsurvey.bib},
  location  = {Seattle, Washington, USA},
}

@ARTICLE{Garau2005,
  author = {Garau, Maia and Slater, Mel and Pertaub, David-Paul and Razzaque,
	Sharif},
  title = {The Responses of People to Virtual Humans in an Immersive Virtual
	Environment},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2005},
  volume = {14},
  pages = {104--116},
  number = {1},
  month = {\#feb\#},
  abstract = {This paper presents an experiment investigating the impact of behavior
	and responsiveness on social responses to virtual humans in an immersive
	virtual environment (IVE). A number of responses are investigated,
	including presence, copresence, and two physiological responses?heart
	rate and electrodermal activity (EDA). Our findings suggest that
	increasing agents' responsiveness even on a simple level can have
	a significant impact on certain aspects of people's social responses
	to human-oid agents. Despite being aware that the agents were computer-generated,
	participants with higher levels of social anxiety were significantly
	more likely to avoid ?disturbing? them. This suggests that on some
	level people can respond to virtual humans as social actors even
	in the absence of complex interaction. Responses appear to be shaped
	both by the agents' behaviors and by people's expectations of the
	technology. Participants experienced a significantly higher sense
	of personal contact when the agents were visually responsive to them,
	as opposed to static or simply moving. However, this effect diminished
	with experienced computer users. Our preliminary analysis of objective
	heart-rate data reveals an identical pattern of responses.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Garau2003,
  author = {Garau, Maia and Slater, Mel and Vinayagamoorthy, Vinoba and Brogni,
	Andrea and Steed, Anthony and Sasse, M Angela},
  title = {The impact of avatar realism and eye gaze control on perceived quality
	of communication in a shared immersive virtual environment},
  booktitle = {Proceedings of the {SIGCHI} conference on Human factors in computing
	systems},
  year = {2003},
  pages = {529--536},
  institution = {ACM},
  keywords = {litsurvey.bib}
}

@INCOLLECTION{Gargallo2007,
  author = {Gargallo, Pau and Sturm, Peter and Pujades, Sergi},
  title = {An occupancy--depth generative model of multi-view images},
  booktitle = {Computer {Vision--ACCV} 2007},
  publisher = {Springer},
  year = {2007},
  pages = {373--383},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Garrison1999,
  author = {Garrison, D Randy and Anderson, Terry and Archer, Walter},
  title = {Critical Inquiry In A Text-based Environment: Computer Conferencing
	In Higher Education},
  year = {1999},
  volume = {2},
  pages = {87--105},
  publisher = {Elsevier},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Gasparello2011,
  author = {Gasparello, P S and Marino, G and Bann{\`o}, F and Tecchia, F and
	Bergamasco, M},
  title = {{{Real-Time} Network Streaming of Dynamic {3D} Content with In-frame
	and Inter-frame Compression}},
  booktitle = {2011 {IEEE/ACM} 15th International Symposium on Distributed Simulation
	and Real Time Applications},
  year = {2011},
  pages = {81--87},
  address = {Salford},
  month = {\#sep\#},
  publisher = {IEEE},
  abstract = {Real-time 3D content distribution over a network (either LAN or WAN)
	has many possible applications, but requires facing several challenges,
	most notably the handling of the large amount of data usually associated
	with 3D meshes. The scope of the present paper falls within the well-established
	context of real-time capture and streaming of OpenGL command sequences,
	focusing in particular on data compression schemes. However, we advance
	beyond the state-of-the-art improving over previous attempts of ``in-frame''
	geometric compression on 3D structures inferred from generic OpenGL
	command sequences and adding ``inter-frame'' redundancy exploitation
	of the traffic generated by the typical architecture of interactive
	applications. Measurements reveal for this combination of techniques
	a very effective reduction of network traffic and a CPU overhead
	compatible with the requirements of interactive applications, suggesting
	a significant application potential for Internet-based 3D content
	streaming.},
  keywords = {computational geometry;content management;data compression;data handling;Internet;media
	streaming;mesh generation;telecommunication traffic;real-time network
	streaming;real-time 3D content distribution;in-frame compression;inter-frame
	compression;data handling;3D meshes;OpenGL command sequences;in-frame
	geometric compression;inter-frame redundancy exploitation;traffic
	generation;network traffic reduction;Internet-based 3D content streaming;Three
	dimensional displays;Real time systems;Data compression;Geometry;Solid
	modeling;Rendering (computer graphics);Cameras;Distributed Rendering;Distributed
	Applications;Remote Graphics;Delta Compression;Geometric Compression;litsurvey.bib}
}

@ARTICLE{Gatica-Perez2009,
  author = {Gatica-Perez, Daniel},
  title = {Automatic nonverbal analysis of social interaction in small groups:
	A review},
  journal = {Image Vis. Comput.},
  year = {2009},
  volume = {27},
  pages = {1775--1787},
  number = {12},
  month = {\#nov\#},
  abstract = {An increasing awareness of the scientific and technological value
	of the automatic understanding of face-to-face social interaction
	has motivated in the past few years a surge of interest in the devising
	of computational techniques for conversational analysis. As an alternative
	to existing linguistic approaches for the automatic analysis of conversations,
	a relatively recent domain is using findings in social cognition,
	social psychology, and communication that have established the key
	role that nonverbal communication plays in the formation, maintenance,
	and evolution of a number of fundamental social constructs, which
	emerge from face-to-face interactions in time scales that range from
	short glimpses all the way to long-term encounters. Small group conversations
	are a specific case on which much of this work has been conducted.
	This paper reviews the existing literature on automatic analysis
	of small group conversations using nonverbal communication, and aims
	at bridging the current fragmentation of the work in this domain,
	currently split among half a dozen technical communities. The review
	is organized around the main themes studied in the literature and
	discusses, in a comparative fashion, about 100 works addressing problems
	related to the computational modeling of interaction management,
	internal states, personality traits, and social relationships in
	small group conversations, along with pointers to the relevant literature
	in social science. Some of the many open challenges and opportunities
	in this domain are also discussed.},
  keywords = {Social interaction analysis; Small group conversations; Nonverbal
	behavior;litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Gaver1996,
  author = {Gaver, William W},
  title = {Situating Action {II}: Affordances for Interaction: The Social Is
	Material for Design},
  journal = {Ecol. Psychol.},
  year = {1996},
  volume = {8},
  pages = {111--129},
  number = {2},
  month = {\#jun\#},
  keywords = {litsurvey.bib},
  publisher = {Routledge}
}

@INPROCEEDINGS{Gaver1992,
  author = {Gaver, William W},
  title = {The affordances of media spaces for collaboration},
  booktitle = {Proceedings of the 1992 {ACM} conference on Computer-supported cooperative
	work},
  year = {1992},
  series = {CSCW '92},
  pages = {17--24},
  address = {New York, NY, USA},
  month = {\#dec\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {ecological approaches, mediaspaces, affordance, video;litsurvey.bib},
  location = {Toronto, Ontario, Canada}
}

@InProceedings{Gaver1992,
  author    = {Gaver, William W},
  booktitle = {Proceedings of the 1992 {ACM} conference on Computer-supported cooperative work},
  title     = {The affordances of media spaces for collaboration},
  year      = {1992},
  address   = {New York, NY, USA},
  month     = {\#dec\#},
  pages     = {17--24},
  publisher = {Association for Computing Machinery},
  series    = {CSCW '92},
  volume    = {92},
  keywords  = {but, in indicating some, misleading in suggesting that, of media spaces, of the intended functions, these metaphors are useful, they may well be; ecological approaches; mediaspaces; affordance; video;litsurvey.bib},
  location  = {Toronto, Ontario, Canada},
}

@InProceedings{Gaver1993,
  author    = {Gaver, William W and Sellen, Abigail and Heath, Christian and Luff, Paul},
  booktitle = {Proceedings of the {INTERACT} '93 and {CHI} '93 Conference on Human Factors in Computing Systems},
  title     = {One is not enough: multiple views in a media space},
  year      = {1993},
  address   = {New York, NY, USA},
  month     = {\#may\#},
  pages     = {335--341},
  publisher = {Association for Computing Machinery},
  series    = {CHI '93},
  keywords  = {comparisons, experimental studies, not add, of collaboration, on the other hand, see one another does, significantly to the process, tend to suggest, that allowing people to; media spaces; CSCW; video; social interaction;litsurvey.bib},
  location  = {Amsterdam, The Netherlands},
}

@INPROCEEDINGS{Gee2005,
  author = {Gee, F C and Browne, W N and Kawamura, K},
  title = {Uncanny valley revisited},
  booktitle = {Robot and Human Interactive Communication, 2005. {IEEE} International
	Workshop on},
  year = {2005},
  pages = {151--157},
  institution = {Ieee},
  keywords = {litsurvey.bib}
}

@ARTICLE{Gemmell2000,
  author = {Gemmell, J and Toyama, K and Zitnick, C L and Kang, T and Seitz,
	S},
  title = {Gaze awareness for video-conferencing: a software approach},
  journal = {IEEE Multimedia},
  year = {2000},
  volume = {7},
  pages = {26--35},
  number = {4},
  month = {\#oct\#},
  abstract = {Previous attempts at bringing gaze awareness to desktop videoconferencing
	have relied on hardware solutions. In this article, the authors describe
	their software approach, which tracks participants' head and eye
	movements using vision techniques, then uses this information to
	graphically place the head and eyes in a 3D environment.},
  keywords = {teleconferencing;tracking;active vision;computer graphics;groupware;gaze
	awareness;desktop videoconferencing;software approach;head movements;eye
	movements;computer vision techniques;graphical placement;3D environment;CSCW;Videoconference;Eyes;Face
	detection;Humans;Psychology;Teleconferencing;Lips;Animation;Collaborative
	work;Mouth;litsurvey.bib},
  publisher = {IEEE}
}

@INPROCEEDINGS{Gergle2006,
  author = {Gergle, Darren and Kraut, Robert E and Fussell, Susan R},
  title = {The impact of delayed visual feedback on collaborative performance},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2006},
  series = {CHI '06},
  pages = {1303--1312},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {shared visual space, visual delay, language, computer-supported cooperative
	work, empirical studies, communication;litsurvey.bib},
  location = {Montr{\'e}al, Qu{\'e}bec, Canada}
}

@BOOK{Gibson2014,
  title = {The ecological approach to visual perception: classic edition},
  publisher = {Psychology Press},
  year = {2014},
  author = {Gibson, James J},
  keywords = {litsurvey.bib}
}

@ARTICLE{Gibson1963,
  author = {Gibson, J J and Pick, A D},
  title = {Perception of another person's looking behavior},
  journal = {Am. J. Psychol.},
  year = {1963},
  volume = {76},
  pages = {386--394},
  number = {3},
  month = {\#sep\#},
  keywords = {EYE MOVEMENTS; VISUAL PERCEPTION;litsurvey.bib},
  language = {en},
  publisher = {JSTOR}
}

@ARTICLE{Gillies2005,
  author = {Gillies, Marco and Slater, Mel and {Others}},
  title = {Non-verbal communication for correlational characters},
  year = {2005},
  keywords = {litsurvey.bib}
}

@ARTICLE{Godfrey2016,
  author = {Godfrey, Parke and Gryz, Jarek and Lasek, Piotr},
  title = {Interactive visualization of large data sets},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year = {2016},
  volume = {28},
  pages = {2142--2157},
  number = {8},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07457691.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Goebbels2003,
  author = {Goebbels, Gernot and Lalioti, Vali and G{\"o}bel, Martin},
  title = {Design and evaluation of team work in distributed collaborative virtual
	environments},
  booktitle = {Proceedings of the {ACM} symposium on Virtual reality software and
	technology},
  year = {2003},
  series = {VRST '03},
  pages = {231--238},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {guidelines, evaluation, CVE Design Model, tele-presence, collaborative
	virtual environments, awareness;litsurvey.bib},
  location = {Osaka, Japan}
}

@INPROCEEDINGS{Goldin-Meadow1999,
  author = {Goldin-Meadow, S},
  title = {The role of gesture in communication and thinking},
  year = {1999},
  volume = {3},
  pages = {419--429},
  abstract = {People move their hands as they talk - they gesture. Gesturing is
	a robust phenomenon, found across cultures, ages, and tasks. Gesture
	is even found in individuals blind from birth. But what purpose,
	if any, does gesture serve? In this review, I begin by examining
	gesture when it stands on its own, substituting for speech and clearly
	serving a communicative function. When called upon to carry the full
	burden of communication, gesture assumes a language-like form, with
	structure at word and sentence levels. However, when produced along
	with speech, gesture assumes a different form - it becomes imagistic
	and analog. Despite its form, the gesture that accompanies speech
	also communicates. Trained coders can glean substantive information
	from gesture - information that is not always identical to that gleaned
	from speech. Gesture can thus serve as a research tool, shedding
	light on speakers' unspoken thoughts. The controversial question
	is whether gesture conveys information to listeners not trained to
	read them. Do spontaneous gestures communicate to ordinary listeners?
	Or might they be produced only for speakers themselves? I suggest
	these are not mutually exclusive functions - gesture serves as both
	a tool for communication for listeners, and a tool for thinking for
	speakers.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Golovchinsky2009,
  author = {Golovchinsky, Gene and Qvarfordt, Pernilla and van Melle, Bill and
	Carter, Scott and Dunnigan, Tony},
  title = {{DICE}: designing conference rooms for usability},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2009},
  series = {CHI '09},
  pages = {1015--1024},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {ubiquitous computing, smart environments, usability;litsurvey.bib},
  location = {Boston, MA, USA}
}

@ARTICLE{Goodwin2000,
  author = {Goodwin, Charles},
  title = {Action and embodiment within situated human interaction},
  journal = {J. Pragmat.},
  year = {2000},
  volume = {32},
  pages = {1489--1522},
  number = {10},
  month = {\#sep\#},
  abstract = {A theory of action must come to terms with both the details of language
	use and the way in which the social, cultural, material and sequential
	structure of the environment where action occurs figure into its
	organization. In this paper it will be suggested that a primordial
	site for the analysis of human language, cognition, and action consists
	of a situation in which multiple participants are attempting to carry
	out courses of action in concert with each other through talk while
	attending to both the larger activities that their current actions
	are ambedded within, and relevant phenomena in their surround. Using
	as data video recordings of young girls playing hopscotch and archaeologists
	classifying color, it will be argued that human action is built throught
	the simultaneous deployment of a range of quite different kinds of
	semiotic resources. Talk itself contains multiple sign systems with
	alternative properties. Strips of talk gain their power as social
	action via their placement within larger sequential structures, encompassing
	activities, and participation frameworks constituted through displays
	of mutual orientation made by the actors' bodies. The body is used
	in a quite different way to perform gesture, again a class of phenomena
	that encompasses structurally different types of sign systems. Both
	talk and gesture can index, construe or treat as irrelevant, entities
	in the participants' surround. Moreover, material structure in the
	surround, such as graphic fields of various types, can provide semiotic
	structure without which the constitution of particular kinds of action
	being invoked through talk would be impossible. In brief it will
	be argued that the construction of action through talk within situated
	interaction is accomplished through the temporally unfolding juxtaposition
	of quite different kinds of semiotic resources, and that moreover
	through this process the human body is made publicly visible as the
	site for a range of structurally different kinds of displays implicated
	in the constitution of the actions of the moment.},
  keywords = {Theory of action; Conversation analysis; Talk-in-interaction; Embodiment;
	Gestures; Semiotic fields;litsurvey.bib},
  publisher = {Elsevier}
}

@Article{Gorodnichy2004,
  author   = {Gorodnichy, Dmitry O and Roth, Gerhard},
  journal  = {Image Vis. Comput.},
  title    = {Nouse `use your nose as a mouse' perceptual vision technology for hands-free games and interfaces},
  year     = {2004},
  month    = {\#oct\#},
  number   = {12},
  pages    = {931--942},
  volume   = {22},
  abstract = {Due to recent increase of computer power and decrease of camera cost,
	it became very common to see a camera on top of a computer monitor.
	This paper presents the vision-based technology which allows one
	in such a setup to significantly enhance the perceptual power of
	the computer. The described techniques for tracking a face using
	a convex-shape nose feature as well as for face-tracking with two
	off-the-shelf cameras allow one to track faces robustly and precisely
	in both 2D and 3D with low resolution cameras. Supplemented by the
	mechanism for detecting multiple eye blinks, this technology provides
	a complete solution for building intelligent hands-free input devices.
	The theory behind the technology is presented. The results from running
	several perceptual user interfaces built with this technology are
	shown.},
  keywords = {computer human, face tracking, stereo tracking; Computer-human; Stereo-tracking; Face-tracking;litsurvey.bib},
}

@INPROCEEDINGS{Gotsch2018,
  author = {Gotsch, Daniel and Zhang, Xujing and Merritt, Timothy and Vertegaal,
	Roel},
  title = {{TeleHuman2}: A Cylindrical Light Field Teleconferencing System for
	Life-size {3D} Human Telepresence},
  booktitle = {{CHI}},
  year = {2018},
  pages = {522},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Grau2007,
  author = {Grau, O and Thomas, G A and Hilton, A and Kilner, J and Starck, J},
  title = {A Robust {Free-Viewpoint} Video System for Sport Scenes},
  booktitle = {2007 {3DTV} Conference},
  year = {2007},
  pages = {1--4},
  month = {\#may\#},
  abstract = {This contribution describes robust methods to provide a free-viewpoint
	video visualisation of sport scenes using a multi-camera set-up.
	This allows generation of novel views of actions from any angle and
	is of interest for visualisation in TV productions. The system utilises
	3D reconstruction techniques previously developed for studio use.
	This paper discusses some experiences found while applying these
	techniques for an uncontrolled outdoor environment and addresses
	robustness issues. This includes segmentation, camera calibration
	and 3D reconstruction. A number of different 3D representations,
	including billboards, visual hulls and view-dependent geometry are
	evaluated for the purpose.},
  institution = {IEEE},
  keywords = {image reconstruction;image representation;three-dimensional television;video
	signal processing;robust free-viewpoint video system;sport scenes;robust
	methods;free-viewpoint video visualisation;multi-camera set-up;TV
	productions;3D reconstruction techniques;uncontrolled outdoor environment;camera
	calibration;Robustness;Layout;Cameras;Robot vision systems;Visualization;Broadcasting;Calibration;TV;Production;Geometry;litsurvey.bib}
}

@ARTICLE{De_Greef2001,
  author = {de Greef, P and Ijsselsteijn, W A},
  title = {Social presence in a home tele-application},
  journal = {Cyberpsychol. Behav.},
  year = {2001},
  volume = {4},
  pages = {307--315},
  number = {2},
  month = {\#apr\#},
  abstract = {The current paper presents a study on the subjective evaluation of
	an advanced telecommunication platform aimed at informal home use,
	called the PhotoShare tele-application. This platform enables users
	to view photos (e.g., family or holiday snapshots) together, while
	the presenter and the viewer are at different, remote locations.
	The platform includes a common viewing space where the photos are
	displayed and selected, as well as an audio connection and a large-screen
	video connection for communication between the remote sites. The
	study investigated the effects of videocommunication on social presence.
	In addition, the ability to point at a picture with an electronic
	pointer was evaluated. In the context of presence research, the current
	study also provided information regarding the validity of the IPO
	Social Presence Questionnaire (IPO-SPQ), which was specifically designed
	to investigate social presence with telecommunication applications.
	The results indicated that adding broadband, life-size video communication
	significantly increased social presence. In addition, we found a
	significant effect of sex on social presence: women gave substantially
	higher social presence ratings than men. The absence of a significant
	effect of the pointing function indicated that extensive workspace
	functionality may be of minor importance to the user's feeling of
	social presence.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Mary Ann Liebert, Inc.}
}

@ARTICLE{Greenberg1976,
  author = {Greenberg, Jerald},
  title = {The Role of Seating Position in Group Interaction: A Review, with
	Applications for Group Trainers},
  journal = {Group \& Organization Studies},
  year = {1976},
  volume = {1},
  pages = {310--327},
  number = {3},
  month = {\#sep\#},
  abstract = {Experimental research relating seating position to group interaction
	was critically reviewed. Studies have found that persons in central
	seating positions were able to maintain eye contact with the most
	group mem bers, thereby enhancing their ability to interact with
	the group and emerge as the leader. Tasks requiring interpersonal
	communication were associated with the use of close seating arrangements,
	and tasks requir ing independent activities were associated with
	distant seating ar rangements. Research on affiliative relations
	found that physical close ness enhances friendship formation and
	is a reliable sociometric index of friendship choices within groups.
	Final discussion centered on the prac tical implications of these
	findings for the group training session. It was stressed that group
	trainers learn to alter the seating positions of mem bers in order
	to facilitate the attainment of group goals.},
  keywords = {litsurvey.bib},
  publisher = {SAGE Publications}
}

@INPROCEEDINGS{Greenhalgh1997,
  author = {Greenhalgh, Chris and Benford, Steve},
  title = {Boundaries, awareness and interaction in collaborative virtual environments},
  booktitle = {Enabling Technologies: Infrastructure for Collaborative Enterprises,
	1997. Proceedings., Sixth {IEEE} Workshops on},
  year = {1997},
  pages = {193--198},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Greenhalgh1995,
  author = {Greenhalgh, Chris and Benford, Steven},
  title = {{MASSIVE}: a collaborative virtual environment for teleconferencing},
  month = {\#sep\#},
  year = {1995},
  keywords = {CSCW, scalability;litsurvey.bib}
}

@ARTICLE{Greenhalgh2001,
  author = {Greenhalgh, Chris and Bullock, Adrian and Fr{\'e}con, Emmanuel and
	Lloyd, David and Steed, Anthony},
  title = {Making Networked Virtual Environments Work},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2001},
  volume = {10},
  pages = {142--159},
  number = {2},
  month = {\#apr\#},
  abstract = {Collaborative virtual environments (CVEs) are a promising technology
	enabling remote participants to share a common place through three-dimensional
	graphical scenes. Within the COVEN project (Normand, 1999), we have
	run prolonged series of Internet trials that have allowed us to gather
	valuable data to formulate usability guidelines and networking requirements.
	However, running such trials in a real setting and making sure that
	the application and networking infrastructures will be stable enough
	is still a challenge. In this paper, we describe some of our experiences,
	together with the technical choices that have permitted many hours
	of successful Internet trials. We also make a thorough analysis of
	different correlated logging data. This analysis allows us to propose
	and confirm a model of a CVE application's network behavior, together
	with a number of interesting results that disprove some common assumptions.
	Furthermore, we use the model and the logging data to highlight the
	benefits of IP multicasting and for predicting traffic behaviors
	and bandwidth use on top of different logical network topologies.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Greenhalgh2001,
  author = {Greenhalgh, Chris and Bullock, Adrian and Fr{\'e}con, Emmanuel and
	Lloyd, David and Steed, Anthony},
  title = {Making Networked Virtual Environments Work},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2001},
  volume = {10},
  pages = {142--159},
  number = {2},
  month = {\#apr\#},
  abstract = {Collaborative virtual environments (CVEs) are a promising technology
	enabling remote participants to share a common place through three-dimensional
	graphical scenes. Within the COVEN project (Normand, 1999), we have
	run prolonged series of Internet trials that have allowed us to gather
	valuable data to formulate usability guidelines and networking requirements.
	However, running such trials in a real setting and making sure that
	the application and networking infrastructures will be stable enough
	is still a challenge. In this paper, we describe some of our experiences,
	together with the technical choices that have permitted many hours
	of successful Internet trials. We also make a thorough analysis of
	different correlated logging data. This analysis allows us to propose
	and confirm a model of a CVE application's network behavior, together
	with a number of interesting results that disprove some common assumptions.
	Furthermore, we use the model and the logging data to highlight the
	benefits of IP multicasting and for predicting traffic behaviors
	and bandwidth use on top of different logical network topologies.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Gregor2006,
  author = {Gregor, Shirley},
  title = {The Nature of Theory in Information Systems},
  journal = {Miss. Q.},
  year = {2006},
  volume = {30},
  pages = {611--642},
  number = {3},
  abstract = {[The aim of this research essay is to examine the structural nature
	of theory in Information Systems. Despite the importance of theory,
	questions relating to its form and structure are neglected in comparison
	with questions relating to epistemology. The essay addresses issues
	of causality, explanation, prediction, and generalization that underlie
	an understanding of theory. A taxonomy is proposed that classifies
	information systems theories with respect to the manner in which
	four central goals are addressed: analysis, explanation, prediction,
	and prescription. Five interrelated types of theory are distinguished:
	(1) theory for analyzing, (2) theory for explaining, (3) theory for
	predicting, (4) theory for explaining and predicting, and (5) theory
	for design and action. Examples illustrate the nature of each theory
	type. The applicability of the taxonomy is demonstrated by classifying
	a sample of journal articles. The paper contributes by showing that
	multiple views of theory exist and by exposing the assumptions underlying
	different viewpoints. In addition, it is suggested that the type
	of theory under development can influence the choice of an epistemological
	approach. Support is given for the legitimacy and value of each theory
	type. The building of integrated bodies of theory that encompass
	all theory types is advocated.]},
  keywords = {litsurvey.bib},
  publisher = {Management Information Systems Research Center, University of Minnesota}
}

@INPROCEEDINGS{Grimstead2005,
  author = {Grimstead, I J and Walker, D W and Avis, N J},
  title = {Collaborative visualization: a review and taxonomy},
  booktitle = {Ninth {IEEE} International Symposium on Distributed Simulation and
	{Real-Time} Applications},
  year = {2005},
  pages = {61--69},
  month = {\#oct\#},
  publisher = {Ieee},
  abstract = {We present a brief review of 42 collaborative visualization systems,
	grouped into four application areas: collaborative problem-solving
	environments, virtual reality environments, multi-player online games
	and multi-user enabling of single user applications. The systems
	are then compared by five attributes: number of simultaneous users,
	user access control, communication architecture, type of transmitted
	data and user synchronization. We review the characteristic properties
	of each application area, overall trends in characteristics and recommend
	improvements for future systems. The taxonomy of visualization and
	accompanying bibliography are available on-line via the RAVE project
	pages by Grimstead, I.J., (2005), with on-line references hyper-linked
	where available.},
  keywords = {groupware;bibliographies;data visualisation;virtual reality;user interfaces;collaborative
	visualization taxonomy;collaborative problem-solving;virtual reality;multiplayer
	online games;user access control;communication architecture;data
	transmission;user synchronization;bibliography;online references;Taxonomy;Layout;Data
	visualization;Application software;Online Communities/Technical Collaboration;Virtual
	reality;Peer to peer computing;Problem-solving;Analytical models;Access
	control;litsurvey.bib}
}

@INPROCEEDINGS{Grimstead2005,
  author = {Grimstead, I J and Walker, D W and Avis, N J},
  title = {Collaborative visualization: A review and taxonomy},
  booktitle = {Distributed Simulation and {Real-Time} Applications, 2005. {DS-RT}
	2005 Proceedings. Ninth {IEEE} International Symposium on},
  year = {2005},
  pages = {61--69},
  publisher = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Gross2003,
  author = {Gross, Markus and W{\"u}rmlin, Stephan and Naef, Martin and Lamboray,
	Edouard and Spagno, Christian and Kunz, Andreas and Koller-Meier,
	Esther and Svoboda, Tomas and Van Gool, Luc and Lang, Silke and Strehlke,
	Kai and Moere, Andrew Vande and Staadt, Oliver},
  title = {blue-c: a spatially immersive display and {3D} video portal for telepresence},
  booktitle = {{ACM} {SIGGRAPH} 2003 Papers},
  year = {2003},
  volume = {22},
  series = {SIGGRAPH '03},
  pages = {819--827},
  address = {New York, NY, USA},
  month = {\#jul\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {virtual environments, graphics hardware, spatially immersive displays,
	3D Video, real-time graphics;litsurvey.bib},
  location = {San Diego, California}
}

@INPROCEEDINGS{Gross2003,
  author = {Gross, Markus and W{\"u}rmlin, Stephan and Naef, Martin and Lamboray,
	Edouard and Spagno, Christian and Kunz, Andreas and Koller-Meier,
	Esther and Svoboda, Tomas and Van Gool, Luc and Lang, Silke and Strehlke,
	Kai and Moere, Andrew Vande and Staadt, Oliver},
  title = {blue-c: a spatially immersive display and {3D} video portal for telepresence},
  booktitle = {{ACM} {SIGGRAPH} 2003 Papers},
  year = {2003},
  volume = {22},
  series = {SIGGRAPH '03},
  pages = {819--827},
  address = {New York, NY, USA},
  month = {\#jul\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {virtual environments, graphics hardware, spatially immersive displays,
	3D Video, real-time graphics;litsurvey.bib},
  location = {San Diego, California}
}

@INPROCEEDINGS{Grossman2008,
  author = {Grossman, Tovi and Balakrishnan, Ravin},
  title = {Collaborative interaction with volumetric displays},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2008},
  series = {CHI '08},
  pages = {383--392},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {collaborative interaction, volumetric displays;litsurvey.bib},
  location = {Florence, Italy}
}

@INPROCEEDINGS{Gu2006,
  author = {Gu, Erdan and Badler, Norman I},
  title = {Visual Attention and Eye Gaze During Multiparty Conversations with
	Distractions},
  booktitle = {Intelligent Virtual Agents},
  year = {2006},
  pages = {193--204},
  publisher = {Springer Berlin Heidelberg},
  abstract = {Our objective is to develop a computational model to predict visual
	attention behavior for an embodied conversational agent. During interpersonal
	interaction, gaze provides signal feedback and directs conversation
	flow. Simultaneously, in a dynamic environment, gaze also directs
	attention to peripheral movements. An embodied conversational agent
	should therefore employ social gaze not only for interpersonal interaction
	but also to possess human attention attributes so that its eyes and
	facial expression portray and convey appropriate distraction and
	engagement behaviors.},
  institution = {Springer},
  keywords = {litsurvey.bib}
}

@ARTICLE{Gunawardena1997,
  author = {Gunawardena, Charlotte N and Zittle, Frank J},
  title = {Social presence as a predictor of satisfaction within a computer ?mediated
	conferencing environment},
  journal = {Am. J. Distance Educ.},
  year = {1997},
  volume = {11},
  pages = {8--26},
  number = {3},
  month = {\#jan\#},
  abstract = {Abstract Based on the GlobalEd inter?university computer conference,
	this study examined how effective ?social presence? is as a predictor
	of overall learner satisfaction in a text?based medium. The stepwise
	regression analysis converged on a three?predictor model revealing
	that social presence (the degree to which a person is perceived as
	?real? in mediated communication), student perception of having equal
	opportunity to participate, and technical skills accounted for about
	68\% of the explained variance. Social presence alone contributed
	about 60\% of this variance, suggesting that it may be a very strong
	predictor of satisfaction. Reliability data on the social presence
	scale is provided. The results also indicated that participants who
	felt a higher sense of social presence enhanced their socio?emotional
	experience by using emoticons to express missing nonverbal cues in
	written form. These findings have implications for designing academic
	computer conferences where equal attention must be paid to designing
	techniques that enhance social presence.},
  keywords = {litsurvey.bib},
  publisher = {Routledge}
}

@ARTICLE{Guye-Vuilleme1999,
  author = {Guye-Vuill{\`e}me, A and Capin, T K and Pandzic, S and Thalmann,
	N Magnenat and Thalmann, D},
  title = {Nonverbal communication interface for collaborative virtual environments},
  journal = {Virtual Real.},
  year = {1999},
  volume = {4},
  pages = {49--59},
  number = {1},
  month = {\#mar\#},
  abstract = {Nonverbal communication is an important aspect of real-life face-to-face
	interaction and one of the most efficient ways to convey emotions,
	therefore users should be provided the means to replicate it in the
	virtual world. Because articulated embodiments are well suited to
	provide body communication in virtual environments, this paper first
	reviews some of the advantages and disadvantages of complex embodiments.
	After a brief introduction to nonverbal communication theories, we
	present our solution, taking into account the practical limitations
	of input devices and social science aspects. We introduce our sample
	of actions and implementation using our VLNET (Virtual Life Network)
	networked virtual environment and discuss the results of an informal
	evaluation experiment.},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@INPROCEEDINGS{Hackathorn2016,
  author = {Hackathorn, Richard and Margolis, Todd},
  title = {Immersive analytics: Building virtual data worlds for collaborative
	decision support},
  booktitle = {2016 Workshop on Immersive Analytics (IA)},
  year = {2016},
  pages = {44--47},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07932382.pdf:PDF}
}

@Book{petzold2008annotated,
  author    = {Petzold, Charles},
  publisher = {Wiley Publishing},
  title     = {The annotated Turing: a guided tour through Alan Turing's historic paper on computability and the Turing machine},
  year      = {2008},
}

@ARTICLE{Hager1979,
  author = {Hager, Joseph C and Ekman, Paul},
  title = {Long-distance of transmission of facial affect signals},
  journal = {Ethol. Sociobiol.},
  year = {1979},
  volume = {1},
  pages = {77--82},
  number = {1},
  month = {\#oct\#},
  abstract = {This study examined the distance at which certain facial expression
	can transmit affect messages. A man and a woman assumed---facial
	expressions that were selected carefully to represent six affects.
	These expressions were shown in still photographs and in live portrayals
	to 49 observers who composed four groups which were 30, 35, 40, and
	45 meters away from the stimuli. Photographs and live portrayals
	produced comparable results. Every observer was able to label the
	expressions accurately although accuracy declined as distance increased.
	Extrapolation from the data suggested that some messages may be sent
	far beyond the distances used in this study. These results raise
	important issues about the transmission of facial signals over distance
	and suggest that the face is a long-distance transmitter of affect
	signals.},
  keywords = {Facial expression;litsurvey.bib},
  publisher = {Elsevier}
}

@BOOK{Hall1969,
  title = {The Hidden Dimension},
  publisher = {Anchor Books New York},
  year = {1969},
  author = {Hall, Edward Twitchell and Hall, Edward T},
  volume = {1990},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Hall-Holt2001,
  author = {Hall-Holt, O and Rusinkiewicz, S},
  title = {{Stripe boundary codes for real-time structured-light range scanning
	of moving objects}},
  booktitle = {Proceedings of the 8\textbackslashtextsuperscript{th} International
	Conference on Computer Vision ({ICCV} '01)},
  year = {2001},
  pages = {359--366},
  address = {Vancouver},
  publisher = {IEEE Comput. Soc},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Hancock2004,
  author = {Hancock, Jeffrey T and Thom-Santelli, Jennifer and Ritchie, Thompson},
  title = {Deception and design: the impact of communication technology on lying
	behavior},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2004},
  series = {CHI '04},
  pages = {129--134},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {lying, communication, trust, deception, CMC, media;litsurvey.bib},
  location = {Vienna, Austria}
}

@ARTICLE{Harms2004,
  author = {Harms, Chad and Biocca, Frank},
  title = {Internal consistency and reliability of the networked minds measure
	of social presence},
  year = {2004},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Harrop2006,
  author = {Harrop, Warren and Armitage, Grenville},
  title = {Real-time collaborative network monitoring and control using 3D game
	engines for representation and interaction},
  booktitle = {Proceedings of the 3rd international workshop on Visualization for
	computer security},
  year = {2006},
  pages = {31--40},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1179576.1179583.pdf:PDF}
}

@BOOK{Hartley2003,
  title = {{Multiple View Geometry in Computer Vision}},
  publisher = {Cambridge University Press},
  year = {2003},
  author = {Hartley, Richard and Zisserman, Andrew},
  edition = {2},
  abstract = {A basic problem in computer vision is to understand the structure
	of a real world scene given several images of it. Techniques for
	solving this problem are taken from projective geometry and photogrammetry.
	Here, the authors cover the geometric principles and their algebraic
	representation in terms of camera projection matrices, the fundamental
	matrix and the trifocal tensor. The theory and methods of computation
	of these entities are discussed with real examples, as is their use
	in the reconstruction of scenes from multiple images. The new edition
	features an extended introduction covering the key ideas in the book
	(which itself has been updated with additional examples and appendices)
	and significant new results which have appeared since the first edition.
	Comprehensive background material is provided, so readers familiar
	with linear algebra and basic numerical methods can understand the
	projective geometry and estimation algorithms presented, and implement
	the algorithms directly from the book.},
  keywords = {litsurvey.bib},
  language = {en}
}

@PHDTHESIS{Hauber2008,
  author = {Hauber, J{\"o}rg},
  title = {Understanding Remote Collaboration in Video Collaborative Virtual
	Environments},
  school = {University of Canterbury},
  year = {2008},
  keywords = {litsurvey.bib}
}

@InProceedings{Hauber2006,
  author    = {Hauber, J{\"o}rg and Regenbrecht, Holger and Billinghurst, Mark and Cockburn, Andy},
  booktitle = {Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work},
  title     = {{Spatiality in videoconferencing: trade-offs between efficiency and social presence}},
  year      = {2006},
  address   = {New York, NY, USA},
  month     = {\#nov\#},
  pages     = {413--422},
  publisher = {Association for Computing Machinery},
  series    = {CSCW '06},
  keywords  = {2d and 3d video, are interested in comparing, collaborative virtual, distributed collaboration, environment, in our work we, photo-ware, social presence, videoconferencing; remote collaboration; collaborative virtual environment;litsurvey.bib},
  location  = {Banff, Alberta, Canada},
}

@INPROCEEDINGS{Hauber2006,
  author = {Hauber, J{\"o}rg and Regenbrecht, Holger and Billinghurst, Mark and
	Cockburn, Andy},
  title = {Spatiality in videoconferencing: trade-offs between efficiency and
	social presence},
  booktitle = {Proceedings of the 2006 20th anniversary conference on Computer supported
	cooperative work},
  year = {2006},
  series = {CSCW '06},
  pages = {413--422},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {videoconferencing, social presence, remote collaboration, collaborative
	virtual environment, photo-ware;litsurvey.bib},
  location = {Banff, Alberta, Canada}
}

@ARTICLE{Hauber2005,
  author = {Hauber, J{\"o}rg and Regenbrecht, Holger and Hills, Aimee and Cockburn,
	Andrew and Billinghurst, Mark},
  title = {Social presence in two-and three-dimensional videoconferencing},
  year = {2005},
  keywords = {litsurvey.bib},
  publisher = {University of Canterbury. Computer Science and Software Engineering.}
}

@INCOLLECTION{Hauser2006,
  author = {Hauser, Helwig},
  title = {Generalizing focus+ context visualization},
  booktitle = {Scientific visualization: The visual extraction of knowledge from
	data},
  publisher = {Springer},
  year = {2006},
  pages = {305--327},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Generalizing Focus + Context Visualization.pdf:PDF}
}

@ARTICLE{Hauser2005,
  author = {Hauser, Helwig},
  title = {Toward new grounds in visualization},
  journal = {ACM SIGGRAPH Computer Graphics},
  year = {2005},
  volume = {39},
  pages = {5--8},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Towards New Grounds in Visualization.pdf:PDF}
}

@INPROCEEDINGS{hauser2003interactive,
  author = {Hauser, Helwig and Mlejnek, Matej},
  title = {Interactive volume visualization of complex flow semantics.},
  booktitle = {VMV},
  year = {2003},
  pages = {191--198},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Interactive Volume Visualization of Complex Fl.pdf:PDF}
}

@ARTICLE{Hawes2018,
  author = {Hawes, Sloane and Kerrigan, Josephine and Morris, Kevin},
  title = {Factors informing outcomes for older cats and dogs in animal shelters},
  journal = {Animals},
  year = {2018},
  volume = {8},
  pages = {36},
  number = {3},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/animals-08-00036.pdf:PDF},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@ARTICLE{Haythornthwaite1995,
  author = {Haythornthwaite, Caroline and Wellman, Barry and Mantei, Marilyn},
  title = {Work relationships and media use: A social network analysis},
  journal = {Group Decision and Negotiation},
  year = {1995},
  volume = {4},
  pages = {193--211},
  number = {3},
  month = {\#may\#},
  abstract = {Our research provided empirical evidence about the alternative means
	of communication used by 25 members of a research group who had available
	to them: unscheduled face-to-face encounters, sheduled face-to-face
	meetings, electronic mail, telephone, fax, and desktop videoconferencing.
	The intent of our research is to learn whether there are elements
	in existing group communication patterns that suggest how future
	communication systems can be designed or selected to fit the actual
	work relationships of a group. A detailed social network survey provided
	information about what members of the group communicated about, how
	they communicated, and with whom they communicated. Most communication
	was done through a combination of media, but predominately through
	unscheduled encounters, electronic mail, and scheduled meetings;
	people rarely videoconferenced, telephoned, or faxed. Factor analysis
	reduced the 24 work relationships to six distinct dimensions: receiving
	work, giving work, collaborative writing, major emotional support,
	sociability, and computer programming. The proportion in which the
	three main media were used varied according to the nature of the
	work dimension. Our findings suggest that a multivariate perspective
	that considers group norms and practices, social networks, and work
	dimensions is necessary to analyze media use.},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@INPROCEEDINGS{Hedge1978,
  author = {Hedge, B J and Everitt, B S and Frith, Christopher D},
  title = {The Role Of Gaze In Dialogue},
  year = {1978},
  volume = {42},
  pages = {453--475},
  publisher = {Elsevier},
  keywords = {litsurvey.bib}
}

@ARTICLE{Heeter1992,
  author = {Heeter, Carrie},
  title = {Being There: The Subjective Experience of Presence},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {1992},
  volume = {1},
  pages = {262--271},
  number = {2},
  month = {\#jan\#},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Heldal2005,
  author = {Heldal, Ilona and Steed, Anthony and Spante, Maria and Schroeder,
	Ralph and Bengtsson, Sophia and Partanen, Marja},
  title = {Successes and Failures in {Co-Present} Situations},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2005},
  volume = {14},
  pages = {563--579},
  number = {5},
  month = {\#oct\#},
  abstract = {Virtual environments systems based on immersive projection technologies
	(IPTs) offer users the possibility of collaborating intuitively in
	a 3D environment. While considerable work has been done to examine
	interaction in desktop-based collaborative virtual environments (CVEs),
	there are currently no studies for collaborative interaction using
	IPTs. The aim of this paper is to examine how immersive technologies
	support interaction and to compare this to the experience with desktop
	systems. A study of collaboration is presented where two partners
	worked together using networked IPT environments. The data collected
	included observations, analysis of video and audio recordings, questionnaires
	and debriefing interviews from both IPT sites. This paper focuses
	on the successes and failures in collaboration through detailed examination
	of particular incidents during the interaction. We compare these
	successes and failures with the findings of a study by Hindmarsh,
	Fraser, Heath, \& Benford (Computer Supported Collaborative Work,
	CSCW'98, 1998, pp. 217?226) that examined object-focused interaction
	on a desktop-based CVE system. Our findings identify situations where
	interaction is better supported with the IPT system than the desktop
	system, and situations where interaction is not as well supported.
	We also present examples of how social interaction is critical to
	seamless collaboration.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Heldner2010,
  author = {Heldner, Mattias and Edlund, Jens},
  title = {Pauses, gaps and overlaps in conversations},
  journal = {J. Phon.},
  year = {2010},
  volume = {38},
  pages = {555--568},
  number = {4},
  month = {\#oct\#},
  abstract = {This paper explores durational aspects of pauses, gaps and overlaps
	in three different conversational corpora with a view to challenge
	claims about precision timing in turn-taking. Distributions of pause,
	gap and overlap durations in conversations are presented, and methodological
	issues regarding the statistical treatment of such distributions
	are discussed. The results are related to published minimal response
	times for spoken utterances and thresholds for detection of acoustic
	silences in speech. It is shown that turn-taking is generally less
	precise than is often claimed by researchers in the field of conversation
	analysis or interactional linguistics. These results are discussed
	in the light of their implications for models of timing in turn-taking,
	and for interaction control models in speech technology. In particular,
	it is argued that the proportion of speaker changes that could potentially
	be triggered by information immediately preceding the speaker change
	is large enough for reactive interaction controls models to be viable
	in speech technology.},
  keywords = {litsurvey.bib},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Helm2018,
  author = {Helm, Paul and Pickering, Julian and others},
  title = {Enabling Collaborative Decision Making Through Immersive Visualisation},
  booktitle = {SPE Annual Technical Conference and Exhibition},
  year = {2018},
  organization = {Society of Petroleum Engineers},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/SPE-191525-MS.pdf:PDF}
}

@INPROCEEDINGS{Herraiz2009,
  author = {Herraiz, J L and Espa{\~n}a, S and Garc{\'\i}a, S and Cabido, R and
	Montemayor, A S and Desco, M and Vaquero, J J and Udias, J M},
  title = {{{GPU} acceleration of a fully {3D} Iterative Reconstruction Software
	for {PET} using {CUDA}}},
  booktitle = {2009 {IEEE} Nuclear Science Symposium Conference Record ({NSS/MIC})},
  year = {2009},
  pages = {4064--4067},
  month = {\#oct\#},
  abstract = {A CUDA implementation of the existing software FIRST (Fast Iterative
	Reconstruction Software for (PET) Tomography) is presented. This
	implementation uses consumer graphics processing units (GPUs) to
	accelerate the compute-intensive parts of the reconstruction: forward
	and backward projection. FIRST was originally developed in FORTRAN,
	and it has been migrated to C language to be used with NVIDIA C for
	CUDA, as well as for a straightforward implementation and performance
	comparison between the C versions of the code running on the CPU
	and on the GPU. We measured the execution time of the CUDA version
	compared to the fastest available CPU. The CUDA implementation includes
	a loop re-ordering and an optimized memory allocation, which improves
	even more the performance of the reconstruction on the GPUs.},
  keywords = {C language;coprocessors;image reconstruction;iterative methods;medical
	image processing;positron emission tomography;transforms;GPU acceleration;fully
	3D iterative reconstruction software;PET reconstruction software;CUDA;FIRST
	software;Fast Iterative Reconstruction Software for Tomography;graphics
	processing units;forward projection;backward projection;C language;NVIDIA
	C;loop reordering;optimised memory allocation;Acceleration;Positron
	emission tomography;Central Processing Unit;Hospitals;Nuclear and
	plasma sciences;Graphics;Time measurement;Iterative methods;Radiation
	detectors;Multicore processing;litsurvey.bib}
}

@INPROCEEDINGS{Hilliges2012,
  author = {Hilliges, Otmar and Kim, David and Izadi, Shahram and Weiss, Malte
	and Wilson, Andrew},
  title = {{HoloDesk}: direct 3d interactions with a situated see-through display},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {2421--2430},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {kinect, see-through display, 3d physics interactions, augmented reality
	(ar), natural human grasping;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@ARTICLE{Hilton2000,
  author = {Hilton, Adrian and Beresford, Daniel and Gentils, Thomas and Smith,
	Raymond and Sun, Wei and Illingworth, John},
  title = {{Whole-body modelling of people from multiview images to populate
	virtual worlds}},
  journal = {Vis. Comput.},
  year = {2000},
  volume = {16},
  pages = {411--436},
  number = {7},
  month = {\#nov\#},
  abstract = {In this paper a new technique is introduced for automatically building
	recognisable, moving 3D models of individual people. A set of multiview
	colour images of a person is captured from the front, sides and back
	by one or more cameras. Model-based reconstruction of shape from
	silhouettes is used to transform a standard 3D generic humanoid model
	to approximate a person's shape and anatomical structure. Realistic
	appearance is achieved by colour texture mapping from the multiview
	images. The results show the reconstruction of a realistic 3D facsimile
	of the person suitable for animation in a virtual world. The system
	is inexpensive and is reliable for large variations in shape, size
	and clothing. This is the first approach to achieve realistic model
	capture for clothed people and automatic reconstruction of animated
	models. A commercial system based on this approach has recently been
	used to capture thousands of models of the general public.},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Hindmarsh2000,
  author = {Hindmarsh, Jon and Fraser, Mike and Heath, Christian and Benford,
	Steve and Greenhalgh, Chris},
  title = {Object-focused interaction in collaborative virtual environments},
  month = {\#dec\#},
  year = {2000},
  keywords = {embodiment, user interface design, objects, virtual reality, CSCW,
	shared spaces, social interaction;litsurvey.bib}
}

@ARTICLE{Ho2010,
  author = {Ho, Chin-Chang and MacDorman, Karl F},
  title = {Revisiting the uncanny valley theory: Developing and validating an
	alternative to the Godspeed indices},
  journal = {Comput. Human Behav.},
  year = {2010},
  volume = {26},
  pages = {1508--1518},
  number = {6},
  month = {\#nov\#},
  abstract = {Mori (1970) proposed a hypothetical graph describing a nonlinear relation
	between a character's degree of human likeness and the emotional
	response of the human perceiver. However, the index construction
	of these variables could result in their strong correlation, thus
	preventing rated characters from being plotted accurately. Phase
	1 of this study tested the indices of the Godspeed questionnaire
	as measures of humanlike characters. The results indicate significant
	and strong correlations among the relevant indices (Bartneck, Kuli{\'c},
	Croft, \& Zoghbi, 2009). Phase 2 of this study developed alternative
	indices with nonsignificant correlations (p>.05) between the proposed
	y-axis eeriness and x-axis perceived humanness (r=.02). The new humanness
	and eeriness indices facilitate plotting relations among rated characters
	of varying human likeness.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  keywords = {Affective appraisal, Embodied agents, Human-robot interaction, Psychometric
	scales, Social perception; Human--robot interaction;litsurvey.bib},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{Ho2008,
  author = {Ho, Chin-Chang and MacDorman, Karl F and Pramono, Z A D Dwi},
  title = {Human emotion and the uncanny valley: a {GLM}, {MDS}, and Isomap
	analysis of robot video ratings},
  booktitle = {Proceedings of the 3rd {ACM/IEEE} international conference on Human
	robot interaction},
  year = {2008},
  series = {HRI '08},
  pages = {169--176},
  address = {New York, NY, USA},
  month = {\#mar\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {data visualization, android science, uncanny valley, emotion;litsurvey.bib},
  location = {Amsterdam, The Netherlands}
}

@ARTICLE{Hofmann2006,
  author = {Hofmann, Stefan G and Suvak, Michael and Litz, Brett T},
  title = {Sex differences in face recognition and influence of facial affect},
  journal = {Pers. Individ. Dif.},
  year = {2006},
  volume = {40},
  pages = {1683--1690},
  number = {8},
  month = {\#jun\#},
  abstract = {To study sex differences in the recognition of human faces with different
	facial expressions, 65 female and 64 male participants learned to
	associate names with various male and female neutral faces. During
	the recall phase, participants were then asked to name the same persons
	depicting different emotional expressions (neutral, happy, angry,
	and fearful). Females were faster than males at naming male faces,
	and males were faster than females at naming female faces. All participants
	were faster at naming neutral or happy female faces than neural or
	happy male faces. These results suggest that opposite-sex faces require
	less processing time than same-sex faces, which is consistent with
	an evolutionary account.},
  keywords = {Sex difference; Recognition; Facial affect; Emotional processing;
	Reaction time; Evolutionary psychology;litsurvey.bib}
}

@ARTICLE{Holm2010,
  author = {Holm, H{\aa}kan J and Kawagoe, Toshiji},
  title = {Face-to-face lying -- An experimental study in Sweden and Japan},
  journal = {J. Econ. Psychol.},
  year = {2010},
  volume = {31},
  pages = {310--321},
  number = {3},
  month = {\#jun\#},
  abstract = {This paper investigates face-to-face lying and beliefs associated
	with it. In experiments in Sweden and Japan, subjects answer questions
	about personal characteristics, play a face-to-face sender--receiver
	game and participate in an elicitation of lie-detection beliefs.
	The previous finding of too much truth-telling (compared to the equilibrium
	prediction) also holds in the face-to-face setting. A new result
	is that although many people claim that they are good at lie-detection,
	few reveal belief in this ability when money is at stake. Correlations
	between the subjects' characteristics and their behavior and performances
	in the game are also explored.},
  keywords = {Lying; Game theory; Truth detection; Lie-detection; Experiment;litsurvey.bib},
  publisher = {Elsevier}
}

@BOOK{Horgen1999,
  title = {Excellence by design: Transforming workplace and work practice},
  publisher = {John Wiley \& Sons},
  year = {1999},
  author = {Horgen, Turid},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Howard2006,
  author = {Howard, Steve and Kjeldskov, Jesper and Skov, Mikael B and Garn{\ae}s,
	Kasper and Gr{\"u}nberger, Olga},
  title = {Negotiating presence-in-absence: contact, content and context},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2006},
  series = {CHI '06},
  pages = {909--912},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {presence-in-absence, asynchronous, intimacy;litsurvey.bib},
  location = {Montr{\'e}al, Qu{\'e}bec, Canada}
}

@INPROCEEDINGS{Hu1986,
  author = {Hu, G and Jain, A K and Stockman, G},
  title = {{Shape from light stripe texture}},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR}
	'86)},
  year = {1986},
  pages = {412--414},
  address = {Miami},
  keywords = {litsurvey.bib}
}

@ARTICLE{Hua2004,
  author = {Hua, Hong and Brown, Leonard D and Gao, Chunyu},
  title = {Scape: supporting stereoscopic collaboration in augmented and projective
	environments},
  journal = {IEEE Comput. Graph. Appl.},
  year = {2004},
  volume = {24},
  pages = {66--75},
  number = {1},
  month = {\#jan\#},
  keywords = {application program interfaces;augmented reality;data visualisation;groupware;stereo
	image processing;3D environment;API;Scape;application-programming
	interface;augmented reality;collaborative augmented reality system;multimodality
	interface device;multiple user;stereoscopic collaboration;virtual
	reality;widget interface;litsurvey.bib},
  language = {en}
}

@ARTICLE{Hua2004,
  author = {Hua, Hong and Brown, Leonard D and Gao, Chunyu},
  title = {Scape: supporting stereoscopic collaboration in augmented and projective
	environments},
  journal = {IEEE Comput. Graph. Appl.},
  year = {2004},
  volume = {24},
  pages = {66--75},
  number = {1},
  month = {\#jan\#},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {IEEE}
}

@INPROCEEDINGS{Huang2003,
  author = {Huang, Elaine M and Mynatt, Elizabeth D},
  title = {Semi-public displays for small, co-located groups},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2003},
  series = {CHI '03},
  pages = {49--56},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {community, information visualization, awareness, ubiquitous computing,
	peripheral displays;litsurvey.bib},
  location = {Ft. Lauderdale, Florida, USA}
}

@ARTICLE{Hugot2007,
  author = {Hugot, Vanessa},
  title = {Eye gaze analysis in human-human interactions},
  journal = {Unpublished master{\^a}€{\v s}{\~A}„{\~A}´s thesis, CSC, KTH, Sweden},
  year = {2007},
  keywords = {litsurvey.bib},
  publisher = {Citeseer}
}

@INCOLLECTION{Ichikawa1995,
  author = {Ichikawa, Yusuke and Okada, Ken-Ichi and Jeong, Giseok and Tanaka,
	Shunsuke and Matsushita, Yutaka},
  title = {{MAJIC} Videoconferencing System: Experiments, Evaluation and Improvement},
  booktitle = {Proceedings of the Fourth European Conference on {Computer-Supported}
	Cooperative Work {ECSCW} '95: 10--14 September, 1995, Stockholm,
	Sweden},
  publisher = {Springer Netherlands},
  year = {1995},
  editor = {Marmolin, Hans and Sundblad, Yngve and Schmidt, Kjeld},
  pages = {279--292},
  address = {Dordrecht},
  abstract = {We need to know the real intentions of participants that are not expressed
	by verbal languages. This means that not only verbal information
	but also non-verbal information (i.e., gestures, facial expression,
	eyes of participant, etc.) is a very important factor. We proposed
	and implemented MAJIC, a multi-party videoconferencing system that
	enables eye contact among people in remote places, with life-sized
	images of participants.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Ichikawa1995,
  author = {Ichikawa, Yusuke and Okada, Ken-Ichi and Jeong, Giseok and Tanaka,
	Shunsuke and Matsushita, Yutaka},
  title = {{MAJIC} videoconferencing system: experiments, evaluation and improvement},
  booktitle = {Proceedings of the Fourth European Conference on {Computer-Supported}
	Cooperative Work {ECSCW{\^a}€™95}},
  year = {1995},
  pages = {279--292},
  institution = {Springer},
  keywords = {litsurvey.bib}
}

@ARTICLE{ijiri1986framework,
  author = {Ijiri, Yuji},
  title = {A framework for triple-entry bookkeeping},
  journal = {Accounting Review},
  year = {1986},
  pages = {745--759},
  publisher = {JSTOR}
}

@INPROCEEDINGS{Inami2000,
  author = {Inami, Masahiko and Kawakami, Naoki and Sekiguchi, Dairoku and Yanagida,
	Yasuyuki and Maeda, Taro and Tachi, Susumu},
  title = {Visuo-haptic display using head-mounted projector},
  booktitle = {Virtual Reality, 2000. Proceedings. {IEEE}},
  year = {2000},
  pages = {233--240},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@ARTICLE{Isaacs1997,
  author = {Isaacs, Ellen A and Tang, John C},
  title = {Studying video-based collaboration in context: From small workgroups
	to large organizations},
  journal = {Video-mediated communication},
  year = {1997},
  pages = {173--197},
  keywords = {litsurvey.bib},
  publisher = {New Jersey: Lawrence Erlbaum}
}

@INPROCEEDINGS{Ishii1992,
  author = {Ishii, Hiroshi and Kobayashi, Minoru},
  title = {{{ClearBoard}: a seamless medium for shared drawing and conversation
	with eye contact}},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1992},
  series = {CHI '92},
  pages = {525--532},
  address = {New York, NY, USA},
  month = {\#jun\#},
  publisher = {Association for Computing Machinery},
  keywords = {litsurvey.bib},
  location = {Monterey, California, USA}
}

@UNPUBLISHED{Ishii1993,
  author = {Ishii, Hiroshi and Kobayashi, Minoru and Grudin, Jonathan},
  title = {Integration of interpersonal space and shared workspace: {ClearBoard}
	design and experiments},
  month = {\#oct\#},
  year = {1993},
  keywords = {gaze awareness, groupware, gaze direction, seamless design, shared
	drawing, eye contact, video conference;litsurvey.bib}
}

@INPROCEEDINGS{Itoh2005,
  author = {Itoh, Kazuko and Miwa, Hiroyasu and Onishi, Yoshitaka and Imanishi,
	Kazutaka and Hayashi, Kouki and Takanishi, Atsuo},
  title = {Development of face robot to express the individual face by optimizing
	the facial features},
 booktitle = {Humanoid Robots,
	International Conference on},
  year = {2005},
  pages = {412--417},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@ARTICLE{Iverson2005,
  author = {Iverson, Jana M and Goldin-Meadow, Susan},
  title = {Gesture paves the way for language development},
  journal = {Psychol. Sci.},
  year = {2005},
  volume = {16},
  pages = {367--371},
  number = {5},
  month = {\#may\#},
  abstract = {In development, children often use gesture to communicate before they
	use words. The question is whether these gestures merely precede
	language development or are fundamentally tied to it. We examined
	10 children making the transition from single words to two-word combinations
	and found that gesture had a tight relation to the children's lexical
	and syntactic development. First, a great many of the lexical items
	that each child produced initially in gesture later moved to that
	child's verbal lexicon. Second, children who were first to produce
	gesture-plus-word combinations conveying two elements in a proposition
	(point at bird and say ``nap'') were also first to produce two-word
	combinations (``bird nap''). Changes in gesture thus not only predate
	but also predict changes in language, suggesting that early gesture
	may be paving the way for future developments in language.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@BOOK{Jacko2007,
  title = {{Human-Computer} Interaction. Interaction Design and Usability: 12th
	International Conference, {HCI} International 2007, Beijing, China,
	July 22-27, 2007, Proceedings, Part {I}},
  publisher = {Springer Berlin Heidelberg},
  year = {2007},
  editor = {Jacko, Julie A},
  author = {Jacko, Julie A},
  volume = {4550},
  pages = {802--811},
  series = {Lecture Notes in Computer Science},
  address = {Berlin, Heidelberg},
  month = {\#jul\#},
  abstract = {The 12th International Conference on Human-Computer Interaction, HCI
	Inter- tional 2007, was held in Beijing, P.R. China, 22-27 July 2007,
	jointly with the S- posium on Human Interface (Japan) 2007, the 7th
	International Conference on Engineering Psychology and Cognitive
	Ergonomics, the 4th International Conference on Universal Access
	in Human-Computer Interaction, the 2nd International Conf- ence on
	Virtual Reality, the 2nd International Conference on Usability and
	Inter- tionalization, the 2nd International Conference on Online
	Communities and Social Computing, the 3rd International Conference
	on Augmented Cognition, and the 1st International Conference on Digital
	Human Modeling. A total of 3403 individuals from academia, research
	institutes, industry and g- ernmental agencies from 76 countries
	submitted contributions, and 1681 papers, judged to be of high scientific
	quality, were included in the program. These papers address the latest
	research and development efforts and highlight the human aspects
	of design and use of computing systems. The papers accepted for presentation
	th- oughly cover the entire field of Human-Computer Interaction,
	addressing major - vances in knowledge and effective use of computers
	in a variety of application areas. This volume, edited by Julie A.
	Jacko, contains papers in the thematic area of Human-Computer Interaction,
	addressing the following major topics: • Interaction Design: Theoretical
	Issues, Methods, Techniques and Practice • Usability and Evaluation
	Methods and Tools • Understanding Users and Contexts of Use • Models
	and Patterns in HCI},
  keywords = {Computer Science;litsurvey.bib},
  language = {en}
}

@INPROCEEDINGS{Jacob2008,
  author = {Jacob, Robert J K and Girouard, Audrey and Hirshfield, Leanne M and
	Horn, Michael S and Shaer, Orit and Solovey, Erin Treacy and Zigelbaum,
	Jamie},
  title = {Reality-based interaction: a framework for {post-WIMP} interfaces},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2008},
  series = {CHI '08},
  pages = {201--210},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {multimodal, interaction styles, reality-based interaction, next-generation,
	virtual reality, tangible interfaces, context-aware, post-wimp interfaces,
	ubiquitous computing;litsurvey.bib},
  location = {Florence, Italy}
}

@INPROCEEDINGS{Jamil2011,
  author = {Jamil, Izdihar and O'Hara, Kenton and Perry, Mark and Karnik, Abhijit
	and Subramanian, Sriram},
  title = {The effects of interaction techniques on talk patterns in collaborative
	peer learning around interactive tables},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {3043--3052},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {communication, interaction techniques, children, collaborative learning,
	tabletop;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@INPROCEEDINGS{Jan2007,
  author = {Jan, Du{\v s}an and Traum, David R},
  title = {Dynamic movement and positioning of embodied agents in multiparty
	conversations},
  booktitle = {Proceedings of the Workshop on Embodied Language Processing},
  year = {2007},
  series = {EmbodiedNLP '07},
  pages = {59--66},
  address = {USA},
  month = {\#jun\#},
  publisher = {Association for Computational Linguistics},
  institution = {Association for Computational Linguistics},
  keywords = {litsurvey.bib},
  location = {Prague, Czech Republic}
}

@ARTICLE{Jarvenpaa1988,
  author = {Jarvenpaa, Sirkka L and Rao, V Srinivasan and Huber, George P},
  title = {Computer Support for Meetings of Groups Working on Unstructured Problems:
	A Field Experiment},
  journal = {Miss. Q.},
  year = {1988},
  volume = {12},
  pages = {645--666},
  number = {4},
  abstract = {[This preliminary study was conducted to learn about the consequences
	of computer support for teams working on unstructured, high-level
	conceptual software design problems in face-to-face group settings.
	A networked workstation technology and electronic blackboard technology
	were contrasted with their conventional counterparts. Twenty-one
	software designers, assigned to three teams, performed team tasks
	that involved generating ideas and reaching consensus. Positive effects
	on the thoroughness of information exchange and quality of team performance
	were found in the meetings in which electronic blackboard technology
	was available. The networked workstations provided mixed results.
	Significant team differences were found in performance and interaction
	measures. The results and their implications are discussed in terms
	of the necessary future developments and nature of future research
	in computer-based meeting support technology.]},
  keywords = {litsurvey.bib},
  publisher = {Management Information Systems Research Center, University of Minnesota}
}

@INPROCEEDINGS{Jetter2011,
  author = {Jetter, Hans-Christian and Gerken, Jens and Z{\"o}llner, Michael
	and Reiterer, Harald and Milic-Frayling, Natasa},
  title = {Materializing the query with facet-streams: a hybrid surface for
	collaborative search on tabletops},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {3013--3022},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {collaborative search, tangible user interfaces, tabletop;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@ARTICLE{Jin2015,
  author = {Jin, Xiaolong and Wah, Benjamin W and Cheng, Xueqi and Wang, Yuanzhuo},
  title = {Significance and challenges of big data research},
  journal = {Big Data Research},
  year = {2015},
  volume = {2},
  pages = {59--64},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S2214579615000076-main.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Johnson1998,
  author = {Johnson, Scott},
  title = {What's in a representation, why do we care, and what does it mean?
	Examining evidence from psychology},
  journal = {Autom. Constr.},
  year = {1998},
  volume = {8},
  pages = {15--24},
  number = {1},
  month = {\#nov\#},
  abstract = {This paper examines psychological evidence on the nature and role
	of representations in cognition. Both internal (mental) and external
	(physical or digital) representations are considered. It is discovered
	that both types of representation are deeply linked to thought processes.
	They are linked to learning, the ability to use existing knowledge,
	and problem solving strategies. The links between representations,
	thought processes, and behavior are so deep that even eye movements
	are partly governed by representations. Choice of representations
	can affect limited cognitive resources like attention and short-term
	memory by forcing a person to try to utilize poorly organized information
	or perform `translations' from one representation to another. The
	implications of this evidence are discussed. Based on these findings,
	a set of guidelines are presented, for digital representations which
	minimize drain of cognitive resources. These guidelines describe
	what sorts of characteristics and behaviors a representation should
	exhibit, and what sorts of information it should contain in order
	to accommodate and facilitate design. Current attempts to implement
	such representations are discussed.},
  keywords = {Representation in cognition; Learning; Thought process;litsurvey.bib},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Jones2009,
  author = {Jones, Andrew and Lang, Magnus and Fyffe, Graham and Yu, Xueming
	and Busch, Jay and McDowall, Ian and Bolas, Mark and Debevec, Paul},
  title = {{HeadSPIN}: a one-to-many {3D} video teleconferencing system},
  booktitle = {{ACM} {SIGGRAPH} 2009 Emerging Technologies},
  year = {2009},
  number = {Article 13},
  series = {SIGGRAPH '09},
  pages = {1},
  address = {New York, NY, USA},
  month = {\#aug\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {New Orleans, Louisiana}
}

@INPROCEEDINGS{Jones2009,
  author = {Jones, Andrew and Lang, Magnus and Fyffe, Graham and Yu, Xueming
	and Busch, Jay and McDowall, Ian and Bolas, Mark and Debevec, Paul},
  title = {{Achieving eye contact in a one-to-many {3D} video teleconferencing
	system}},
  booktitle = {{ACM} {SIGGRAPH} 2009 papers},
  year = {2009},
  volume = {28},
  number = {Article 64},
  series = {SIGGRAPH '09},
  pages = {1--8},
  address = {New York, NY, USA},
  month = {\#jul\#},
  publisher = {Association for Computing Machinery},
  keywords = {litsurvey.bib},
  location = {New Orleans, Louisiana}
}

@INPROCEEDINGS{Jones2014,
  author = {Jones, Brett and Sodhi, Rajinder and Murdock, Michael and Mehra,
	Ravish and Benko, Hrvoje and Wilson, Andrew and Ofek, Eyal and MacIntyre,
	Blair and Raghuvanshi, Nikunj and Shapira, Lior},
  title = {{RoomAlive}: magical experiences enabled by scalable, adaptive projector-camera
	units},
  booktitle = {Proceedings of the 27th annual {ACM} symposium on User interface
	software and technology},
  year = {2014},
  series = {UIST '14},
  pages = {637--644},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {spatial augmented reality, projection mapping, projector-camera system;litsurvey.bib},
  location = {Honolulu, Hawaii, USA}
}

@INPROCEEDINGS{Jones1971,
  author = {Jones, Edward Ellsworth and Nisbett, Richard E},
  title = {The Actor And The Observer: Divergent Perceptions Of The Causes Of
	Behavior},
  year = {1971},
  publisher = {General Learning Press Morristown, NJ},
  keywords = {litsurvey.bib}
}

@ARTICLE{jones2008trust,
  author = {Jones, Kiku and Leonard, Lori NK},
  title = {Trust in consumer-to-consumer electronic commerce},
  journal = {Information \& management},
  year = {2008},
  volume = {45},
  pages = {88--95},
  number = {2},
  publisher = {Elsevier}
}

@InProceedings{Jouppi2004,
  author    = {Jouppi, Norman P and Iyer, Subu and Thomas, Stan and Slayden, April},
  booktitle = {Proceedings of the 12th annual ACM international conference on Multimedia},
  title     = {Bireality: mutually-immersive telepresence},
  year      = {2004},
  pages     = {860--867},
}

@INPROCEEDINGS{Jouppi2002,
  author = {Jouppi, Norman P and Pan, Michael J},
  title = {Mutually-immersive audio telepresence},
  booktitle = {Audio Engineering Society Convention 113},
  year = {2002},
  institution = {Audio Engineering Society},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Judge2010,
  author = {Judge, Tejinder K and Neustaedter, Carman},
  title = {Sharing conversation and sharing life: video conferencing in the
	home},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2010},
  series = {CHI '10},
  pages = {655--658},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {families, media spaces, domestic, video conferencing;litsurvey.bib},
  location = {Atlanta, Georgia, USA}
}

@INPROCEEDINGS{Junuzovic2012,
  author = {Junuzovic, Sasa and Inkpen, Kori and Tang, John and Sedlins, Mara
	and Fisher, Kristie},
  title = {To see or not to see: a study comparing four-way avatar, video, and
	audio conferencing for work},
  booktitle = {Proceedings of the 17th {ACM} international conference on Supporting
	group work},
  year = {2012},
  series = {GROUP '12},
  pages = {31--34},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {video, audio, conferencing, distributed teams, avatar;litsurvey.bib},
  location = {Sanibel Island, Florida, USA}
}

@BOOK{Kalawsky2004,
  title = {{Science of Virtual Reality and Virtual Environments}},
  publisher = {Addison Wesley Longman Publishing Co., Inc},
  year = {2004},
  author = {Kalawsky, Roy S},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Kang2008,
  author = {Kang, Sin-Hwa and Watt, James H and Ala, Sasi Kanth},
  title = {Social copresence in anonymous social interactions using a mobile
	video telephone},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2008},
  series = {CHI '08},
  pages = {1535--1544},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {social copresence, avatar realism, affective behavior, social presence,
	mobile phone communication, anonymity;litsurvey.bib},
  location = {Florence, Italy}
}

@INPROCEEDINGS{Karahalios2004,
  author = {Karahalios, Karrie and Donath, Judith},
  title = {Telemurals: linking remote spaces with social catalysts},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2004},
  series = {CHI '04},
  pages = {615--622},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {mediated spaces, video, mediated communication, social catalyst, remote
	connections, telepresence, ethnography, social interaction;litsurvey.bib},
  location = {Vienna, Austria}
}

@INPROCEEDINGS{Kashagiri2007,
  author = {Kashagiri, Yasuhero},
  title = {Aiduti in Japanese multi-party design conversations},
  year = {2007},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Kauff2002,
  author = {Kauff, Peter and Schreer, Oliver},
  title = {An immersive {3D} video-conferencing system using shared virtual
	team user environments},
  booktitle = {Proceedings of the 4th international conference on Collaborative
	virtual environments},
  year = {2002},
  series = {CVE '02},
  pages = {105--112},
  address = {New York, NY, USA},
  month = {\#sep\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {presence research, image based rendering, disparity estimation, MPEG-4
	video coding, shared virtual table environment, tele-cubicles, next
	generation video conference, tele-immersion, arbitrarily shaped video
	objects, 3D video processing;litsurvey.bib},
  location = {Bonn, Germany}
}

@INPROCEEDINGS{Kauff2002,
  author = {Kauff, Peter and Schreer, Oliver},
  title = {Virtual team user environments-a step from tele-cubicles towards
	distributed tele-collaboration in mediated workspaces},
  booktitle = {Multimedia and Expo, 2002. {ICME'02}. Proceedings. 2002 {IEEE} International
	Conference on},
  year = {2002},
  volume = {2},
  pages = {9--12},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Kauff2002,
  author = {Kauff, Peter and Schreer, Oliver},
  title = {Virtual team user environments-a step from tele-cubicles towards
	distributed tele-collaboration in mediated workspaces},
  booktitle = {Multimedia and Expo, 2002. {ICME'02}. Proceedings. 2002 {IEEE} International
	Conference on},
  year = {2002},
  volume = {2},
  pages = {9--12},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@ARTICLE{Kendon1967,
  author = {Kendon, A},
  title = {{Some functions of gaze-direction in social interaction.}},
  journal = {Acta Psychol.},
  year = {1967},
  volume = {26},
  pages = {22--63},
  number = {1},
  abstract = {Films of two-person conversations were transcribed and analyzed from
	the point of view of how gaze direction is related to utterance and
	silence. It was found that patterns of looking were systematically
	related to features of talk and could be accounted for in terms of
	the monitoring functions of gaze. At the same time, evidence was
	presented that suggested that gaze direction may also play a role
	in the regulation of turn-taking in conversation.},
  keywords = {litsurvey.bib},
  publisher = {Elsevier BV, Radarweg 29, Amsterdam, 1043 NX, Netherlands,}
}

@INPROCEEDINGS{Kim2012,
  author = {Kim, Kibum and Bolton, John and Girouard, Audrey and Cooperstock,
	Jeremy and Vertegaal, Roel},
  title = {{TeleHuman}: effects of 3d perspective on gaze and pose estimation
	with a life-size cylindrical telepresence pod},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {2531--2540},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {motion parallax, cylindrical display, videoconference, organic user
	interfaces, 3d video, telepresence;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@ARTICLE{Kim2015,
  author = {Kim, Seong-Pil and Kwon, Ohung},
  title = {Development of a Moon Exploring Simulator},
  journal = {한국콘 ?츠학회 ICCC 논문집},
  year = {2015},
  pages = {51--52},
  keywords = {litsurvey.bib}
}

@ARTICLE{Kleinke1986,
  author = {Kleinke, C L},
  title = {Gaze and eye contact: a research review},
  journal = {Psychol. Bull.},
  year = {1986},
  volume = {100},
  pages = {78--100},
  number = {1},
  month = {\#jul\#},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {American Psychological Association}
}

@ARTICLE{Kleinsmith2013,
  author = {Kleinsmith, A and Bianchi-Berthouze, N},
  title = {Affective Body Expression Perception and Recognition: A Survey},
  journal = {IEEE Transactions on Affective Computing},
  year = {2013},
  volume = {4},
  pages = {15--33},
  number = {1},
  month = {\#jan\#},
  abstract = {Thanks to the decreasing cost of whole-body sensing technology and
	its increasing reliability, there is an increasing interest in, and
	understanding of, the role played by body expressions as a powerful
	affective communication channel. The aim of this survey is to review
	the literature on affective body expression perception and recognition.
	One issue is whether there are universal aspects to affect expression
	perception and recognition models or if they are affected by human
	factors such as culture. Next, we discuss the difference between
	form and movement information as studies have shown that they are
	governed by separate pathways in the brain. We also review psychological
	studies that have investigated bodily configurations to evaluate
	if specific features can be identified that contribute to the recognition
	of specific affective states. The survey then turns to automatic
	affect recognition systems using body expressions as at least one
	input modality. The survey ends by raising open questions on data
	collecting, labeling, modeling, and setting benchmarks for comparing
	automatic recognition systems.},
  keywords = {pattern recognition;affective body expression perception;affective
	body expression recognition;whole-body sensing technology;affective
	communication channel;human factor;form information;movement information;input
	modality;data collection;data labeling;data modeling;automatic recognition
	system;Face recognition;Emotion recognition;Data models;Cultural
	differences;Face recognition;Emotion recognition;Data models;Cultural
	differences;spatiotemporal affective body features;Affective body
	posture;affective body movement;affective recognition systems;cross-cultural
	differences;litsurvey.bib},
  publisher = {IEEE}
}

@INPROCEEDINGS{Klie2006,
  author = {Klie, Patrick and B{\"u}schenfeld, Torsten and Ostermann, J{\"o}rn},
  title = {Vipid-virtual 3d person models for intuitive dialog systems},
  booktitle = {{IEEE} Workshop on Content Generation and Coding for 3D-television},
  year = {2006},
  volume = {1},
  keywords = {litsurvey.bib}
}

@Article{Kluttz2009,
  author    = {Kluttz, Nathan L and Mayes, Brandon R and West, Roger W and Kerby, Dave S},
  journal   = {Vision Res.},
  title     = {The effect of head turn on the perception of gaze},
  year      = {2009},
  month     = {\#jul\#},
  number    = {15},
  pages     = {1979--1993},
  volume    = {49},
  abstract  = {When subjects viewed straight and turned eyes that were isolated singly
	or in pairs from a head that was straight or turned, they underestimated
	their true direction of gaze. They also underestimated the direction
	of head turn when both eyes were closed. However, the judged direction
	of gaze was improved when the eyes were layered against the heads.
	Judged direction of averted gaze was primarily based on the abducting
	eye. The effect that the deviation between an eye's optical axis
	and its true direction of gaze (angle kappa) has on its judged direction
	of gaze is discussed.},
  keywords  = {Adult, Attention, Cues, Eye Movements, Female, Head Movements, Humans, Male, Models, Psychological, Optical Illusions, Psychophysics, Visual Perception, Visual Perception: physiology, Young Adult;litsurvey.bib},
  language  = {en},
  publisher = {Elsevier Ltd},
}

@ARTICLE{Kluttz2009,
  author = {Kluttz, Nathan L and Mayes, Brandon R and West, Roger W and Kerby,
	Dave S},
  title = {The effect of head turn on the perception of gaze},
  journal = {Vision Res.},
  year = {2009},
  volume = {49},
  pages = {1979--1993},
  number = {15},
  month = {\#jul\#},
  abstract = {When subjects viewed straight and turned eyes that were isolated singly
	or in pairs from a head that was straight or turned, they underestimated
	their true direction of gaze. They also underestimated the direction
	of head turn when both eyes were closed. However, the judged direction
	of gaze was improved when the eyes were layered against the heads.
	Judged direction of averted gaze was primarily based on the abducting
	eye. The effect that the deviation between an eye's optical axis
	and its true direction of gaze (angle kappa) has on its judged direction
	of gaze is discussed.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Knoblauch2008,
  author = {Knoblauch, Daniel and Kuester, Falko},
  title = {{VirtualizeMe}: interactive model reconstruction from stereo video
	streams},
  booktitle = {Proceedings of the 2008 {ACM} symposium on Virtual reality software
	and technology},
  year = {2008},
  series = {VRST '08},
  pages = {193--196},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {point cloud streaming, background extraction, tele-immersion, disparity
	maps, 3D from video;litsurvey.bib},
  location = {Bordeaux, France}
}

@ARTICLE{Kollock1998,
  author = {Kollock, Peter},
  title = {Social Dilemmas: The Anatomy of Cooperation},
  journal = {Annu. Rev. Sociol.},
  year = {1998},
  volume = {24},
  pages = {183--214},
  number = {1},
  month = {\#aug\#},
  abstract = {The study of social dilemmas is the study of the tension between individual
	and collective rationality. In a social dilemma, individually reasonable
	behavior leads to a situation in which everyone is worse off. The
	first part of this review is a discussion of categories of social
	dilemmas and how they are modeled. The key two-person social dilemmas
	(Prisoner's Dilemma, Assurance, Chicken) and multiple-person social
	dilemmas (public goods dilemmas and commons dilemmas) are examined.
	The second part is an extended treatment of possible solutions for
	social dilemmas. These solutions are organized into three broad categories
	based on whether the solutions assume egoistic actors and whether
	the structure of the situation can be changed: Motivational solutions
	assume actors are not completely egoistic and so give some weight
	to the outcomes of their partners. Strategic solutions assume egoistic
	actors, and neither of these categories of solutions involve changing
	the fundamental structure of the situation. Solutions that do involve
	changing the rules of the game are considered in the section on structural
	solutions. I conclude the review with a discussion of current research
	and directions for future work.},
  keywords = {litsurvey.bib},
  publisher = {Annual Reviews}
}

@ARTICLE{Kouvril2018,
  author = {Kou{\v{r}}il, David and {\v{C}}mol{\'\i}k, Ladislav and Kozl{\'\i}kov{\'a},
	Barbora and Wu, Hslanc-Yun and Johnson, Graham and Goodsell, David
	S and Olson, Arthur and Gr{\"o}ller, M Eduard and Viola, Ivan},
  title = {Labels on levels: labeling of multi-scale multi-instance and crowded
	3D biological environments},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {977--986},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440077.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Kouvril2018a,
  author = {Kou{\v{r}}il, David and {\v{C}}mol{\'\i}k, Ladislav and Kozl{\'\i}kov{\'a},
	Barbora and Wu, Hslanc-Yun and Johnson, Graham and Goodsell, David
	S and Olson, Arthur and Gr{\"o}ller, M Eduard and Viola, Ivan},
  title = {Labels on levels: labeling of multi-scale multi-instance and crowded
	3D biological environments},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {977--986},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/kouril-2018-LoL-paper.pdf:PDF},
  publisher = {IEEE}
}

@INCOLLECTION{Krauss1996,
  author = {Krauss, Robert M and Chen, Yihsiu and Chawla, Purnima},
  title = {Nonverbal Behavior and Nonverbal Communication: What do Conversational
	Hand Gestures Tell Us?},
  booktitle = {Advances in Experimental Social Psychology},
  publisher = {Academic Press},
  year = {1996},
  editor = {Zanna, Mark P},
  volume = {28},
  pages = {389--450},
  month = {\#jan\#},
  abstract = {Publisher Summary This chapter explores how gestures contribute to
	comprehension, how gesturing affect speech and what can be learned
	from studying conversational gestures. The primary function of conversational
	hand gestures is to aid in the formulation of speech. Gestures can
	convey nonsemantic information. The study of speech and gestures
	overlaps with the study of person perception and attribution processes.
	The significance of gestures can be ambiguous and will affect the
	meanings and consequences to the observed gestures. A topology of
	gestures is adopters, symbolic gestures, and conversational gestures.
	Different types of conversational gestures can be distinguished as---namely,
	motor movements and lexical movements. Conversational hand gestures
	have been assumed to convey semantic information. Several studies
	that attempt to assess the kinds of information conversational gestures
	convey to naive observers and the extent to which gestures enhance
	the communicativeness of spoken messages are described in the chapter.},
  keywords = {litsurvey.bib}
}

@INCOLLECTION{Krauss1996,
  author = {Krauss, Robert M and Chen, Yihsiu and Chawla, Purnima},
  title = {Nonverbal Behavior and Nonverbal Communication: What do Conversational
	Hand Gestures Tell Us?},
  booktitle = {Advances in Experimental Social Psychology},
  publisher = {Academic Press},
  year = {1996},
  editor = {Zanna, Mark P},
  volume = {28},
  pages = {389--450},
  month = {\#jan\#},
  abstract = {Publisher Summary This chapter explores how gestures contribute to
	comprehension, how gesturing affect speech and what can be learned
	from studying conversational gestures. The primary function of conversational
	hand gestures is to aid in the formulation of speech. Gestures can
	convey nonsemantic information. The study of speech and gestures
	overlaps with the study of person perception and attribution processes.
	The significance of gestures can be ambiguous and will affect the
	meanings and consequences to the observed gestures. A topology of
	gestures is adopters, symbolic gestures, and conversational gestures.
	Different types of conversational gestures can be distinguished as---namely,
	motor movements and lexical movements. Conversational hand gestures
	have been assumed to convey semantic information. Several studies
	that attempt to assess the kinds of information conversational gestures
	convey to naive observers and the extent to which gestures enhance
	the communicativeness of spoken messages are described in the chapter.},
  keywords = {litsurvey.bib}
}

@ARTICLE{Kristoffersson2013,
  author = {Kristoffersson, Annica and Coradeschi, Silvia and Loutfi, Amy},
  title = {A Review of Mobile Robotic Telepresence},
  journal = {Advances in Human-Computer Interaction},
  year = {2013},
  volume = {2013},
  pages = {3},
  month = {\#apr\#},
  abstract = {Mobile robotic telepresence (MRP) systems incorporate video conferencing
	equipment onto mobile robot devices which can be steered from remote
	locations. These systems, which are primarily used in the context
	of promoting social interaction between people, are becoming increasingly
	popular within certain application domains such as health care environments,
	independent living for the elderly, and office environments. In this
	paper, an overview of the various systems, application areas, and
	challenges found in the literature concerning mobile robotic telepresence
	is provided. The survey also proposes a set terminology for the field
	as there is currently a lack of standard terms for the different
	concepts related to MRP systems. Further, this paper provides an
	outlook on the various research directions for developing and enhancing
	mobile robotic telepresence systems per se, as well as evaluating
	the interaction in laboratory and field settings. Finally, the survey
	outlines a number of design implications for the future of mobile
	robotic telepresence systems for social interaction.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Hindawi}
}

@INCOLLECTION{Kristoffersson2011,
  author = {Kristoffersson, Annica and Coradeschi, Silvia and Severinson Eklundh,
	Kerstin and Loutfi, Amy},
  title = {Sense of Presence in a Robotic Telepresence Domain: 6th International
	Conference, {UAHCI} 2011, Held as Part of {HCI} International 2011,
	Orlando, {FL}, {USA}, July 9-14, 2011, Proceedings, Part {II}},
  booktitle = {Universal Access in {Human-Computer} Interaction. Users Diversity},
  publisher = {Springer Berlin Heidelberg},
  year = {2011},
  editor = {Stephanidis, Constantine},
  volume = {6766},
  series = {Lecture Notes in Computer Science},
  pages = {479--487},
  address = {Berlin, Heidelberg},
  keywords = {litsurvey.bib}
}

@ARTICLE{Krum2012,
  author = {Krum, David M and Suma, Evan A and Bolas, Mark},
  title = {Augmented reality using personal projection and retroreflection},
  journal = {Pers. Ubiquit. Comput.},
  year = {2012},
  volume = {16},
  pages = {17--26},
  number = {1},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@ARTICLE{Kubota2007,
  author = {Kubota, A and Smolic, A and Magnor, M and Tanimoto, M and Chen, T
	and Zhang, C},
  title = {Multiview Imaging and {3DTV}},
  journal = {IEEE Signal Process. Mag.},
  year = {2007},
  volume = {24},
  pages = {10--21},
  number = {6},
  month = {\#nov\#},
  abstract = {The eight articles in this special section are devoted to multi-view
	imaging and three dimensional television displays.},
  keywords = {Cameras;Layout;Rendering (computer graphics);Image coding;Displays;Costs;TV;Application
	software;Stereo vision;Navigation;litsurvey.bib}
}

@INPROCEEDINGS{Kulik2011,
  author = {Kulik, Alexander and Kunert, Andr{\'e} and Beck, Stephan and Reichel,
	Roman and Blach, Roland and Zink, Armin and Froehlich, Bernd},
  title = {C1x6: a stereoscopic six-user display for co-located collaboration
	in shared virtual environments},
  booktitle = {Proceedings of the 2011 {SIGGRAPH} Asia Conference},
  year = {2011},
  volume = {30},
  number = {Article 188},
  series = {SA '11},
  pages = {1--12},
  address = {New York, NY, USA},
  month = {\#dec\#},
  publisher = {Association for Computing Machinery},
  keywords = {display technology, virtual reality, collaboration;litsurvey.bib},
  location = {Hong Kong, China}
}

@INPROCEEDINGS{Kum2003,
  author = {Kum, Sang-Uok and Mayer-Patel, Ketan and Fuchs, Henry},
  title = {Real-time compression for dynamic {3D} environments},
  booktitle = {Proceedings of the eleventh {ACM} international conference on Multimedia},
  year = {2003},
  series = {MULTIMEDIA '03},
  pages = {185--194},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {virtual reality, tele-immersion, K-Means algorithm, real-time compression,
	K-Means initialization;litsurvey.bib},
  location = {Berkeley, CA, USA}
}

@INPROCEEDINGS{Kurillo2008,
  author = {Kurillo, G and Bajcsy, R and Nahrsted, K and Kreylos, O},
  title = {{Immersive {3D} Environment for Remote Collaboration and Training
	of Physical Activities}},
  booktitle = {2008 {IEEE} Virtual Reality Conference},
  year = {2008},
  pages = {269--270},
  address = {Reno},
  month = {\#mar\#},
  abstract = {In this paper we present a framework for immersive virtual environment
	intended for remote collaboration and training of physical activities.
	Our multi-camera system performs full-body 3D reconstruction of human
	user(s) in real time and renders their image in the virtual space
	allowing remote users to interact. The paper features a short overview
	of the technology used for the capturing and reconstruction. Some
	of the applications where we have successfully demonstrated use of
	the system in combination with the tele-immersive virtual environment
	are described. Finally, we address current drawbacks with regard
	to data capturing and networking and provide some ideas for future
	work.},
  keywords = {image reconstruction;stereo image processing;virtual reality;immersive
	3D virtual environment;remote collaboration;physical activity training;multi-camera
	system;full-body 3D reconstruction;Collaboration;Image reconstruction;Cameras;Humans;Real
	time systems;Rendering (computer graphics);Space technology;Avatars;Virtual
	environment;Computer vision;3D reconstruction;immersion;real-time
	systems;remote collaboration;tele-immersion;H.5.1 [Information Interfaces
	and Presentation]: Multimedia Information Systems-Artificial, Augmented,
	and Virtual Realities;I.4.10 [Image Processing and Computer Vision]:
	Image Representation\?\`Volumetric;litsurvey.bib}
}

@UNPUBLISHED{Kuster2012,
  author = {Kuster, Claudia and Popa, Tiberiu and Bazin, Jean-Charles and Gotsman,
	Craig and Gross, Markus},
  title = {{Gaze correction for home video conferencing}},
  month = {\#nov\#},
  year = {2012},
  keywords = {gaze correction, depth camera, video conferencing;litsurvey.bib},
  number = {Article 174}
}

@INPROCEEDINGS{Kuster2012,
  author = {Kuster, Claudia and Popa, Tiberiu and Bazin, Jean-Charles and Gotsman,
	Craig and Gross, Markus},
  title = {Gaze Correction For Home Video Conferencing},
  year = {2012},
  volume = {31},
  pages = {174},
  publisher = {ACM},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Kuster2012,
  author = {Kuster, Claudia and Popa, Tiberiu and Bazin, Jean-Charles and Gotsman,
	Craig and Gross, Markus},
  title = {Gaze correction for home video conferencing},
  month = {\#nov\#},
  year = {2012},
  keywords = {gaze correction, depth camera, video conferencing;litsurvey.bib},
  number = {Article 174}
}

@INPROCEEDINGS{Kuster2012,
  author = {Kuster, C and Ranieri, N and {Agustina} and Zimmer, H and Bazin,
	J C and Sun, C and Popa, T and Gross, M},
  title = {Towards next generation {3D} teleconferencing systems},
  booktitle = {2012 {3DTV-Conference}: The True Vision - Capture, Transmission and
	Display of {3D} Video ({3DTV-CON})},
  year = {2012},
  pages = {1--4},
  month = {\#oct\#},
  abstract = {Teleconferencing is becoming more and more important and popular in
	today's society and is mostly accomplished using 2D video conferencing
	systems. However, we believe there is a lot of room for improving
	the communication experience: one crucial aspect is to add 3D information,
	but also freeing the user from sitting in front of a computer. With
	these improvements, we aim at eventually creating a fully immersive
	3D telepresence system that might improve the way we communicate
	over long distances. In this paper we review and analyze existing
	technology to achieve this goal and present a proof-of-concept, but
	fully functional prototype.},
  institution = {IEEE},
  keywords = {teleconferencing;virtual reality;next generation 3D teleconferencing;fully
	immersive 3D telepresence system;3D display;3D acquisition;Three
	dimensional displays;Cameras;Prototypes;Teleconferencing;Bandwidth;Streaming
	media;Geometry;3D teleconferencing;3D display;3D acquisition;litsurvey.bib}
}

@INPROCEEDINGS{Kyoung_Shin_Park1999,
  author = {{Kyoung Shin Park} and Kenyon, R V},
  title = {Effects of network characteristics on human performance in a collaborative
	virtual environment},
  booktitle = {Proceedings {IEEE} Virtual Reality (Cat. No. {99CB36316})},
  year = {1999},
  pages = {104--111},
  month = {\#mar\#},
  abstract = {We assessed the effects of network latency and jitter on a cooperative
	teleoperation task in a collaborative virtual environment. Two remote
	partners worked together to manipulate shared virtual objects over
	a network. The task was to minimize the time to transfer a ring through
	one of four paths with the least number of collisions. The performance
	of human subjects was measured and analyzed quantitatively as a function
	of network latency: 10 and 200 msec delays with and without jitter.
	Jitter had the greatest impact on coordination performance when the
	latency was high and the task was difficult. These results are discussed
	in light of current and future CVE tasks.},
  institution = {IEEE},
  keywords = {jitter;virtual reality;local area networks;ISDN;quality of service;wide
	area networks;groupware;network characteristics;human performance;collaborative
	virtual environment;network latency;jitter;cooperative teleoperation
	task;shared virtual objects;Humans;Intelligent networks;Collaboration;Virtual
	environment;Delay;Jitter;Quality of service;Collaborative work;Optical
	design;Wide area networks;litsurvey.bib}
}

@INPROCEEDINGS{Laber2018a,
  author = {Laber, Eduardo and Molinaro, Marco and Pereira, Felipe Mello},
  title = {Binary partitions with approximate minimum impurity},
  booktitle = {International Conference on Machine Learning},
  year = {2018},
  pages = {2854--2862},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/laber18a.pdf:PDF}
}

@ARTICLE{Laber2018,
  author = {Laber, Eduardo Sany and Pereira, Felipe de A Mello},
  title = {Splitting criteria for classification problems with multi-valued
	attributes and large number of classes},
  journal = {Pattern Recognition Letters},
  year = {2018},
  volume = {111},
  pages = {58--63},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/1-s2.0-S0167865518301338-main.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Ladikos2008,
  author = {Ladikos, A and Benhimane, S and Navab, N},
  title = {{Efficient visual hull computation for real-time {3D} reconstruction
	using {CUDA}}},
  booktitle = {2008 {IEEE} Computer Society Conference on Computer Vision and Pattern
	Recognition Workshops},
  year = {2008},
  pages = {1--8},
  address = {Anchorage},
  month = {\#jun\#},
  abstract = {In this paper we present two efficient GPU-based visual hull computation
	algorithms. We compare them in terms of performance using image sets
	of varying size and different voxel resolutions. In addition, we
	present a real-time 3D reconstruction system which uses the proposed
	GPU-based reconstruction method to achieve real-time performance
	(30 fps) using 16 cameras and 4 PCs.},
  keywords = {computational geometry;image reconstruction;image resolution;visual
	hull computation;real-time 3D reconstruction;CUDA;GPU;image sets;voxel
	resolutions;real-time performance;Image reconstruction;Cameras;Real
	time systems;Reconstruction algorithms;Personal communication networks;Shape;Hardware;Image
	segmentation;Distributed computing;Computer science;litsurvey.bib}
}

@ARTICLE{Lamboray2005,
  author = {Lamboray, Edouard and W{\"u}rmlin, Stephan and Gross, Markus},
  title = {Data streaming in telepresence environments},
  journal = {IEEE Trans. Vis. Comput. Graph.},
  year = {2005},
  volume = {11},
  pages = {637--648},
  number = {6},
  month = {\#nov\#},
  abstract = {In this paper, we discuss data transmission in telepresence environments
	for collaborative virtual reality applications. We analyze data streams
	in the context of networked virtual environments and classify them
	according to their traffic characteristics. Special emphasis is put
	on geometry-enhanced (3D) video. We review architectures for real-time
	3D video pipelines and derive theoretical bounds on the minimal system
	latency as a function of the transmission and processing delays.
	Furthermore, we discuss bandwidth issues of differential update coding
	for 3D video. In our telepresence system-the blue-c-we use a point-based
	3D video technology which allows for differentially encoded 3D representations
	of human users. While we discuss the considerations which lead to
	the design of our three-stage 3D video pipeline, we also elucidate
	some critical implementation details regarding decoupling of acquisition,
	processing and rendering frame rates, and audio/video synchronization.
	Finally, we demonstrate the communication and networking features
	of the blue-c system in its full deployment. We show how the system
	can possibly be controlled to face processing or networking bottlenecks
	by adapting the multiple system components like audio, application
	data, and 3D video.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {IEEE}
}

@ARTICLE{Lamping1996,
  author = {Lamping, Jonh and Rao, Ramana},
  title = {The hyperbolic browser: A focus+ context technique for visualizing
	large hierarchies},
  journal = {Journal of Visual Languages \& Computing},
  year = {1996},
  volume = {7},
  pages = {33--55},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/The Hyperbolic Browser A  Focus 1 Context Tech.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Lamport1983,
  author = {Lamport, Leslie},
  title = {The weak Byzantine generals problem},
  journal = {Journal of the ACM (JACM)},
  year = {1983},
  volume = {30},
  pages = {668--676},
  number = {3},
  file = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\bitcoin\\byz.pdf:PDF},
  publisher = {ACM New York, NY, USA}
}

@ARTICLE{Langton2000,
  author = {Langton, S R},
  title = {The mutual influence of gaze and head orientation in the analysis
	of social attention direction},
  journal = {Q. J. Exp. Psychol. A},
  year = {2000},
  volume = {53},
  pages = {825--845},
  number = {3},
  month = {\#aug\#},
  abstract = {Three experiments are reported that investigate the hypothesis that
	head orientation and gaze direction interact in the processing of
	another individual's direction of social attention. A Stroop-type
	interference paradigm was adopted, in which gaze and head cues were
	placed into conflict. In separate blocks of trials, participants
	were asked to make speeded keypress responses contingent on either
	the direction of gaze, or the orientation of the head displayed in
	a digitized photograph of a male face. In Experiments 1 and 2, head
	and gaze cues showed symmetrical interference effects. Compared with
	congruent arrangements, incongruent head cues slowed responses to
	gaze cues, and incongruent gaze cues slowed responses to head cues,
	suggesting that head and gaze are mutually influential in the analysis
	of social attention direction. This mutuality was also evident in
	a cross-modal version of the task (Experiment 3) where participants
	responded to spoken directional words whilst ignoring the head/gaze
	images. It is argued that these interference effects arise from the
	independent influences of gaze and head orientation on decisions
	concerning social attention direction.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Taylor \& Francis}
}

@ARTICLE{Langton2000,
  author = {Langton, S R and Watt, R J and Bruce, I, I},
  title = {Do the eyes have it? Cues to the direction of social attention},
  journal = {Trends Cogn. Sci.},
  year = {2000},
  volume = {4},
  pages = {50--59},
  number = {2},
  month = {\#feb\#},
  abstract = {The face communicates an impressive amount of visual information.
	We use it to identify its owner, how they are feeling and to help
	us understand what they are saying. Models of face processing have
	considered how we extract such meaning from the face but have ignored
	another important signal - eye gaze. In this article we begin by
	reviewing evidence from recent neurophysiological studies that suggests
	that the eyes constitute a special stimulus in at least two senses.
	First, the structure of the eyes is such that it provides us with
	a particularly powerful signal to the direction of another person's
	gaze, and second, we may have evolved neural mechanisms devoted to
	gaze processing. As a result, gaze direction is analysed rapidly
	and automatically, and is able to trigger reflexive shifts of an
	observer's visual attention. However, understanding where another
	individual is directing their attention involves more than simply
	analysing their gaze direction. We go on to describe research with
	adult participants, children and non-human primates that suggests
	that other cues such as head orientation and pointing gestures make
	significant contributions to the computation of another's direction
	of attention.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Langton2000,
  author = {Langton, S R H},
  title = {The Mutual Influence Of Gaze And Head Orientation In The Analysis
	Of Social Attention Direction},
  year = {2000},
  pages = {825--845},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Langton2000,
  author = {Langton, Stephen R H and Watt, Roger J and Bruce, Vicki},
  title = {Do The Eyes Have It? Cues To The Direction Of Social Attention},
  year = {2000},
  volume = {4},
  pages = {50--59},
  abstract = {The face communicates an impressive amount of visual information.
	We use it to identify its owner, how they are feeling and to help
	us understand what they are saying. Models of face processing have
	considered how we extract such meaning from the face but have ignored
	another important signal \textbackslashquotesinglbase{\"A}{\`\i}
	eye gaze. In this article we begin by reviewing evidence from recent
	neurophysiological studies that suggests that the eyes constitute
	a special stimulus in at least two senses. First, the structure of
	the eyes is such that it provides us with a particularly powerful
	signal to the direction of another person\textbackslashquotesinglbase{\"A}{\^o}s
	gaze, and second, we may have evolved neural mechanisms devoted to
	gaze processing. As a result, gaze direction is analysed rapidly
	and automatically, and is able to trigger reflexive shifts of an
	observer\textbackslashquotesinglbase{\"A}{\^o}s visual attention.
	However, understanding where another individual is directing their
	attention involves more than simply analysing their gaze direction.
	We go on to describe research with adult participants, children and
	non-human primates that suggests that other cues such as head orientation
	and pointing gestures make significant contributions to the computation
	of another\textbackslashquotesinglbase{\"A}{\^o}s direction of attention.},
  keywords = {neuroscience;litsurvey.bib}
}

@UNPUBLISHED{Lantz1997,
  author = {Lantz, Ed},
  title = {Future directions in visual display systems},
  month = {\#may\#},
  year = {1997},
  keywords = {litsurvey.bib}
}

@ARTICLE{Lau1998,
  author = {Lau, Dora C and Murnighan, J Keith},
  title = {Demographic Diversity and Faultlines: The Compositional Dynamics
	of Organizational Groups},
  journal = {Acad. Manage. Rev.},
  year = {1998},
  volume = {23},
  pages = {325--340},
  number = {2},
  abstract = {In this article we address issues of diversity within organizational
	groups by discussing and summarizing previous approaches and by introducing
	a new variable-faultlines-which depends on the alignment of individual
	member characteristics. By analyzing a group's faultlines, we focus
	attention on the underlying patterns of group member characteristics,
	which can be an important determinant of subgroup conflict, particularly
	when the group's task is related to one of its faultlines. We discuss
	the dynamics of faultlines from the early to later stages of a group's
	development and show how they may be strongest and most likely when
	diversity of individual member characteristics is moderate.},
  keywords = {litsurvey.bib},
  publisher = {Academy of Management}
}

@INPROCEEDINGS{Laurendeau1999,
  author = {Laurendeau, Denis and Bertrand, Nathalie and Houde, R{\'e}gis},
  title = {{The mapping of texture on {VR} polygonal models}},
  booktitle = {Proceedings of the 2\textbackslashtextsuperscript{nd} international
	conference on {3-D} digital imaging and modeling ({3DIM} '99)},
  year = {1999},
  address = {Ottawa},
  publisher = {IEEE Computer Society},
  keywords = {litsurvey.bib}
}

@ARTICLE{Laurentini1994,
  author = {Laurentini, A},
  title = {The visual hull concept for silhouette-based image understanding},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {1994},
  volume = {16},
  pages = {150--162},
  number = {2},
  month = {\#feb\#},
  abstract = {Many algorithms for both identifying and reconstructing a 3-D object
	are based on the 2-D silhouettes of the object. In general, identifying
	a nonconvex object using a silhouette-based approach implies neglecting
	some features of its surface as identification clues. The same features
	cannot be reconstructed by volume intersection techniques using multiple
	silhouettes of the object. This paper addresses the problem of finding
	which parts of a nonconvex object are relevant for silhouette-based
	image understanding. For this purpose, the geometric concept of visual
	hull of a 3-D object is introduced. This is the closest approximation
	of object S that can be obtained with the volume intersection approach;
	it is the maximal object silhouette-equivalent to S, i.e., which
	can be substituted for S without affecting any silhouette. Only the
	parts of the surface of S that also lie on the surface of the visual
	hull can be reconstructed or identified using silhouette-based algorithms.
	The visual hull depends not only on the object but also on the region
	allowed to the viewpoint. Two main viewing regions result in the
	external and internal visual hull. In the former case the viewing
	region is related to the convex hull of S, in the latter it is bounded
	by S. The internal visual hull also admits an interpretation not
	related to silhouettes. Algorithms for computing visual hulls are
	presented and their complexity analyzed. In general, the visual hull
	of a 3-D planar face object turns out to be bounded by planar and
	curved patches.},
  keywords = {image reconstruction;silhouette-based image understanding;object identification;object
	reconstruction;nonconvex object;internal visual hull;external visual
	hull;Image reconstruction;Object recognition;Shape;Surface reconstruction;Computer
	vision;Algorithm design and analysis;Face detection;Image recognition;Layout;Navigation;litsurvey.bib},
  publisher = {IEEE}
}

@ARTICLE{lavoie1990prefatory,
  author = {Lavoie, Don},
  title = {Prefatory Note: The Origins of" The Agorics Project},
  journal = {Market Process, v8, Spring},
  year = {1990},
  pages = {116--119}
}

@INPROCEEDINGS{Lazebnik2001,
  author = {Lazebnik, S and Boyer, E and Ponce, J},
  title = {{On computing exact visual hulls of solids bounded by smooth surfaces}},
  booktitle = {{IEEE} Computer Society Conference on Computer Vision and Pattern
	Recognition ({CVPR} '01)},
  year = {2001},
  address = {Kauai},
  keywords = {litsurvey.bib}
}

@ARTICLE{Lazebnik2007,
  author = {Lazebnik, S and Furukawa, Y and Ponce, J},
  title = {{Projective visual hulls}},
  journal = {Int. J. Comput. Vis.},
  year = {2007},
  volume = {74},
  pages = {137--165},
  number = {2},
  keywords = {litsurvey.bib}
}

@ARTICLE{Lee1985,
  author = {Lee, Hsi-Jian and Chen, Zen},
  title = {{Determination of {3D} human body postures from a single view}},
  journal = {Computer Vision, Graphics, and Image Processing},
  year = {1985},
  volume = {30},
  pages = {148--168},
  number = {2},
  month = {\#may\#},
  abstract = {In this paper a method is proposed to recover and interpret the 3D
	body structures of a person from a single view, provided that (1)
	at least six feature points on the head and a set of body joints
	are available on the image plane, and (2) the geometry of head and
	lengths of body segments formed by joints are known. First of all,
	the feature points on the head in the head-centered coordinate system
	and their image projections are used to determine a transformation
	matrix. Then, the camera position and orientations are extracted
	from the matrix. Finally, the 3D coordinates of the head points expressed
	in the camera-centered coordinate system are obtained. Starting from
	the coordinates of the neck, which is a head feature point, the 3D
	coordinates of other joints one-by-one are determined under the assumption
	of the fixed lengths of the body segments. A binary interpretation
	tree is used to represent the 2n − 1 possible body structures, if
	a human body has n joints. To determine the final feasible body structures,
	physical and motion constraints are used to prune the interpretation
	tree. Formulas and rules required for the tree pruning are formulated.
	Experiments are used to illustrate the pruning powers of these constraints.
	In the two cases of input data chosen, a unique or nearly unique
	solution of the body structure is obtained.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Lee2011,
  author = {Lee, Min Kyung and Takayama, Leila},
  title = {``Now, i have a body'': uses and social norms for mobile remote presence
	in the workplace},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {33--42},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {computer supported collaborative work, human-robot interaction, mobile
	remote presence;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@INPROCEEDINGS{Lehment2014,
  author = {Lehment, N H and Merget, D and Rigoll, G},
  title = {Creating automatically aligned consensus realities for {AR} videoconferencing},
  booktitle = {2014 {IEEE} International Symposium on Mixed and Augmented Reality
	({ISMAR})},
  year = {2014},
  pages = {201--206},
  month = {\#sep\#},
  abstract = {This paper presents an AR videoconferencing approach merging two remote
	rooms into a shared workspace. Such bilateral AR telepresence inherently
	suffers from breaks in immersion stemming from the different physical
	layouts of participating spaces. As a remedy, we develop an automatic
	alignment scheme which ensures that participants share a maximum
	of common features in their physical surroundings. The system optimizes
	alignment with regard to initial user position, free shared floor
	space, camera positioning and other factors. Thus we can reduce discrepancies
	between different room and furniture layouts without actually modifying
	the rooms themselves. A description and discussion of our alignment
	scheme is given along with an exemplary implementation on real-world
	datasets.},
  institution = {IEEE},
  keywords = {augmented reality;teleconferencing;AR videoconferencing;augmented
	reality;bilateral AR telepresence;immersion stemming;automatic alignment
	scheme;user position;free shared floor space;camera positioning;Cameras;Three-dimensional
	displays;Avatars;Observability;Optimization;Teleconferencing;Computational
	modeling;H.4.3 [Information Systems Applications];Communications
	Applications --- Computer Conferencing;Teleconferencing;Videoconferencing;litsurvey.bib}
}

@INPROCEEDINGS{Leshed2009,
  author = {Leshed, Gilly and Perez, Diego and Hancock, Jeffrey T and Cosley,
	Dan and Birnholtz, Jeremy and Lee, Soyoung and McLeod, Poppy L and
	Gay, Geri},
  title = {Visualizing real-time language-based feedback on teamwork behavior
	in computer-mediated groups},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2009},
  series = {CHI '09},
  pages = {537--546},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {peripheral displays, cmc, cscw, linguistic analysis, feedback visualization,
	teamwork;litsurvey.bib},
  location = {Boston, MA, USA}
}

@INPROCEEDINGS{Lessels2004,
  author = {Lessels, S and Ruddle, R A},
  title = {Changes in navigational behaviour produced by a wide field of view
	and a high fidelity visual scene},
  booktitle = {Proceedings of the 10\textbackslashtextsuperscript{th} Eurographics
	Symposium on Virtual Environments},
  year = {2004},
  pages = {71--78},
  institution = {Eurographics},
  keywords = {litsurvey.bib}
}

@ARTICLE{Lessiter2001,
  author = {Lessiter, Jane and Freeman, Jonathan and Keogh, Edmund and Davidoff,
	Jules},
  title = {A {Cross-Media} Presence Questionnaire: The {ITC-Sense} of Presence
	Inventory},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2001},
  volume = {10},
  pages = {282--297},
  number = {3},
  month = {\#jun\#},
  abstract = {The presence research community would benefit from a reliable and
	valid cross-media presence measure that allows results from different
	laboratories to be compared and a more comprehensive knowledge base
	to be developed. The ITC-Sense of Presence Inventory (ITC-SOPI) is
	a new state questionnaire measure whose development has been informed
	by previous research on the determinants of presence and current
	self-report measures. It focuses on users' experiences of media,
	with no reference to objective system parameters. More than 600 people
	completed the ITC-SOPI following an experience with one of a range
	of noninteractive and interactive media. Exploratory analysis (principal
	axis factoring) revealed four factors: Sense of Physical Space, Engagement,
	Ecological Validity, and Negative Effects. Relations between the
	factors and the consistency of the factor structure with others reported
	in the literature are discussed. Preliminary analyses described here
	demonstrate that the ITC-SOPI is reliable and valid, but more rigorous
	testing of its psychometric properties and applicability to interactive
	virtual environments is required. Subject to satisfactory confirmatory
	analyses, the ITC-SOPI will offer researchers using a range of media
	systems a tool with which to measure four facets of a media experience
	that are putatively related to presence.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Lessiter2000,
  author = {Lessiter, Jane and Freeman, Jonathan and Keogh, Ed and Davidoff,
	Jules},
  title = {{Development of a New {Cross-Media} Presence Questionnaire : The
	{ITC-Sense} of Presence Inventory}},
  journal = {3\textbackslashtextsuperscriptrd International Presence Workshop},
  year = {2000},
  number = {ii},
  abstract = {Summary l Previous studies have attempted to measure presence using
	simple post-test rating scales (e.g., Slater, Usoh \& Steed, 1994;
	Barfield \& Hendrix, 1996). l The stability of simple post-test ratings
	has been questioned (Freeman Avons, Pearson \& IJsselsteijn, 1999).
	l More detailed, carefully piloted and psychometrically-sound questionnaires
	offer a solution to potential instabilities in simple post-test ratings.
	This approach has been adopted by Schubert, Friedmann and Regenbrecht
	(1999), Witmer and Singer (1998), and Kim and Biocca (1997). l These
	attempts have limitations, such as restricted media applications.
	l We present research documenting the development of a new cross-media
	presence questionnaire - the ITC-Sense of Presence Inventory (ITC-SOPI).
	l Preliminary results indicate four components: Physical Space, Engagement,
	Naturalness and Negative Effects.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Lincoln2010,
  author = {Lincoln, Peter and Nashel, Andrew and Ilie, Adrian and Towles, Herman
	and Welch, Gregory and Fuchs, Henry},
  title = {Multi-view lenticular display for group teleconferencing},
  booktitle = {Proceedings of the 2nd International Conference on Immersive Telecommunications},
  year = {2010},
  pages = {22},
  month = {\#may\#},
  publisher = {ICST},
  institution = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications
	Engineering)},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Lincoln2010,
  author = {Lincoln, Peter and Nashel, Andrew and Ilie, Adrian and Towles, Herman
	and Welch, Gregory and Fuchs, Henry},
  title = {Multi-view lenticular display for group teleconferencing},
  booktitle = {Proceedings of the 2nd International Conference on Immersive Telecommunications},
  year = {2010},
  pages = {22},
  month = {\#may\#},
  publisher = {ICST},
  institution = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications
	Engineering)},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Lincoln2009,
  author = {Lincoln, P and Welch, G and Nashel, A and Ilie, A and State, A and
	Fuchs, H},
  title = {Animatronic Shader Lamps Avatars},
  booktitle = {2009 8th {IEEE} International Symposium on Mixed and Augmented Reality},
  year = {2009},
  pages = {27--33},
  month = {\#oct\#},
  abstract = {Applications such as telepresence and training involve the display
	of real or synthetic humans to multiple viewers. When attempting
	to render the humans with conventional displays, non-verbal cues
	such as head pose, gaze direction, body posture, and facial expression
	are difficult to convey correctly to all viewers. In addition, a
	framed image of a human conveys only a limited physical sense of
	presence - primarily through the display's location. While progress
	continues on articulated robots that mimic humans, the focus has
	been on the motion and behavior of the robots. We introduce a new
	approach for robotic avatars of real people: the use of cameras and
	projectors to capture and map the dynamic motion and appearance of
	a real person onto a humanoid animatronic model. We call these devices
	Animatronic Shader Lamps Avatars (SLA).We present a proof-of-concept
	prototype comprised of a camera, a tracking system, a digital projector,
	and a life-sized styrofoam head mounted on a pan-tilt unit. The system
	captures imagery of a moving, talking user and maps the appearance
	and motion onto the animatronic SLA, delivering a dynamic, real-time
	representation of the user to multiple viewers.},
  institution = {IEEE},
  keywords = {avatars;computer vision;rendering (computer graphics);animatronic
	shader lamps avatars;articulated robots;robotic avatars;humanoid
	animatronic model;Animation;Lamps;Avatars;Humans;Displays;Robot sensing
	systems;Head;Robot vision systems;Cameras;Rendering (computer graphics);H.4.3
	[Information Systems Applications]: Communications Applications;Computer
	conferencing, teleconferencing, and videoconferencing H.5.1 [Multimedia
	Information Systems]: Animations;Artificial, augmented, and virtual
	realities I.3.7 [Computer Graphics]: Three Dimensional Graphics and
	Realism;Virtual Reality; I.3.8 [Computer Graphics]: Applications;litsurvey.bib}
}

@ARTICLE{Lincoln2011,
  author = {Lincoln, Peter and Welch, Greg and Nashel, Andrew and {State, Andrei}
	and Ilie, Adrian and Fuchs, Henry},
  title = {{Animatronic shader lamps avatars}},
  journal = {Virtual Real.},
  year = {2011},
  volume = {15},
  pages = {225--238},
  number = {2},
  month = {\#jun\#},
  abstract = {Applications such as telepresence and training involve the display
	of real or synthetic humans to multiple viewers. When attempting
	to render the humans with conventional displays, non-verbal cues
	such as head pose, gaze direction, body posture, and facial expression
	are difficult to convey correctly to all viewers. In addition, a
	framed image of a human conveys only a limited physical sense of
	presence---primarily through the display's location. While progress
	continues on articulated robots that mimic humans, the focus has
	been on the motion and behavior of the robots rather than on their
	appearance. We introduce a new approach for robotic avatars of real
	people: the use of cameras and projectors to capture and map both
	the dynamic motion and the appearance of a real person onto a humanoid
	animatronic model. We call these devices animatronic Shader Lamps
	Avatars (SLA). We present a proof-of-concept prototype comprised
	of a camera, a tracking system, a digital projector, and a life-sized
	styrofoam head mounted on a pan-tilt unit. The system captures imagery
	of a moving, talking user and maps the appearance and motion onto
	the animatronic SLA, delivering a dynamic, real-time representation
	of the user to multiple viewers.},
  keywords = {litsurvey.bib}
}

@MISC{Lister2020,
  author = {Lister, Kate},
  title = {Global Workplace Statistics},
  howpublished = {\url{https://globalworkplaceanalytics.com/telecommuting-statistics}},
  year = {2020},
  keywords = {litsurvey.bib}
}

@ARTICLE{Liu2009,
  author = {Liu, Shubao and Kang, Kongbin and Tarel, J and Cooper, D},
  title = {{Distributed volumetric scene geometry reconstruction with a network
	of distributed smart cameras}},
  journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR
	'09)},
  year = {2009},
  pages = {2334--2341},
  keywords = {litsurvey.bib}
}

@ARTICLE{Liu2007,
  author = {Liu, Xin and Yao, Hongxun and Gao, Wen},
  title = {{Shape from silhouette outlines using an adaptive dandelion model}},
  journal = {Comput. Vis. Image Underst.},
  year = {2007},
  volume = {105},
  pages = {121--130},
  number = {2},
  month = {\#feb\#},
  abstract = {In this paper we study the problem of shape from silhouette outlines
	(SFO) using a novel adaptive dandelion model. SFO reconstructs a
	3D model using only the outmost silhouette contours and produces
	a solid called the ``bounding hull''. The dandelion model is composed
	of a pencil of organized line segments emitted from a common point
	which samples the bounding hull surface in regularly distributed
	orientations with the ending points serving as sampling points. The
	orientations and the topology of the line segments are derived from
	a geodesic sphere. The lengths of the line segments are computed
	by cutting rays in 2D with silhouette outlines. Based on the subdivision
	structure of the geodesic sphere, the sampling resolution can be
	refined adaptively until the desired precision is achieved. Finally
	a manifold mesh is extracted from the dandelion model.},
  keywords = {Shape from silhouette outlines; Bounding hull; Dandelion model;litsurvey.bib}
}

@ARTICLE{Lohmann1998,
  author = {Lohmann, Klaudia and Gundelfinger, Eckart D and Scheich, Henning
	and Grimm, Rita and Tischmeyer, Wolfgang and Richter, Karin and Hess,
	Andreas},
  title = {BrainView: a computer program for reconstruction and interactive
	visualization of 3D data sets},
  journal = {Journal of neuroscience methods},
  year = {1998},
  volume = {84},
  pages = {143--154},
  number = {1-2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0165027098001034-main.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Loomis2008,
  author = {Loomis, Jack M and Kelly, Jonathan W and Pusch, Matthias and Bailenson,
	Jeremy N and Beall, Andrew C},
  title = {Psychophysics of perceiving eye-gaze and head direction with peripheral
	vision: implications for the dynamics of eye-gaze behavior},
  journal = {Perception},
  year = {2008},
  volume = {37},
  pages = {1443--1457},
  number = {9},
  abstract = {Two psychophysical experiments are reported, one dealing with the
	visual perception of the head orientation of another person (the
	'looker') and the other dealing with the perception of the looker's
	direction of eye gaze. The participant viewed the looker with different
	retinal eccentricities, ranging from foveal to far-peripheral viewing.
	On average, judgments of head orientation were reliable even out
	to the extremes of peripheral vision (90 degrees eccentricity), with
	better performance at the extremes when the participant was able
	to view the looker changing head orientation from one trial to the
	next. In sharp contrast, judgments of eye-gaze direction were reliable
	only out to 4 degrees eccentricity, signifying that the eye-gaze
	social signal is available to people only when they fixate near the
	looker's eyes. While not unexpected, this vast difference in availability
	of information about head direction and eye direction, both of which
	can serve as indicators of the looker's focus of attention, is important
	for understanding the dynamics of eye-gaze behavior.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {SAGE Publications Sage UK: London, England}
}

@INPROCEEDINGS{Loomis2008,
  author = {Loomis, Jack M and Kelly, Jonathan W and Pusch, Matthias and Bailenson,
	Jeremy N and Beall, Andrew C},
  title = {Psychophysics Of Perceiving Eye-gaze And Head Direction With Peripheral
	{Vision:$\neg${\textbackslashdag}implications} For The Dynamics Of
	Eye-gaze Behavior},
  year = {2008},
  volume = {37},
  pages = {1443--1457},
  keywords = {litsurvey.bib}
}

@INCOLLECTION{Loomis2012,
  author = {Loomis, Jack M and Klatzky, Roberta L and Giudice, Nicholas A},
  title = {-Sensory Substitution of Vision: Importance of Perceptual and Cognitive
	Processing},
  booktitle = {Assistive technology for blindness and low vision},
  publisher = {CRC Press},
  year = {2012},
  pages = {179--210},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Lorensen1987,
  author = {Lorensen, W E and Cline, H E},
  title = {{Marching cubes: A high resolution {3D} surface construction algorithm}},
  booktitle = {Proceedings of the 14\textbackslashtextsuperscript{th} annual conference
	on Computer Graphics and Interactive Techniques ({SIGGRAPH} '87)},
  year = {1987},
  pages = {163--169},
  address = {Anaheim},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Lottridge2009,
  author = {Lottridge, Danielle and Masson, Nicolas and Mackay, Wendy},
  title = {Sharing empty moments: design for remote couples},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2009},
  series = {CHI '09},
  pages = {2329--2338},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {remote couples, presence, field trials, ambient, computer mediated
	communication, intimacy, domestic routines, reflective design, empty
	moments, intimate technology;litsurvey.bib},
  location = {Boston, MA, USA}
}

@INPROCEEDINGS{Luff2011,
  author = {Luff, Paul and Yamashita, Naomi and Kuzuoka, Hideaki and Heath, Christian},
  title = {Hands on hitchcock: embodied reference to a moving scene},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {43--52},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {interaction analysis, cscw, media spaces, embodied interaction;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@ARTICLE{Luo2019,
  author = {Luo, Wenhong},
  title = {User choice of interactive data visualization format: The effects
	of cognitive style and spatial ability},
  journal = {Decision Support Systems},
  year = {2019},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0167923619300776-main.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Ma2011,
  author = {Ma, Xiaohan and Le, Binh Huy and Deng, Zhigang},
  title = {Perceptual analysis of talking avatar head movements: a quantitative
	perspective},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {2699--2702},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {head motion, quantitative analysis, and audio-head motion features,
	perceptual modeling;litsurvey.bib},
  location = {Vancouver, BC, Canada}
}

@ARTICLE{Macrae2002,
  author = {Macrae, C Neil and Hood, Bruce M and Milne, Alan B and Rowe, Angela
	C and Mason, Malia F},
  title = {Are you looking at me? Eye gaze and person perception},
  journal = {Psychol. Sci.},
  year = {2002},
  volume = {13},
  pages = {460--464},
  number = {5},
  month = {\#sep\#},
  abstract = {Previous research has highlighted the pivotal role played by gaze
	detection and interpretation in the development of social cognition.
	Extending work of this kind, the present research investigated the
	effects of eye gaze on basic aspects of the person-perception process,
	namely, person construal and the extraction of category-related knowledge
	from semantic memory. It was anticipated that gaze direction would
	moderate the efficiency of the mental operations through which these
	social-cognitive products are generated. Specifically, eye gaze was
	expected to influence both the speed with which targets could be
	categorized as men and women and the rate at which associated stereotypic
	material could be accessed from semantic memory. The results of two
	experiments supported these predictions: Targets with nondeviated
	(i.e., direct) eye gaze elicited facilitated categorical responses.
	The implications of these findings for recent treatments of person
	perception are considered.},
  keywords = {litsurvey.bib},
  language = {en}
}

@InProceedings{Macrae2002,
  author   = {Macrae, C Neil and Hood, Bruce M and Milne, Alan B and Rowe, Angela C and Mason, Malia F},
  title    = {Are You Looking At Me? Eye Gaze And Person Perception},
  year     = {2002},
  pages    = {460--464},
  volume   = {13},
  abstract = {Previous research has highlighted the pivotal role played by gaze
	detection and interpretation in the development of social cognition.
	Extending work of this kind, the present research investigated the
	effects of eye gaze on basic aspects of the person-perception process,
	namely, person construal and the extraction of category-related knowledge
	from semantic memory. It was anticipated that gaze direction would
	moderate the efficiency of the mental operations through which these
	social-cognitive products are generated. Specifically, eye gaze was
	expected to influence both the speed with which targets could be
	categorized as men and women and the rate at which associated stereotypic
	material could be accessed from semantic memory. The results of two
	experiments supported these predictions: Targets with nondeviated
	(i.e., direct) eye gaze elicited facilitated categorical responses.
	The implications of these findings for recent treatments of person
	perception are considered.},
  keywords = {Adult, Attention, Female, Fixation, Ocular, Gender Identity, Humans, Interpersonal Relations, Male, Mental Recall, Social Perception, Stereotyping;litsurvey.bib},
}

@INPROCEEDINGS{Maeda2004,
  author = {Maeda, Hiroyuki and Tanikawa, Tomohiro and Yamashita, Jun and Hirota,
	Koichi and Hirose, Michitaka},
  title = {Real World Video Avatar: Transmission And Presentation Of Human Figure},
  booktitle = {Virtual Reality, 2004. Proceedings. {IEEE}},
  year = {2004},
  pages = {237--238},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Maimone2011,
  author = {Maimone, A and Fuchs, H},
  title = {Encumbrance-free telepresence system with real-time {3D} capture
	and display using commodity depth cameras},
  booktitle = {2011 10th {IEEE} International Symposium on Mixed and Augmented Reality},
  year = {2011},
  pages = {137--146},
  month = {\#oct\#},
  abstract = {This paper introduces a proof-of-concept telepresence system that
	offers fully dynamic, real-time 3D scene capture and continuous-viewpoint,
	head-tracked stereo 3D display without requiring the user to wear
	any tracking or viewing apparatus. We present a complete software
	and hardware framework for implementing the system, which is based
	on an array of commodity Microsoft Kinect™color-plus-depth cameras.
	Novel contributions include an algorithm for merging data between
	multiple depth cameras and techniques for automatic color calibration
	and preserving stereo quality even with low rendering rates. Also
	presented is a solution to the problem of interference that occurs
	between Kinect cameras with overlapping views. Emphasis is placed
	on a fully GPU-accelerated data processing and rendering pipeline
	that can apply hole filling, smoothing, data merger, surface generation,
	and color correction at rates of up to 100 million triangles/sec
	on a single PC and graphics board. Also presented is a Kinect-based
	marker-less tracking system that combines 2D eye recognition with
	depth information to allow head-tracked stereo views to be rendered
	for a parallax barrier autostereoscopic display. Our system is affordable
	and reproducible, offering the opportunity to easily deliver 3D telepresence
	beyond the researcher's lab.},
  keywords = {Cameras;Graphics processing unit;Image color analysis;Interference;Rendering
	(computer graphics);Smoothing methods;Three dimensional displays;camera
	calibration;color calibration;computer vision;filtering;object recognition;parallel
	processing;sensor fusion;surface fitting;teleconferencing;three-dimensional
	displays;tracking;virtual reality;litsurvey.bib}
}

@INPROCEEDINGS{Maimone2011,
  author = {Maimone, A and Fuchs, H},
  title = {Encumbrance-free telepresence system with real-time {3D} capture
	and display using commodity depth cameras},
  booktitle = {2011 10th {IEEE} International Symposium on Mixed and Augmented Reality},
  year = {2011},
  pages = {137--146},
  month = {\#oct\#},
  abstract = {This paper introduces a proof-of-concept telepresence system that
	offers fully dynamic, real-time 3D scene capture and continuous-viewpoint,
	head-tracked stereo 3D display without requiring the user to wear
	any tracking or viewing apparatus. We present a complete software
	and hardware framework for implementing the system, which is based
	on an array of commodity Microsoft Kinect™color-plus-depth cameras.
	Novel contributions include an algorithm for merging data between
	multiple depth cameras and techniques for automatic color calibration
	and preserving stereo quality even with low rendering rates. Also
	presented is a solution to the problem of interference that occurs
	between Kinect cameras with overlapping views. Emphasis is placed
	on a fully GPU-accelerated data processing and rendering pipeline
	that can apply hole filling, smoothing, data merger, surface generation,
	and color correction at rates of up to 100 million triangles/sec
	on a single PC and graphics board. Also presented is a Kinect-based
	marker-less tracking system that combines 2D eye recognition with
	depth information to allow head-tracked stereo views to be rendered
	for a parallax barrier autostereoscopic display. Our system is affordable
	and reproducible, offering the opportunity to easily deliver 3D telepresence
	beyond the researcher's lab.},
  institution = {IEEE},
  keywords = {Cameras;Three dimensional displays;Image color analysis;Graphics processing
	unit;Interference;Rendering (computer graphics);Smoothing methods;teleconferencing;virtual
	reality;sensor fusion;camera calibration;color calibration;surface
	fitting;filtering;parallel processing;computer vision;tracking;object
	recognition;three-dimensional displays;litsurvey.bib}
}

@ARTICLE{Maimone2011,
  author = {Maimone, Andrew and Fuchs, Henry},
  title = {A first look at a telepresence system with room-sized real-time 3d
	capture and life-sized tracked display wall},
  journal = {Proceedings of ICAT 2011, to appear},
  year = {2011},
  pages = {4--9},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Maimone2013,
  author = {Maimone, A and Yang, X and Dierk, N and State, A and Dou, M and Fuchs,
	H},
  title = {General-purpose telepresence with head-worn optical see-through displays
	and projector-based lighting},
  booktitle = {2013 {IEEE} Virtual Reality ({VR})},
  year = {2013},
  pages = {23--26},
  month = {\#mar\#},
  abstract = {In this paper we propose a general-purpose telepresence system design
	that can be adapted to a wide range of scenarios and present a framework
	for a proof-of-concept prototype. The prototype system allows users
	to see remote participants and their surroundings merged into the
	local environment through the use of an optical see-through head-worn
	display. Real-time 3D acquisition and head tracking allows the remote
	imagery to be seen from the correct point of view and with proper
	occlusion. A projector-based lighting control system permits the
	remote imagery to appear bright and opaque even in a lit room. Immersion
	can be adjusted across the VR continuum. Our approach relies only
	on commodity hardware; we also experiment with wider field of view
	custom displays.},
  institution = {IEEE},
  keywords = {data acquisition;helmet mounted displays;lighting control;object tracking;optical
	projectors;virtual reality;head-worn optical see-through displays;projector-based
	lighting;general-purpose telepresence system design;proof-of-concept
	prototype;optical see-through head-worn display;real-time 3D acquisition;head
	tracking;remote imagery;projector-based lighting control system;VR
	continuum;field-of-view custom displays;commodity hardware;Three-dimensional
	displays;Optical imaging;Optical sensors;Lighting control;Prototypes;Adaptive
	optics;Geometry;teleconferencing;augmented reality;virtual reality;litsurvey.bib}
}

@BOOK{Marriott2018,
  title = {Immersive Analytics},
  publisher = {Springer},
  year = {2018},
  author = {Marriott, Kim and Schreiber, Falk and Dwyer, Tim and Klein, Karsten
	and Riche, Nathalie Henry and Itoh, Takayuki and Stuerzlinger, Wolfgang
	and Thomas, Bruce H},
  volume = {11190},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/2018_Book_ImmersiveAnalytics.pdf:PDF}
}

@INPROCEEDINGS{Marti2005,
  author = {Marti, Stefan and Schmandt, Chris},
  title = {Physical embodiments for mobile communication agents},
  booktitle = {Proceedings of the 18th annual {ACM} symposium on User interface
	software and technology},
  year = {2005},
  series = {UIST '05},
  pages = {231--240},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {embodiment, conversational agent, robotic user interface, interruptions,
	human style non-verbal cues;litsurvey.bib},
  location = {Seattle, WA, USA}
}

@ARTICLE{Martin1983,
  author = {Martin, W N and Aggarwal, J K},
  title = {{Volumetric descriptions of objects from multiple views}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {1983},
  volume = {5},
  pages = {150--158},
  number = {2},
  month = {\#feb\#},
  abstract = {Occluding contours from an image sequence with view-point specifications
	determine a bounding volume approximating the object generating the
	contours. The initial creation and continual refinement of the approximation
	requires a volumetric representation that facilitates modification
	yet is descriptive of surface detail. The ``volume segment'' representation
	presented in this paper is one such representation.},
  keywords = {litsurvey.bib},
  language = {en}
}

@ARTICLE{Matsuyama2004,
  author = {Matsuyama, T and {Xiaojun Wu} and Takai, T and Wada, T},
  title = {{Real-time dynamic {3-D} object shape reconstruction and high-fidelity
	texture mapping for {3-D} video}},
  journal = {IEEE Trans. Circuits Syst. Video Technol.},
  year = {2004},
  volume = {14},
  pages = {357--369},
  number = {3},
  month = {\#mar\#},
  abstract = {Three-dimensional (3-D) video is a real 3-D movie recording the object's
	full 3-D shape, motion, and precise surface texture. This paper first
	proposes a parallel pipeline processing method for reconstructing
	a dynamic 3-D object shape from multiview video images, by which
	a temporal series of full 3-D voxel representations of the object
	behavior can be obtained in real time. To realize the real-time processing,
	we first introduce a plane-based volume intersection algorithm: first
	represent an observable 3-D space by a group of parallel plane slices,
	then back-project observed multiview object silhouettes onto each
	slice, and finally apply two-dimensional silhouette intersection
	on each slice. Then, we propose a method to parallelize this algorithm
	using a PC cluster, where we employ five-stage pipeline processing
	in each PC as well as slice-by-slice parallel silhouette intersection.
	Several results of the quantitative performance evaluation are given
	to demonstrate the effectiveness of the proposed methods. In the
	latter half of the paper, we present an algorithm of generating video
	texture on the reconstructed dynamic 3-D object surface. We first
	describe a naive view-independent rendering method and show its problems.
	Then, we improve the method by introducing image-based rendering
	techniques. Experimental results demonstrate the effectiveness of
	the improved method in generating high fidelity object images from
	arbitrary viewpoints.},
  keywords = {real-time systems;image reconstruction;image texture;video signal
	processing;video recording;pipeline processing;image representation;real-time
	dynamic 3D object shape reconstruction;high-fidelity texture mapping;3D
	video;3D movie recording;parallel pipeline processing method;multiview
	video images;voxel representation;plane-based volume intersection
	algorithm;observable 3D space;parallel plane slices;back-project
	observed multiview object silhouette intersection;two-dimensional
	silhouette intersection;slice-by-slice parallel silhouette intersection;view-independent
	rendering method;image-based rendering technique;PC cluster;Shape;Image
	reconstruction;Real time systems;Humans;Surface reconstruction;Surface
	texture;Clustering algorithms;Pipeline processing;Rendering (computer
	graphics);Biomedical imaging;litsurvey.bib}
}

@INPROCEEDINGS{Matusik2000,
  author = {Matusik, Wojciech and Buehler, Chris and Raskar, Ramesh and Gortler,
	Steven J and McMillan, Leonard},
  title = {Image-based visual hulls},
  booktitle = {Proceedings of the 27th annual conference on Computer graphics and
	interactive techniques},
  year = {2000},
  series = {SIGGRAPH '00},
  pages = {369--374},
  address = {USA},
  month = {\#jul\#},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  institution = {ACM Press/Addison-Wesley Publishing Co.},
  keywords = {constructive solid geometry, misc. rendering algorithms, computer
	vision, image-based rendering;litsurvey.bib}
}

@INPROCEEDINGS{McGrenere2000,
  author = {McGrenere, Joanna and Ho, Wayne},
  title = {Affordances: Clarifying and evolving a concept},
  booktitle = {Graphics interface},
  year = {2000},
  volume = {2000},
  pages = {179--186},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Mekuria2013,
  author = {Mekuria, Rufael and Sanna, Michele and Asioli, Stefano and Izquierdo,
	Ebroul and Bulterman, Dick C A and Cesar, Pablo},
  title = {A {3D} tele-immersion system based on live captured mesh geometry},
  booktitle = {Proceedings of the 4th {ACM} Multimedia Systems Conference},
  year = {2013},
  series = {MMSys '13},
  pages = {24--35},
  address = {New York, NY, USA},
  month = {\#feb\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {compression algorithms, graphics streaming, architecture, 3D tele-immersion,
	3D meshes, LT codes, networking;litsurvey.bib},
  location = {Oslo, Norway}
}

@ARTICLE{Mendonca2001,
  author = {Mendonca, P R S and -. K. Wong, K and Cipolla, R},
  title = {{Epipolar geometry from profiles under circular motion}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2001},
  volume = {23},
  pages = {604--616},
  number = {6},
  month = {\#jun\#},
  abstract = {Addresses the problem of motion estimation from profiles (apparent
	contours) of an object rotating on a turntable in front of a single
	camera. A practical and accurate technique for solving this problem
	from profiles alone is developed. It is precise enough to reconstruct
	the shape of the object. No correspondences between points or lines
	are necessary. Symmetry of the surface of revolution swept out by
	the rotating object is exploited to obtain the image of the rotation
	axis and the homography relating epipolar lines in two views robustly
	and elegantly. These, together with geometric constraints for images
	of rotating objects, are used to obtain first the image of the horizon,
	which is the projection of the plane that contains the camera centers,
	and then the epipoles, thus fully determining the epipolar geometry
	of the image sequence. The estimation of this geometry by this sequential
	approach avoids many of the problems found in other algorithms. The
	search for the epipoles, by far the most critical step, is carried
	out as a simple 1D optimization. Parameter initialization is trivial
	and completely automatic at all stages. After the estimation of the
	epipolar geometry, the Euclidean motion is recovered using the fixed
	intrinsic parameters of the camera obtained either from a calibration
	grid or from self-calibration techniques. Finally, the spinning object
	is reconstructed from its profiles using the motion estimated in
	the previous stage. Results from real data are presented, demonstrating
	the efficiency and usefulness of the proposed methods.},
  keywords = {motion estimation;geometry;symmetry;image reconstruction;image sequences;search
	problems;optimisation;calibration;epipolar geometry;profiles;circular
	motion;apparent contours;shape reconstruction;homography;rotation
	axis;image sequence;1D optimization;parameter initialization;Euclidean
	motion;calibration grid;self-calibration techniques;Geometry;Motion
	estimation;Cameras;Image reconstruction;Shape;Surface reconstruction;Robustness;Image
	sequences;Calibration;Spinning;litsurvey.bib}
}

@ARTICLE{merkle1978secure,
  author = {Merkle, Ralph C},
  title = {Secure communications over insecure channels},
  journal = {Communications of the ACM},
  year = {1978},
  volume = {21},
  pages = {294--299},
  number = {4},
  publisher = {ACM New York, NY, USA}
}

@OTHER{MichaelBroxton,
  abstract = {- Computing methodologies -> Image compression.Neural networks.Virtual
	reality.Image-based rendering.Computational photography.},
  author = {Michael Broxton, John Flynn, Ryan Overbeck, Daniel Erickson, Peter
	Hedman, Matthew DuVall, Jason Dourgarian, Jay Busch, Matt Whalen,
	and Paul Debevec},
  file = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\ImmersiveLightFieldVideoWithALayeredMeshRepresentation.pdf:PDF},
  keywords = {view synthesis, light fields, image-based rendering, deep learning},
  title = {Immersive Light Field Video with a Layered Mesh Representation}
}

@ARTICLE{Mihoub2015,
  author = {Mihoub, Alaeddine and Bailly, G{\'e}rard and Wolf, Christian and
	Elisei, Fr{\'e}d{\'e}ric},
  title = {Learning multimodal behavioral models for face-to-face social interaction},
  journal = {Journal on Multimodal User Interfaces},
  year = {2015},
  volume = {9},
  pages = {195--210},
  number = {3},
  month = {\#sep\#},
  abstract = {The aim of this paper is to model multimodal perception-action loops
	of human behavior in face-to-face interactions. To this end, we propose
	trainable behavioral models that predict the optimal actions for
	one specific person given others' perceived actions and the joint
	goals of the interlocutors. We first compare sequential models---in
	particular discrete hidden Markov models (DHMMs)---with standard
	classifiers (SVMs and decision trees). We propose a modification
	of the initialization of the DHMMs in order to better capture the
	recurrent structure of the sensory-motor states. We show that the
	explicit state duration modeling by discrete hidden semi markov models
	(DHSMMs) improves prediction performance. We applied these models
	to parallel speech and gaze data collected from interacting dyads.
	The challenge was to predict the gaze of one subject given the gaze
	of the interlocutor and the voice activity of both. For both DHMMs
	and DHSMMs the short-time Viterbi concept is used for incremental
	decoding and prediction. For the proposed models we evaluated objectively
	several properties in order to go beyond pure classification performance.
	Results show that incremental DHMMs (IDHMMs) were more efficient
	than classic classifiers and superseded by incremental DHSMMs (IDHSMMs).
	This later result emphasizes the relevance of state duration modeling.},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@INPROCEEDINGS{Millais2018,
  author = {Millais, Patrick and Jones, Simon L and Kelly, Ryan},
  title = {Exploring data in virtual reality: Comparisons with 2d data visualizations},
  booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in
	Computing Systems},
  year = {2018},
  pages = {LBW007},
  organization = {ACM},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/LBW007.pdf:PDF}
}

@ARTICLE{Mitchell2011,
  author = {Mitchell, Wade J and Szerszen, Sr, Kevin A and Lu, Amy Shirong and
	Schermerhorn, Paul W and Scheutz, Matthias and Macdorman, Karl F},
  title = {A mismatch in the human realism of face and voice produces an uncanny
	valley},
  journal = {Iperception},
  year = {2011},
  volume = {2},
  pages = {10--12},
  number = {1},
  month = {\#mar\#},
  abstract = {The uncanny valley has become synonymous with the uneasy feeling of
	viewing an animated character or robot that looks imperfectly human.
	Although previous uncanny valley experiments have focused on relations
	among a character's visual elements, the current experiment examines
	whether a mismatch in the human realism of a character's face and
	voice causes it to be evaluated as eerie. The results support this
	hypothesis.},
  keywords = {Masahiro Mori; anthropomorphism; facial--vocal mismatch; human realism;
	social perception;litsurvey.bib},
  language = {en},
  publisher = {Pion Publications}
}

@TECHREPORT{Mitchelson2003,
  author = {Mitchelson, Joel and Hilton, Adrian},
  title = {{Wand-based multiple camera studio calibration}},
  year = {2003},
  keywords = {litsurvey.bib},
  publisher = {Centre for Vision, Speech and Signal Processing, University of Surrey,
	UK}
}

@INPROCEEDINGS{Moere2002,
  author = {Moere, Andrew Vande},
  title = {Infoticles: Information modeling in immersive environments},
  booktitle = {Proceedings Sixth International Conference on Information Visualisation},
  year = {2002},
  pages = {457--461},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/01028813.pdf:PDF}
}

@ARTICLE{Molina-Solana2017,
  author = {Molina-Solana, Miguel and Birch, David and Guo, Yi-ke},
  title = {Improving data exploration in graphs with fuzzy logic and large-scale
	visualisation},
  journal = {Applied Soft Computing},
  year = {2017},
  volume = {53},
  pages = {227--235},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S1568494616306731-main.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Moloney2018,
  author = {Moloney, Jules and Spehar, Branka and Globa, Anastasia and Wang,
	Rui},
  title = {The affordance of virtual reality to enable the sensory representation
	of multi-dimensional data for immersive analytics: from experience
	to insight},
  journal = {Journal of Big Data},
  year = {2018},
  volume = {5},
  pages = {53},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/s40537-018-0158-z.pdf:PDF},
  publisher = {SpringerOpen}
}

@BOOK{Monge1989,
  title = {A Profile of Meetings in Corporate {America}: Results of the {3M}
	Meeting Effectiveness Study},
  publisher = {Annenberg School of Communications, University of Southern California},
  year = {1989},
  author = {Monge, Peter R and McSween, Charles and Wyer, Joanne},
  keywords = {litsurvey.bib},
  language = {en}
}

@ARTICLE{Monk2002,
  author = {Monk, Andrew F and Gale, Caroline},
  title = {A Look Is Worth a Thousand Words: Full Gaze Awareness in {Video-Mediated}
	Conversation},
  journal = {Discourse Process.},
  year = {2002},
  volume = {33},
  pages = {257--278},
  number = {3},
  month = {\#may\#},
  abstract = {Full gaze awareness, defined here as knowing what someone is looking
	at, might be expected to be a powerful communicative resource when
	the conversation concerns some object of common interest in the environment.
	This article sets out to demonstrate this possibility in the context
	of video-mediated communication. An experiment is reported in which
	pairs complete a communication task using a novel apparatus that
	supports full gaze awareness (GA) and mutual gaze (eye contact).
	This ``GA display'' was contrasted with 2 control conditions, mutual
	gaze without full gaze awareness and audio only. The GA display reduced
	the number of turns and number of words required to complete the
	task by about 1/2 in comparison with the 2 control conditions. The
	results of a subsequent conversational games analysis suggest that
	at least part of this saving comes about because full gaze awareness
	provides an alternative nonlinguistic channel for checking one's
	own and the other person's understanding of what was said.},
  keywords = {litsurvey.bib},
  publisher = {Routledge}
}

@BOOK{Moons2010,
  title = {{3D} reconstruction from multiple images part 1: Principles},
  publisher = {Now Publishers, Inc.},
  year = {2010},
  author = {Moons, Theo and Van Gool, Luc and Vergauwen, Maarten and {Others}},
  volume = {4},
  pages = {287--404},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Moore2010,
  author = {Moore, C and Duckworth, T and Aspin, R and Roberts, D},
  title = {{Synchronization of Images from Multiple Cameras to Reconstruct a
	Moving Human}},
  booktitle = {2010 {IEEE/ACM} 14th International Symposium on Distributed Simulation
	and Real Time Applications},
  year = {2010},
  pages = {53--60},
  address = {Fairfax},
  month = {\#oct\#},
  publisher = {IEEE},
  abstract = {What level of synchronization is necessary between images from multiple
	cameras in order to realistically reconstruct a moving human in 3D?
	Live reconstruction of the human form, from cameras surrounding the
	subject, could bridge the gap between video conferencing and Immersive
	Collaborative Virtual Environments (ICVEs). Video conferencing faithfully
	reproduces what someone looks like whereas ICVE faithfully reproduces
	what they look at. While 3D video has been demonstrated in tele-immersion
	prototypes, the visual/temporal quality has been way below what has
	become acceptable in video conferencing. Managed synchronization
	of the acquisition stage is universally used today to ensure multiple
	images feeding the reconstruction algorithm were taken at the same
	time. However, this inevitably increases latency and jitter. We measure
	the temporal characteristics of the capture stage and the impact
	of inconsistency on the reconstruction algorithm this feeds. This
	gives us both input and output characteristics for synchronization.
	From this we determine whether frame synchronization of multiple
	camera video streams actually needs to be delivered for 3D reconstruction,
	and if not what level of temporal divergence is acceptable across
	the captured image frames.},
  keywords = {cameras;image motion analysis;image reconstruction;solid modelling;synchronisation;teleconferencing;video
	communication;image synchronization;moving human reconstruction algorithm;live
	reconstruction;video conferencing;immersive collaborative virtual
	environment;3D video;teleimmersion prototypes;visual-temporal quality;acquisition
	stage;multiple image feeding;jitter;frame synchronization;multiple
	camera video streams;3D reconstruction;temporal divergence;Head;Cameras;Three
	dimensional displays;Streaming media;Synchronization;Image reconstruction;Encoding;tele-immersion;telepresence;3D
	reconstruction;synchronisation;litsurvey.bib}
}

@INPROCEEDINGS{Moore2011,
  author = {Moore, C and Duckworth, T and Roberts, D J},
  title = {{Investigating the Suitability of a Software Capture Trigger in a
	{3D} Reconstruction System for Telepresence}},
  booktitle = {2011 {IEEE/ACM} 15th International Symposium on Distributed Simulation
	and Real Time Applications},
  year = {2011},
  pages = {134--137},
  month = {\#sep\#},
  abstract = {In this paper we examine how closely together images to be used in
	3D reconstruction are captured, when acquisition is started using
	a software-based trigger delivered to multiple computers on a network.
	In addition we compare a software triggered pull system to a push
	system. Synchronisation is a key component in 3D reconstruction systems
	and can also be one of the most problematic. In a shape-from-silhouette
	based system, images are captured at the same moment to ensure the
	position of the object is consistent in all frames. Differences in
	position between captured frames results in deformations such as
	holes and missing or extended features. By capturing images of a
	projected clock, we can tell with around 10ms granularity, how closely
	together images are captured. This gives us an indication of whether
	software capture triggers delivered over a network can be used for
	image acquisition in a 3D reconstruction system, instead of hardware
	synchronised capture.},
  keywords = {image reconstruction;telecontrol;virtual reality;software capture
	trigger;3D reconstruction system;telepresence;software triggered
	pull system;push system;shape-from-silhouette based system;image
	acquisition;Cameras;Three dimensional displays;Synchronization;Image
	reconstruction;Computers;Hardware;Software;synchronisation;3D reconstruction;networking;telepresence;teleimmersion;litsurvey.bib}
}

@ARTICLE{Mori1970,
  author = {Mori, Masahiro},
  title = {The uncanny valley},
  journal = {Energy},
  year = {1970},
  volume = {7},
  pages = {33--35},
  number = {4},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{moritz2017trust,
  author = {Moritz, Dominik and Fisher, Danyel and Ding, Bolin and Wang, Chi},
  title = {Trust, but verify: Optimistic visualizations of approximate queries
	for exploring big data},
  booktitle = {Proceedings of the 2017 CHI conference on human factors in computing
	systems},
  year = {2017},
  pages = {2904--2915},
  organization = {ACM},
  file = {:../../../literature_repository/Data Visualisation/2017-TrustButVerify-CHI.pdf:PDF}
}

@INPROCEEDINGS{Mortensen2002,
  author = {Mortensen, Jesper and Vinayagamoorthy, V and Slater, Mel and Steed,
	Anthony and Lok, B and Whitton, M C},
  title = {Collaboration in tele-immersive environments},
  booktitle = {{ACM} International Conference Proceeding Series},
  year = {2002},
  volume = {23},
  pages = {93--101},
  institution = {Citeseer},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Moubayed2012,
  author = {Moubayed, Samer Al and Edlund, Jens and Beskow, Jonas},
  title = {Taming Mona Lisa},
  year = {2012},
  volume = {1},
  pages = {1--25},
  keywords = {litsurvey.bib}
}

@ARTICLE{Mulligan2002,
  author = {Mulligan, Jane and Isler, Volkan and Daniilidis, Kostas},
  title = {{Trinocular Stereo: A {Real-Time} Algorithm and its Evaluation}},
  journal = {Int. J. Comput. Vis.},
  year = {2002},
  volume = {47},
  pages = {51--61},
  number = {1-3},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Mulligan2000,
  author = {Mulligan, Jane Jane and Kaniilidis, K},
  title = {{Trinocular stereo for non-parallel configurations}},
  booktitle = {15\textbackslashtextsuperscript{th} International Conference on Pattern
	Recognition ({ICPR} 2000)},
  year = {2000},
  pages = {567--570},
  address = {Barcelona},
  keywords = {litsurvey.bib}
}

@ARTICLE{Munsell2013,
  author = {Munsell, Parri},
  title = {Skype and messenger coming together: the next chapter},
  journal = {URL: http://blogs. skype. com/2013/02/15/skype-and-messenger-coming-together-the-next-chapter/\#
	fbid= oFh6i6Q6aMm},
  year = {2013},
  keywords = {litsurvey.bib}
}

@ARTICLE{Munsell2013,
  author = {Munsell, Parri},
  title = {Skype and messenger coming together: the next chapter},
  journal = {URL: http://blogs. skype. com/2013/02/15/skype-and-messenger-coming-together-the-next-chapter/\#
	fbid= oFh6i6Q6aMm},
  year = {2013},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Murray2007,
  author = {Murray, Norman and Roberts, Dave and Steed, Anthony and Sharkey,
	Paul and Dickerson, Paul and Rae, John},
  title = {An assessment of eye-gaze potential within immersive virtual environments},
  month = {\#dec\#},
  year = {2007},
  keywords = {eye gaze, Immersive virtual environments;litsurvey.bib},
  number = {Article 8}
}

@ARTICLE{Murray2009,
  author = {Murray, Norman and Roberts, Dave and Steed, Anthony and Sharkey,
	Paul and Dickerson, Paul and Rae, John and Wolff, Robin},
  title = {Eye gaze in virtual environments: evaluating the need and initial
	work on implementation},
  journal = {Concurr. Comput.},
  year = {2009},
  volume = {21},
  pages = {1437--1449},
  number = {11},
  month = {\#aug\#},
  abstract = {Abstract For efficient collaboration between participants, eye gaze
	is seen as being critical for interaction. Video conferencing either
	does not attempt to support eye gaze (e.g. AcessGrid) or only approximates
	it in round table conditions (e.g. life size telepresence). Immersive
	collaborative virtual environments represent remote participants
	through avatars that follow their tracked movements. By additionally
	tracking people's eyes and representing their movement on their avatars,
	the line of gaze can be faithfully reproduced, as opposed to approximated.
	This paper presents the results of initial work that tested if the
	focus of gaze could be more accurately gauged if tracked eye movement
	was added to that of the head of an avatar observed in an immersive
	VE. An experiment was conducted to assess the difference between
	user's abilities to judge what objects an avatar is looking at with
	only head movements being displayed, while the eyes remained static,
	and with eye gaze and head movement information being displayed.
	The results from the experiment show that eye gaze is of vital importance
	to the subjects correctly identifying what a person is looking at
	in an immersive virtual environment. This is followed by a description
	of the work that is now being undertaken following the positive results
	from the experiment. We discuss the integration of an eye tracker
	more suitable for immersive mobile use and the software and techniques
	that were developed to integrate the user's real-world eye movements
	into calibrated eye gaze in an immersive virtual world. This is to
	be used in the creation of an immersive collaborative virtual environment
	supporting eye gaze and its ongoing experiments. Copyright ? 2009
	John Wiley \& Sons, Ltd.},
  keywords = {litsurvey.bib},
  publisher = {Wiley Online Library}
}

@ARTICLE{Muhlbach1995,
  author = {M{\"u}hlbach, L and B{\"o}cker, M and Prussog, A},
  title = {Telepresence in videocommunications: a study on stereoscopy and individual
	eye contact},
  journal = {Hum. Factors},
  year = {1995},
  volume = {37},
  pages = {290--305},
  number = {2},
  month = {\#jun\#},
  abstract = {We conducted two experiments to investigate how stereoscopy and technologies
	that allow individual eye contact affect the impression of telepresence
	in video-conferencing. Telepresence is defined as the degree to which
	participants of a telemeeting get the impression of sharing space
	with the remote site. Results revealed, among other things, that
	stereoscopy increases telepresence and makes videoconferencing more
	attractive. In addition, we found that reduced eye contact angles
	enhance the recognizability of individually addressed nonverbal signals.
	However, a setup that eliminates horizontal and vertical eye contact
	angles seems to be advantageous only in conferences with more than
	two persons per site.},
  keywords = {litsurvey.bib},
  language = {en}
}

@INPROCEEDINGS{Nagel1984,
  author = {Nagel, H H},
  title = {Spatio-temporal modeling based on image sequences},
  booktitle = {Proa. of the Inter. Symp. on Image Processing and it},
  year = {1984},
  pages = {18--21},
  keywords = {litsurvey.bib}
}

@InProceedings{Nagendran2012,
  author    = {Nagendran, Arjun and Pillat, Remo and Hughes, Charles and Welch, Greg},
  booktitle = {Proceedings of the 11th {ACM} {SIGGRAPH} International Conference on {Virtual-Reality} Continuum and its Applications in Industry},
  title     = {Continuum of virtual-human space: towards improved interaction strategies for physical-virtual avatars},
  year      = {2012},
  address   = {New York, NY, USA},
  month     = {\#dec\#},
  pages     = {135--142},
  publisher = {Association for Computing Machinery},
  series    = {VRCAI '12},
  keywords  = {Avatars, Microposes, Physical-Virtual Avatar, Remo; remote-operation;litsurvey.bib},
  location  = {Singapore, Singapore},
}

@ARTICLE{Nakamoto2008,
  author = {Nakamoto, Satoshi},
  title = {Re: Bitcoin P2P e-cash paper},
  journal = {Email posted to listserv},
  year = {2008},
  volume = {9},
  pages = {04},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/bitcoin.pdf:PDF}
}

@INPROCEEDINGS{Nakanishi2004,
  author = {Nakanishi, Hideyuki and Ishida, Toru},
  title = {{FreeWalk/Q}: social interaction platform in virtual space},
  booktitle = {Proceedings of the {ACM} symposium on Virtual reality software and
	technology},
  year = {2004},
  series = {VRST '04},
  pages = {97--104},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {scenario description, interaction platform, virtual city, virtual
	space, social interaction, virtual community, agent, virtual training,
	avatar;litsurvey.bib},
  location = {Hong Kong}
}

@INPROCEEDINGS{Nakanishi2009,
  author = {Nakanishi, Hideyuki and Murakami, Yuki and Kato, Kei},
  title = {Movable cameras enhance social telepresence in media spaces},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2009},
  series = {CHI '09},
  pages = {433--442},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {media space, motion parallax, telepresence;litsurvey.bib},
  location = {Boston, MA, USA}
}

@BOOK{Napier1983,
  title = {Making groups work: A guide for group leaders},
  publisher = {Houghton Mifflin},
  year = {1983},
  author = {Napier, Rodney and Gershenfeld, Matti K},
  keywords = {litsurvey.bib}
}

@BOOK{Napier1973,
  title = {Groups: Theory and experience},
  publisher = {Houghton Mifflin},
  year = {1973},
  author = {Napier, Rodney W and Gershenfeld, Matti K},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Nguyen2005,
  author = {Nguyen, David and Canny, John},
  title = {{MultiView}: spatially faithful group video conferencing},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2005},
  series = {CHI '05},
  pages = {799--808},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {video conferencing, spatial faithfulness, deixis, eye contact, gaze;litsurvey.bib},
  location = {Portland, Oregon, USA}
}

@INPROCEEDINGS{Nguyen2005,
  author = {Nguyen, David and Canny, John},
  title = {{MultiView}: spatially faithful group video conferencing},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2005},
  series = {CHI '05},
  pages = {799--808},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {video conferencing, spatial faithfulness, deixis, eye contact, gaze;litsurvey.bib},
  location = {Portland, Oregon, USA}
}

@INPROCEEDINGS{Nguyen2009,
  author = {Nguyen, David T and Canny, John},
  title = {More than face-to-face: empathy effects of video framing},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2009},
  series = {CHI '09},
  pages = {423--432},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {video conferencing, empathy, oneness;litsurvey.bib},
  location = {Boston, MA, USA}
}

@INPROCEEDINGS{Nielsen1995,
  author = {Nielsen, Jakob},
  title = {Usability inspection methods},
  booktitle = {Conference Companion on Human Factors in Computing Systems},
  year = {1995},
  series = {CHI '95},
  pages = {377--378},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {Denver, Colorado, USA}
}

@PHDTHESIS{Nilsson2004,
  author = {Nilsson, Cindy},
  title = {{Computer-Supported} Cooperative Work and Embodied Social Interaction},
  year = {2004},
  abstract = {Research in Computer-Supported Cooperative Work (CSCW) has identified
	a gap - the, so called, social-technical gap - between the wide range
	of human social interactions that CSCW ideally should sup ...},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Institutionen f{\"o}r kommunikation och information}
}

@BOOK{Nishibe2016,
  title = {The Enigma of Money: Gold, Central Banknotes, and Bitcoin},
  publisher = {Springer},
  year = {2016},
  author = {Nishibe, Makoto},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/The_Enigma_of_Money_Gold_Central.pdf:PDF}
}

@BOOK{Nitschke2007,
  title = {{3D} Reconstruction},
  publisher = {VDM Verlag},
  year = {2007},
  author = {Nitschke, Christian},
  series = {Real-time Volumetric Scene Reconstruction from Multiple Views},
  keywords = {litsurvey.bib}
}

@ARTICLE{Norman2002,
  author = {Norman, Donald A},
  title = {The psychopathology of everyday things},
  journal = {Foundations of cognitive psychology: core readings. MIT Press, Cambridge,
	MA},
  year = {2002},
  pages = {417--443},
  keywords = {litsurvey.bib}
}

@ARTICLE{Normand1999,
  author = {Normand, V{\'e}ronique and Babski, Christian and Benford, Steve and
	Bullock, Adrian and Carion, St{\'e}phane and Chrysanthou, Yiorgos
	and Farcet, Nicolas and Fr{\'e}con, Emmanuel and Harvey, John and
	Kuijpers, Nico and Magnenat-Thalmann, Nadia and Raupp-Musse, Soraia
	and Rodden, Tom and Slater, Mel and Smith, Gareth and Steed, Anthony
	and Thalmann, Daniel and Tromp, Jolanda and Usoh, Martin and Van
	Liempd, Gidi and Kladias, Nicos},
  title = {The {COVEN} Project: Exploring Applicative, Technical, and Usage
	Dimensions of Collaborative Virtual Environments},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {1999},
  volume = {8},
  pages = {218--236},
  number = {2},
  month = {\#apr\#},
  abstract = {COVEN (Collaborative Virtual Environments) is a European project that
	seeks to develop a comprehensive approach to the issues in the development
	of collaborative virtual environment (CVE) technology. COVEN brings
	together twelve academic and industrial partners with a wide range
	of expertise in CSCW, networked VR, computer graphics, human factors,
	HCI, and telecommunications infrastructures. After two years of work,
	we are presenting the main features of our approach and results,
	our driving applications, the main components of our technical investigations,
	and our experimental activities. With different citizen and professional
	application scenarios as driving forces, COVEN is exploring the requirements
	and supporting techniques for collaborative interaction in scalable
	CVEs. Technical results are being integrated in an enriched networked
	VR platform based on the dVS and DIVE systems. Taking advantage of
	a dedicated Europe-wide ISDN and ATM network infrastructure, a large
	component of the project is a trial and experimentation activity
	that should allow a comprehensive understanding of the network requirements
	of these systems as well as their usability issues and human factors
	aspects.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Norris2012,
  author = {Norris, James and Schn{\"a}delbach, Holger and Qiu, Guoping},
  title = {{CamBlend}: an object focused collaboration tool},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {627--636},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {interaction analysis, focus+context, collaboration, cscw;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@INPROCEEDINGS{Norris2013,
  author = {Norris, James and Schn{\"a}delbach, Holger M and Luff, Paul K},
  title = {Putting things in focus: establishing co-orientation through video
	in context},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {1329--1338},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {collaboration, cscw, focus+context, interaction analysis;litsurvey.bib},
  location = {Paris, France}
}

@INPROCEEDINGS{Novick1996,
  author = {Novick, D G and Hansen, B and Ward, K},
  title = {Coordinating turn-taking with gaze},
  booktitle = {Proceeding of Fourth International Conference on Spoken Language
	Processing. {ICSLP} '96},
  year = {1996},
  volume = {3},
  pages = {1888--1891 vol.3},
  month = {\#oct\#},
  abstract = {Explores the role of gaze in coordinating turn-taking in mixed-initiative
	conversation, and specifically how gaze indicators might be usefully
	modeled in computational dialogue systems. We analyzed about 20 minutes
	of videotape of eight dialogues by four pairs of subjects performing
	a simple face-to-face cooperative laboratory task. We extend previous
	studies by explicating gaze patterns in face-to-face conversations,
	formalizing the most frequent pattern as a computational model of
	turn-taking and testing the model through an agent-based simulation.
	Prior conversation simulations of conversational control acts relied
	on abstract speech-act representations of control. This study advances
	the computational account of dialogue through simulation of direct
	physical expression of gaze to coordinate conversational turns.},
  keywords = {behavioural sciences;digital simulation;software agents;cooperative
	systems;behavioural sciences computing;conversational turn-taking;gaze
	indicators;coordination;mixed-initiative conversation;computational
	dialogue systems;videotape;face-to-face cooperative laboratory task;gaze
	patterns;face-to-face conversations;agent-based simulation;conversational
	control acts;abstract speech-act representations;physical expression;Computational
	modeling;Laboratories;Power system modeling;Testing;Frequency;Natural
	languages;Performance analysis;Physics computing;Monitoring;Communication
	system control;litsurvey.bib}
}

@INPROCEEDINGS{Nowak2001,
  author = {Nowak, Kristen},
  title = {Defining and differentiating copresence, social presence and presence
	as transportation},
  booktitle = {Presence 2001 Conference, Philadelphia, {PA}},
  year = {2001},
  pages = {1--23},
  institution = {Citeseer},
  keywords = {litsurvey.bib}
}

@ARTICLE{Nowak2003,
  author = {Nowak, Kristine L and Biocca, Frank},
  title = {The Effect of the Agency and Anthropomorphism on Users' Sense of
	Telepresence, Copresence, and Social Presence in Virtual Environments},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2003},
  volume = {12},
  pages = {481--494},
  number = {5},
  month = {\#oct\#},
  abstract = {We report on an experiment that examined the influence of anthropomorphism
	and perceived agency on presence, copresence, and social presence
	in a virtual environment. The experiment varied the level of anthropomorphism
	of the image of interactants: high anthropomorphism, low anthropomorphism,
	or no image. Perceived agency was manipulated by telling the participants
	that the image was either an avatar controlled by a human, or an
	agent controlled by a computer. The results support the prediction
	that people respond socially to both human and computer-controlled
	entities, and that the existence of a virtual image increases tele-presence.
	Participants interacting with the less-anthropomorphic image reported
	more copresence and social presence than those interacting with partners
	represented by either no image at all or by a highly anthropomorphic
	image of the other, indicating that the more anthropomorphic images
	set up higher expectations that lead to reduced presence when these
	expectations were not met.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{OHare2016,
  author = {O'Hare, John and Bendall, Robert C A and Rae, John and Thomas, Graham
	and Weir, Bruce and Roberts, David J},
  title = {Is This Seat Taken? Behavioural Analysis of the Telethrone: A Novel
	Situated Telepresence Display},
  booktitle = {{ICAT-EGVE}},
  year = {2016},
  pages = {99--106},
  institution = {Eurographics Association},
  keywords = {litsurvey.bib}
}

@INCOLLECTION{OHare2018,
  author = {O'Hare, John and Fairchild, Allen J and Wolff, Robin and Roberts,
	David J},
  title = {Telethrone Reconstructed; Ongoing Testing Toward a More Natural Situated
	Display},
  booktitle = {Augmented Reality and Virtual Reality: Empowering Human, Place and
	Business},
  publisher = {Springer International Publishing},
  year = {2018},
  editor = {Jung, Timothy and tom Dieck, M Claudia},
  pages = {323--337},
  address = {Cham},
  abstract = {The concept of supporting ad hoc or dynamic membership tele-present
	meetings through pulling up a chair is novel. In real world business
	situations, people pull up a chair after catching the eye of someone
	already seated. Telethrone is a situated display on a chair which
	allows multiple correct views of a remote collaborator. The system
	has been expanded to support informal meetings where chairs can be
	moved around. This is facilitated through the novel integration of
	a 3D reconstructed model of a person, with live viewpoint dependent
	rendering onto a retro-reflective surface. This removes the need
	for painstaking alignment of multiple cameras and projectors each
	time a chair is moved. A between subjects experiment tested accuracy
	of reconnected mutual gaze mediated by part of the system. Subjectively
	easier and harder situations are compared. Specifically best and
	worst cases, both in terms of orientation of eyes in the reconstructed
	head, and angle of observer gaze onto the display. Discussion compares
	results to experiments that used other systems to attempt to convey
	eye gaze by different techniques. This research builds toward a scalable
	system for ad hoc business meetings; a paradigm poorly supported
	by current video conferencing. It is also applicable to supporting
	conversations between seated people in any scenario where seats might
	be moved, for example in interaction between client and therapist
	in tele-therapy.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{OMalley1996,
  author = {O'Malley, C and Langton, Steve},
  title = {Comparison Of Face-to-face And Video-mediated Interaction},
  year = {1996},
  volume = {2},
  pages = {177--192},
  keywords = {computer-supported;litsurvey.bib}
}

@ARTICLE{oeppen2020human,
  author = {Oeppen, RS and Shaw, G and Brennan, PA},
  title = {Human factors recognition at virtual meetings and video conferencing:
	how to get the best performance from yourself and others},
  journal = {British Journal of Oral and Maxillofacial Surgery},
  year = {2020},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Ohba1998,
  author = {Ohba, K and Tsukada, T and Kotoku, T and Tanie, K},
  title = {Facial expression space for smooth tele-communications},
  booktitle = {Proceedings Third {IEEE} International Conference on Automatic Face
	and Gesture Recognition},
  year = {1998},
  pages = {378--383},
  month = {\#apr\#},
  abstract = {In this paper, the facial expression is mainly focused to achieve
	the smooth tele-communications. The facial expressions has been considered
	as the most significant factor in tele-communications, such as tele-services.
	To realize the real time facial expression transportation system,
	we propose the facial expression space (FES) and a correspondence
	technique between each personal facial expression spaces. Then, real
	time facial expression transportation system is developed, which
	transports the facial expression but not the image itself. This final
	system is able to display the same facial expressions in another
	person and further more in cartoon characters. The experimental results
	show the validity of these criteria.},
  institution = {IEEE},
  keywords = {face recognition;facial expression space;smooth telecommunications;personal
	facial expression spaces;Humans;Telephony;Robot vision systems;TV;litsurvey.bib}
}

@PHDTHESIS{Ohta1986,
  author = {Ohta, Yuichi and Watanabe, Masaki and Ikeda, Katsuo},
  title = {{Improving Depth Map by Right-angled Trinocular Stereo}},
  school = {University of Tsukuba},
  year = {1986},
  keywords = {litsurvey.bib}
}

@ARTICLE{Okada2019,
  author = {Okada, Kaya and Yoshida, Mitsuo and Itoh, Takayuki and Czauderna,
	Tobias and Stephens, Kingsley},
  title = {VR system for spatio-temporal visualization of tweet data and support
	of map exploration},
  journal = {Multimedia Tools and Applications},
  year = {2019},
  volume = {78},
  pages = {32849--32868},
  number = {23},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08564144.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{Okada1994,
  author = {Okada, Ken-Ichi and Maeda, Fumihiko and Ichikawaa, Yusuke and Matsushita,
	Yutaka},
  title = {{Multiparty videoconferencing at virtual social distance: {MAJIC}
	design}},
  booktitle = {Proceedings of the 1994 {ACM} conference on Computer supported cooperative
	work},
  year = {1994},
  series = {CSCW '94},
  pages = {385--393},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  keywords = {multiparty videoconferencing, networked realities, tele-presence,
	MAJIC, gaze awareness, groupware, multiple eye contact;litsurvey.bib},
  location = {Chapel Hill, North Carolina, USA}
}

@ARTICLE{Okutomi1993,
  author = {Okutomi, M and Kanade, T},
  title = {A multiple-baseline stereo},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {1993},
  volume = {15},
  pages = {353--363},
  number = {4},
  month = {\#apr\#},
  abstract = {A stereo matching method that uses multiple stereo pairs with various
	baselines generated by a lateral displacement of a camera to obtain
	precise distance estimates without suffering from ambiguity is presented.
	Matching is performed simply by computing the sum of squared-difference
	(SSD) values. The SSD functions for individual stereo pairs are represented
	with respect to the inverse distance and are then added to produce
	the sum of SSDs. This resulting function is called the SSSD-in-inverse-distance.
	It is shown that the SSSD-in-inverse-distance function exhibits a
	unique and clear minimum at the correct matching position, even when
	the underlying intensity patterns of the scene include ambiguities
	or repetitive patterns. The authors first define a stereo algorithm
	based on the SSSD-in-inverse-distance and present a mathematical
	analysis to show how the algorithm can remove ambiguity and increase
	precision. Experimental results with real stereo images are presented
	to demonstrate the effectiveness of the algorithm.},
  keywords = {computer vision;stereo image processing;computer vision;multiple-baseline
	stereo;stereo matching method;lateral displacement;precise distance
	estimates;Stereo vision;Cameras;Layout;Pattern matching;Matched filters;Filtering;Mathematical
	analysis;Image matching;Computer vision;US Department of Defense;litsurvey.bib},
  publisher = {IEEE}
}

@INPROCEEDINGS{Olsson2007,
  author = {Olsson, Anna-Carin and di Zazzo, Nicole and Tjaderborn, Johanna},
  title = {Social decision making strategies in internet poker playing},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  year = {2007},
  volume = {29},
  pages = {1831},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Orts-Escolano2016,
  author = {Orts-Escolano, Sergio and Rhemann, Christoph and Fanello, Sean and
	Chang, Wayne and Kowdle, Adarsh and Degtyarev, Yury and Kim, David
	and Davidson, Philip L and Khamis, Sameh and Dou, Mingsong and Tankovich,
	Vladimir and Loop, Charles and Cai, Qin and Chou, Philip A and Mennicken,
	Sarah and Valentin, Julien and Pradeep, Vivek and Wang, Shenlong
	and Kang, Sing Bing and Kohli, Pushmeet and Lutchyn, Yuliya and Keskin,
	Cem and Izadi, Shahram},
  title = {Holoportation: Virtual {3D} Teleportation in Real-time},
  booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software
	and Technology},
  year = {2016},
  series = {UIST '16},
  pages = {741--754},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {gpu, depth cameras, 3d capture, real-time, telepresence, non-rigid
	reconstruction, mixed reality;litsurvey.bib},
  location = {Tokyo, Japan}
}

@INPROCEEDINGS{Ostrem2014,
  author = {Ostrem, Camilla},
  title = {A Behavior analytic perspective on gambling behavior},
  year = {2014},
  publisher = {H{\o}gskolen i Oslo og Akershus},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Otsuka2013,
  author = {Otsuka, Kazuhiro and Kumano, Shiro and Ishii, Ryo and Zbogar, Maja
	and Yamato, Junji},
  title = {{MM+Space}: n x 4 degree-of-freedom kinetic display for recreating
	multiparty conversation spaces},
  booktitle = {Proceedings of the 15th {ACM} on International conference on multimodal
	interaction},
  year = {2013},
  series = {ICMI '13},
  pages = {389--396},
  address = {New York, NY, USA},
  month = {\#dec\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {telepresence, face-to-face conversation, multimodal interaction, computer-mediated
	communication, projection mapping;litsurvey.bib},
  location = {Sydney, Australia}
}

@INPROCEEDINGS{Otsuka2013,
  author = {Otsuka, Kazuhiro and Kumano, Shiro and Ishii, Ryo and Zbogar, Maja
	and Yamato, Junji},
  title = {{MM+Space}: n x 4 degree-of-freedom kinetic display for recreating
	multiparty conversation spaces},
  booktitle = {Proceedings of the 15th {ACM} on International conference on multimodal
	interaction},
  year = {2013},
  series = {ICMI '13},
  pages = {389--396},
  address = {New York, NY, USA},
  month = {\#dec\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {telepresence, face-to-face conversation, multimodal interaction, computer-mediated
	communication, projection mapping;litsurvey.bib},
  location = {Sydney, Australia}
}

@INPROCEEDINGS{Otsuka2005,
  author = {Otsuka, Kazuhiro and Takemae, Yoshinao and Yamato, Junji},
  title = {A probabilistic inference of multiparty-conversation structure based
	on Markov-switching models of gaze patterns, head directions, and
	utterances},
  booktitle = {Proceedings of the 7th international conference on Multimodal interfaces},
  year = {2005},
  series = {ICMI '05},
  pages = {191--198},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {eye gaze, Markov-switching model, Gibbs sampler, dynamic Bayesian
	network, nonverbal cues, Markov chain Monte Carlo, face-to-face multiparty
	conversation;litsurvey.bib},
  location = {Torento, Italy}
}

@INPROCEEDINGS{Ott1993,
  author = {Ott, Maximilian and Lewis, John P and Cox, Ingemar},
  title = {Teleconferencing eye contract using a virtual camera},
  booktitle = {{INTERACT} '93 and {CHI} '93 Conference Companion on Human Factors
	in Computing Systems},
  year = {1993},
  series = {CHI '93},
  pages = {109--110},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {Amsterdam, The Netherlands}
}

@INPROCEEDINGS{Ou2005,
  author = {Ou, Jiazhi and Oh, Lui Min and Yang, Jie and Fussell, Susan R},
  title = {Effects of task properties, partner actions, and message content
	on eye gaze patterns in a collaborative task},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2005},
  series = {CHI '05},
  pages = {231--240},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {eye-tracking, conversational analysis, collaborative work, video mediated
	communication, gesture, empirical studies, video conferencing, computer-supported;litsurvey.bib},
  location = {Portland, Oregon, USA}
}

@InProceedings{Oyekoya2012,
  author    = {Oyekoya, Oyewole and Steptoe, William and Steed, Anthony},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
  title     = {{SphereAvatar}: a situated display to represent a remote collaborator},
  year      = {2012},
  address   = {New York, NY, USA},
  month     = {\#may\#},
  pages     = {2551--2560},
  publisher = {Association for Computing Machinery},
  series    = {CHI '12},
  keywords  = {Spherical displays, remote collaboration, telepres; avatars; telepresence; mixed reality; telerobotics;litsurvey.bib},
  location  = {Austin, Texas, USA},
}

@ARTICLE{Pahins2016,
  author = {Pahins, Cicero AL and Stephens, Sean A and Scheidegger, Carlos and
	Comba, Joao LD},
  title = {Hashedcubes: Simple, low memory, real-time visual exploration of
	big data},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2016},
  volume = {23},
  pages = {671--680},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07539326.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Pan2008,
  author = {Pan, Xueni and Gillies, Marco and Slater, Mel},
  title = {{Male Bodily Responses during an Interaction with a Virtual Woman}},
  booktitle = {Intelligent Virtual Agents},
  year = {2008},
  editor = {Prendinger, Helmut and Lester, James C and Ishizuka, Mitsuru},
  volume = {5208},
  series = {Lecture Notes in Computer Science},
  pages = {89--96},
  publisher = {Springer Berlin Heidelberg},
  abstract = {This work presents the analysis of the body movement of male participants,
	while talking with a life-size virtual woman in a virtual social
	encounter within a CAVE-like system. We consider independent and
	explanatory variables including whether the participant is the centre
	of attention in the scenario, whether the participant is shy or confident,
	and his relationship status. We also examine whether this interaction
	between the participant and the virtual character changes as the
	conversation progresses. The results show that the participants tend
	to have different hand movements, head movements, and posture depending
	on these conditions. This research therefore provides strong evidence
	for using body movement as a systematic method to assess the responses
	of people within a virtual environment, especially when the participant
	interacts with a virtual character. These results also point the
	way towards the application of this technology to the treatment of
	social phobic males.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Pan_undated,
  author = {Pan, Xueni and Gillies, Marco and Slater, Mel},
  title = {Male Bodily Responses towards a Virtual Woman},
  booktitle = {Symposium on Mental States, Emotions and their Embodiment},
  pages = {8},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Pan2008,
  author = {Pan, Xueni and Gillies, Marco and Slater, Mel},
  title = {Male Bodily Responses during an Interaction with a Virtual Woman},
  booktitle = {Intelligent Virtual Agents},
  year = {2008},
  pages = {89--96},
  publisher = {Springer Berlin Heidelberg},
  abstract = {This work presents the analysis of the body movement of male participants,
	while talking with a life-size virtual woman in a virtual social
	encounter within a CAVE-like system. We consider independent and
	explanatory variables including whether the participant is the centre
	of attention in the scenario, whether the participant is shy or confident,
	and his relationship status. We also examine whether this interaction
	between the participant and the virtual character changes as the
	conversation progresses. The results show that the participants tend
	to have different hand movements, head movements, and posture depending
	on these conditions. This research therefore provides strong evidence
	for using body movement as a systematic method to assess the responses
	of people within a virtual environment, especially when the participant
	interacts with a virtual character. These results also point the
	way towards the application of this technology to the treatment of
	social phobic males.},
  institution = {Springer},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Pan2014,
  author = {Pan, Ye and Steed, Anthony},
  title = {A gaze-preserving situated multiview telepresence system},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2014},
  series = {CHI '14},
  pages = {2173--2176},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {non-planar displays, camera arrays, gaze;litsurvey.bib},
  location = {Toronto, Ontario, Canada}
}

@INPROCEEDINGS{Pan2012,
  author = {Pan, Y and Steed, A},
  title = {Preserving gaze direction in teleconferencing using a camera array
	and a spherical display},
  booktitle = {2012 {3DTV-Conference}: The True Vision - Capture, Transmission and
	Display of {3D} Video ({3DTV-CON})},
  year = {2012},
  pages = {1--4},
  month = {\#oct\#},
  abstract = {The movement of human gaze is very important in face to face conversation.
	Some of the quality of that movement is lost in videoconferencing
	because the participants look at a single planar image of the remote
	person. We use an array of cameras to capture a remote user, and
	then display video of that person on a spherical display. We compare
	the spherical display to a face to face setting and a planar display.
	We demonstrate the effectiveness of the camera array and spherical
	display system in that it allows observers to accurately judge where
	the remote user is placing their gaze.},
  institution = {IEEE},
  keywords = {cameras;computer displays;teleconferencing;video communication;video
	signal processing;gaze direction preservation;teleconferencing;camera
	array;videoconferencing;single planar image;display video;planar
	display;spherical display system;remote user;human gaze;Observers;Cameras;Face;Accuracy;Arrays;Streaming
	media;Non-planar displays;camera arrays;human gaze;litsurvey.bib}
}

@INPROCEEDINGS{Pan2014,
  author = {Pan, Ye and Steptoe, William and Steed, Anthony},
  title = {Comparing flat and spherical displays in a trust scenario in avatar-mediated
	interaction},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2014},
  series = {CHI '14},
  pages = {1397--1406},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {avatars, telecommunication, spherical displays, trust, mixed reality;litsurvey.bib},
  location = {Toronto, Ontario, Canada}
}

@ARTICLE{Pandove2018,
  author = {Pandove, Divya and Goel, Shivan and Rani, Rinkl},
  title = {Systematic review of clustering high-dimensional and large datasets},
  journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
  year = {2018},
  volume = {12},
  pages = {16},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/clustering/3132088.pdf:PDF},
  publisher = {ACM}
}

@INPROCEEDINGS{Pappu2013,
  author = {Pappu, Aasish and Sun, Ming and Sridharan, Seshadri and Rudnicky,
	Alex},
  title = {Situated Multiparty Interaction between Humans and Agents},
  booktitle = {{Human-Computer} Interaction. Interaction Modalities and Techniques},
  year = {2013},
  pages = {107--116},
  publisher = {Springer Berlin Heidelberg},
  abstract = {A social agent such as a receptionist or an escort robot encounters
	challenges when communicating with people in open areas. The agent
	must know not to react to distracting acoustic and visual events
	and it needs to appropriately handle situations that include multiple
	humans, being able to to focus on active interlocutors and appropriately
	shift attention based on the context. We describe a multiparty interaction
	agent that helps multiple users arrange a common activity. From the
	user study we conducted, we found that the agent can discriminate
	between active and inactive interlocutors well by using the skeletal
	and azimuth information. Participants found the addressee much clearer
	when an animated talking head was used.},
  institution = {Springer},
  keywords = {litsurvey.bib}
}

@ARTICLE{Parsons1974,
  author = {Parsons, H M},
  title = {What Happened at Hawthorne?: New evidence suggests the Hawthorne
	effect resulted from operant reinforcement contingencies},
  journal = {Science},
  year = {1974},
  volume = {183},
  pages = {922--932},
  number = {4128},
  month = {\#mar\#},
  abstract = {The Hawthorne effect in experimental research is the unwanted effect
	of the experimental operations themselves. Following the Hawthorne
	studies, various explanations have been proposed to account for rising
	rates of production. Although in the Relay Assembly Test Room experiment
	the experimental operations may have produced other extraneous variables,
	a reexamination based on new and neglected evidence has yielded a
	new interpretation. The new variable, made more plausible because
	research in other contexts has shown it to have similar effects,
	is a combination of information feedback and financial reward. It
	is an example of the control of behavior by its consequences. Although
	several approaches may be taken to explain the effects of response-consequence
	contingencies, I have favored operant conditioning because it seems
	to account for progressive increases in response rate-the Hawthorne
	phenomenon. Generalizing from the particular situation at Hawthorne,
	I would define the Hawthorne effect as the confounding that occurs
	if experimenters fail to realize how the consequences of subjects'
	performance affect what subjects do. But the Hawthorne effect need
	not be viewed solely as a problem in conducting experiments. The
	phenomenon that created it should be studied in its own right, as
	Sommer (67) suggested with a different phenomenon in mind. The study
	of response-consequence contingencies might well be extended to the
	examination of motivation in industrial workers.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {American Association for the Advancement of Science}
}

@INPROCEEDINGS{Paulos1998,
  author = {Paulos, Eric and Canny, John},
  title = {{PRoP}: personal roving presence},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1998},
  series = {CHI '98},
  pages = {296--303},
  address = {USA},
  month = {\#jan\#},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  institution = {ACM Press/Addison-Wesley Publishing Co.},
  keywords = {tele-embodiment, tele-presence, gesturing, robotics, telecommunications,
	tele-work, tele-robotics, tele-conferencing, computer-mediated human-human
	interaction, tele-action;litsurvey.bib},
  location = {Los Angeles, California, USA}
}

@INPROCEEDINGS{Paulos2004,
  author = {Paulos, Eric and Goodman, Elizabeth},
  title = {The familiar stranger: anxiety, comfort, and play in public places},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2004},
  series = {CHI '04},
  pages = {223--230},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {d{\'e}tournement, public place, wearable, urban computing, wireless,
	strangers, community, d{\'e}rive, digital scent;litsurvey.bib},
  location = {Vienna, Austria}
}

@INPROCEEDINGS{Pece2013,
  author = {Pece, Fabrizio and Steptoe, William and Wanner, Fabian and Julier,
	Simon and Weyrich, Tim and Kautz, Jan and Steed, Anthony},
  title = {Panoinserts: mobile spatial teleconferencing},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {1319--1328},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {camera tracking, mixed reality, remote collaboration, teleconferencing,
	telepresence, mobile phones, panoramas;litsurvey.bib},
  location = {Paris, France}
}

@INPROCEEDINGS{Pejsa2016,
  author = {Pejsa, Tomislav and Kantor, Julian and Benko, Hrvoje and Ofek, Eyal
	and Wilson, Andrew},
  title = {{Room2Room}: Enabling {Life-Size} Telepresence in a Projected Augmented
	Reality Environment},
  booktitle = {Proceedings of the 19th {ACM} Conference on {Computer-Supported}
	Cooperative Work \& Social Computing},
  year = {2016},
  series = {CSCW '16},
  pages = {1716--1725},
  address = {New York, NY, USA},
  month = {\#feb\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {projector camera system, spatial augmented reality, projection-mapping,
	Telepresence, spatial interfaces;litsurvey.bib},
  location = {San Francisco, California, USA}
}

@INPROCEEDINGS{Pelechano2008,
  author = {Pelechano, Nuria and Stocker, Catherine and Allbeck, Jan and Badler,
	Norman},
  title = {Being a part of the crowd: towards validating {VR} crowds using presence},
  booktitle = {Proceedings of the 7th international joint conference on Autonomous
	agents and multiagent systems-Volume 1},
  year = {2008},
  pages = {136--142},
  institution = {International Foundation for Autonomous Agents and Multiagent Systems},
  keywords = {litsurvey.bib}
}

@ARTICLE{Perez-Marcos2012,
  author = {Perez-Marcos, Daniel and Solazzi, Massimiliano and Steptoe, William
	and Oyekoya, Oyewole and Frisoli, Antonio and Weyrich, Tim and Steed,
	Anthony and Tecchia, Franco and Slater, Mel and Sanchez-Vives, Maria
	V},
  title = {A fully immersive set-up for remote interaction and neurorehabilitation
	based on virtual body ownership},
  journal = {Front. Neurol.},
  year = {2012},
  volume = {3},
  pages = {110},
  month = {\#jul\#},
  abstract = {Although telerehabilitation systems represent one of the most technologically
	appealing clinical solutions for the immediate future, they still
	present limitations that prevent their standardization. Here we propose
	an integrated approach that includes three key and novel factors:
	(a) fully immersive virtual environments, including virtual body
	representation and ownership; (b) multimodal interaction with remote
	people and virtual objects including haptic interaction; and (c)
	a physical representation of the patient at the hospital through
	embodiment agents (e.g., as a physical robot). The importance of
	secure and rapid communication between the nodes is also stressed
	and an example implemented solution is described. Finally, we discuss
	the proposed approach with reference to the existing literature and
	systems.},
  keywords = {body ownership; haptics; multisensory correlations; neurorehabilitation;
	rubber hand illusion; telemedicine; teleneurology; virtual reality;litsurvey.bib},
  language = {en},
  publisher = {Frontiers Media SA}
}

@INPROCEEDINGS{Perez-Marcos2012,
  author = {Perez-Marcos, Daniel and Solazzi, Massimiliano and Steptoe, William
	and Oyekoya, Oyewole and Frisoli, Antonio and Weyrich, Tim and Steed,
	Anthony and Tecchia, Franco and Slater, Mel and Sanchez-Vives, Maria
	V},
  title = {A Fully Immersive Set-up For Remote Interaction And Neurorehabilitation
	Based On Virtual Body Ownership},
  year = {2012},
  volume = {3},
  publisher = {Frontiers Media SA},
  keywords = {litsurvey.bib}
}

@ARTICLE{Perozzi2018,
  author = {Perozzi, Bryan and Akoglu, Leman},
  title = {Discovering communities and anomalies in attributed graphs: Interactive
	visual exploration and summarization},
  journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
  year = {2018},
  volume = {12},
  pages = {24},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/3139241.pdf:PDF},
  publisher = {ACM}
}

@INPROCEEDINGS{Petit2008,
  author = {Petit, Benjamin and Lesage, Jean-Denis and Franco, Jean-S{\'e}bastien
	and Boyer, Edmond and Raffin, Bruno},
  title = {{Grimage: {3D} modeling for remote collaboration and telepresence}},
  booktitle = {Proceedings of the 2008 {ACM} symposium on Virtual reality software
	and technology},
  year = {2008},
  series = {VRST '08},
  pages = {299--300},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  keywords = {telepresence, marker-less 3D modeling, PC cluster, multi-cameras,
	collaborative 3D interactions;litsurvey.bib},
  location = {Bordeaux, France}
}

@ARTICLE{Petit2009,
  author = {Petit, Benjamin and Lesage, Jean-Denis and Menier, Cl{\'e}ment and
	Allard, J{\'e}r{\'e}mie and Franco, Jean-S{\'e}bastien and Raffin,
	Bruno and Boyer, Edmond and Faure, Fran{\c c}ois},
  title = {{Multicamera {Real-Time} {3D} Modeling for Telepresence and Remote
	Collaboration}},
  journal = {International Journal of Digital Multimedia Broadcasting},
  year = {2009},
  volume = {2010},
  pages = {1--12},
  month = {\#nov\#},
  abstract = {We present a multicamera real-time 3D modeling system that aims at
	enabling new immersive and interactive environments. This system,
	called Grimage, allows to retrieve in real-time a 3D mesh of the
	observed scene as well as the associated textures. This information
	enables a strong visual presence of the user into virtual worlds.
	The 3D shape information is also used to compute collisions and reaction
	forces with virtual objects, enforcing the mechanical presence of
	the user in the virtual world. The innovation is a fully integrated
	system with both immersive and interactive capabilities. It embeds
	a parallel version of the EPVH modeling algorithm inside a distributed
	vision pipeline. It also adopts the hierarchical component approach
	of the FlowVR middleware to enforce software modularity and enable
	distributed executions. Results show high refresh rates and low latencies
	obtained by taking advantage of the I/O and computing resources of
	PC clusters. The applications we have developed demonstrate the quality
	of the visual and mechanical presence with a single platform and
	with a dual platform that allows telecollaboration.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Hindawi}
}

@INPROCEEDINGS{pienta2015scalable,
  author = {Pienta, Robert and Abello, James and Kahng, Minsuk and Chau, Duen
	Horng},
  title = {Scalable graph exploration and visualization: Sensemaking challenges
	and opportunities},
  booktitle = {2015 International Conference on Big Data and Smart Computing (BIGCOMP)},
  year = {2015},
  pages = {271--278},
  organization = {IEEE},
  file = {:../../../literature_repository/Data Visualisation/07072812.pdf:PDF}
}

@INPROCEEDINGS{Po-Hao_Huang2008,
  author = {{Po-Hao Huang} and {Shang-Hong Lai}},
  title = {{Silhouette-based camera calibration from sparse views under circular
	motion}},
  booktitle = {2008 {IEEE} Conference on Computer Vision and Pattern Recognition},
  year = {2008},
  pages = {1--8},
  address = {Anchorage},
  month = {\#jun\#},
  abstract = {In this paper, we propose a new approach to camera calibration from
	silhouettes under circular motion with minimal data. We exploit the
	mirror symmetry property and derive a common homography that relates
	silhouettes with epipoles under circular motion. With the epipoles
	determined, the homography can be computed from the frontier points
	induced by epipolar tangencies. On the other hand, given the homography,
	the epipoles can be located directly from the bi-tangent lines of
	silhouettes. With the homography recovered, the image invariants
	under circular motion and camera parameters can be determined. If
	the epipoles are not available, camera parameters can be determined
	by a low-dimensional search of the optimal homography in a bounded
	region. In the degenerate case, when the camera optical axes intersect
	at one point, we derive a closed-form solution for the focal length
	to solve the problem. By using the proposed algorithm, we can achieve
	camera calibration simply from silhouettes of three images captured
	under circular motion. Experimental results on synthetic and real
	images are presented to show its performance.},
  keywords = {calibration;cameras;image motion analysis;image silhouette-based camera
	calibration;sparse camera view;circular motion;mirror symmetry property;homography;bi-tangent
	line;camera optical intersect axes;camera focal length;Cameras;Calibration;Mirrors;Closed-form
	solution;Computer vision;Laboratories;Computer science;Image sequences;Robustness;Computational
	geometry;litsurvey.bib}
}

@INCOLLECTION{Pollefeys2009,
  author = {Pollefeys, Marc and Sinha, Sudipta N and Guan, Li and Franco, Jean-S{\'e}bastien},
  title = {{CHAPTER} 2 - {Multi-View} Calibration, Synchronization, and Dynamic
	Scene Reconstruction},
  booktitle = {{Multi-Camera} Networks},
  publisher = {Academic Press},
  year = {2009},
  editor = {Aghajan, Hamid and Cavallaro, Andrea},
  pages = {29--75},
  address = {Oxford},
  month = {\#jan\#},
  abstract = {Abstract In this chapter, we first present a method for automatic
	camera network geometric calibration. The novel RANSAC-based calibration
	algorithm simultaneously computes camera poses and synchronization
	only from the objects of interest's (foreground object's) silhouette
	information in the videos from the multiple views. Then using this
	calibrated system, and again just from the silhouette cues, we introduce
	a probabilistic sensor fusion framework for 3D dynamic, scene reconstruction
	with potential static obstacles. Several real-world data sets show
	that despite lighting variation, photometric inconsistency between
	views, shadows, reflections, and so forth, not only are densely cluttered
	dynamic objects reconstructed and tracked, but static obstacles in
	the scene are also recovered.},
  keywords = {epipolar geometry; frontier points; epipolar tangents; RANSAC; structure
	from motion; visual hulls; occlusion; dynamic scene reconstruction;
	shape from silhouette; sensor fusion; probability; Bayes rule;litsurvey.bib}
}

@ARTICLE{Porter2008,
  author = {Porter, Stephen and ten Brinke, Leanne},
  title = {Reading between the lies: identifying concealed and falsified emotions
	in universal facial expressions},
  journal = {Psychol. Sci.},
  year = {2008},
  volume = {19},
  pages = {508--514},
  number = {5},
  month = {\#may\#},
  abstract = {The widespread supposition that aspects of facial communication are
	uncontrollable and can betray a deceiver's true emotion has received
	little empirical attention. We examined the presence of inconsistent
	emotional expressions and ``microexpressions'' (1/25-1/5 of a second)
	in genuine and deceptive facial expressions. Participants viewed
	disgusting, sad, frightening, happy, and neutral images, responding
	to each with a genuine or deceptive (simulated, neutralized, or masked)
	expression. Each 1/30-s frame (104,550 frames in 697 expressions)
	was analyzed for the presence and duration of universal expressions,
	microexpressions, and blink rate. Relative to genuine emotions, masked
	emotions were associated with more inconsistent expressions and an
	elevated blink rate; neutralized emotions showed a decreased blink
	rate. Negative emotions were more difficult to falsify than happiness.
	Although untrained observers performed only slightly above chance
	at detecting deception, inconsistent emotional leakage occurred in
	100\% of participants at least once and lasted longer than the current
	definition of a microexpression suggests. Microexpressions were exhibited
	by 21.95\% of participants in 2\% of all expressions, and in the
	upper or lower face only.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@ARTICLE{Porter2008,
  author = {Porter, Stephen and ten Brinke, Leanne},
  title = {Reading between the lies: identifying concealed and falsified emotions
	in universal facial expressions},
  journal = {Psychol. Sci.},
  year = {2008},
  volume = {19},
  pages = {508--514},
  number = {5},
  month = {\#may\#},
  abstract = {The widespread supposition that aspects of facial communication are
	uncontrollable and can betray a deceiver's true emotion has received
	little empirical attention. We examined the presence of inconsistent
	emotional expressions and ``microexpressions'' (1/25-1/5 of a second)
	in genuine and deceptive facial expressions. Participants viewed
	disgusting, sad, frightening, happy, and neutral images, responding
	to each with a genuine or deceptive (simulated, neutralized, or masked)
	expression. Each 1/30-s frame (104,550 frames in 697 expressions)
	was analyzed for the presence and duration of universal expressions,
	microexpressions, and blink rate. Relative to genuine emotions, masked
	emotions were associated with more inconsistent expressions and an
	elevated blink rate; neutralized emotions showed a decreased blink
	rate. Negative emotions were more difficult to falsify than happiness.
	Although untrained observers performed only slightly above chance
	at detecting deception, inconsistent emotional leakage occurred in
	100\% of participants at least once and lasted longer than the current
	definition of a microexpression suggests. Microexpressions were exhibited
	by 21.95\% of participants in 2\% of all expressions, and in the
	upper or lower face only.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {SAGE Publications}
}

@ARTICLE{Potmesil1987,
  author = {Potmesil, Michael},
  title = {{Generating octree models of {3D} objects from their silhouettes
	in a sequence of images}},
  journal = {Computer Vision, Graphics, and Image Processing},
  year = {1987},
  volume = {37},
  pages = {438},
  number = {3},
  month = {\#mar\#},
  keywords = {litsurvey.bib}
}

@ARTICLE{Potter_van_Loon2015,
  author = {Potter van Loon, Rogier J D and van den Assem, Martijn J and van
	Dolder, Dennie},
  title = {Beyond chance? The persistence of performance in online poker},
  journal = {PLoS One},
  year = {2015},
  volume = {10},
  pages = {e0115479},
  number = {3},
  month = {\#mar\#},
  abstract = {A major issue in the widespread controversy about the legality of
	poker and the appropriate taxation of winnings is whether poker should
	be considered a game of skill or a game of chance. To inform this
	debate we present an analysis into the role of skill in the performance
	of online poker players, using a large database with hundreds of
	millions of player-hand observations from real money ring games at
	three different stakes levels. We find that players whose earlier
	profitability was in the top (bottom) deciles perform better (worse)
	and are substantially more likely to end up in the top (bottom) performance
	deciles of the following time period. Regression analyses of performance
	on historical performance and other skill-related proxies provide
	further evidence for persistence and predictability. Simulations
	point out that skill dominates chance when performance is measured
	over 1,500 or more hands of play.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Public Library of Science}
}

@INPROCEEDINGS{Poullis2007,
  author = {Poullis, C and You, S and Neumann, U},
  title = {{Generating {High-Resolution} Textures for {3D} Virtual Environments
	using {View-Independent} Texture Mapping}},
  booktitle = {2007 {IEEE} International Conference on Multimedia and Expo},
  year = {2007},
  pages = {1295--1298},
  address = {Beijing},
  month = {\#jul\#},
  abstract = {Image based modeling and rendering techniques have become increasingly
	popular for creating and visualizing 3D models from a set of images.
	Typically, these techniques depend on view-dependent texture mapping
	to render the textured 3D models in which the texture of novel views
	is synthesized at runtime according to different view-points. This
	is computationally expensive and limits their application in domains
	where efficient computations are required, such as games and virtual
	reality. In this paper we present an offline technique for creating
	view-independent texture atlases for 3D models, given a set of registered
	images. The best texture map resolution is computed by considering
	the areas of the projected polygons in the images. Texture maps are
	generated by a weighted composition of all available image information
	in the scene.Assuming that all surfaces of the model are exhibiting
	Lambertian reflectance properties, ray-tracing is then employed,
	for creating the view-independent texture maps. Finally, all the
	generated texture maps are packed into texture atlases. The result
	is a 3D model with an associated view-independent texture atlas which
	can be used efficiently in any application without any knowledge
	of camera pose information.},
  keywords = {image texture;ray tracing;rendering (computer graphics);virtual reality;high-resolution
	textures;3D virtual environments;view-independent texture mapping;image
	based modeling;rendering;games;virtual reality;3D models;texture
	map resolution;image information;Lambertian reflectance properties;ray
	tracing;Virtual environment;Rendering (computer graphics);Visualization;Runtime;Virtual
	reality;Image resolution;Surface texture;Reflectivity;Ray tracing;Cameras;litsurvey.bib}
}

@UNPUBLISHED{ProjectionMappingCentral_undated-dj,
  author = {{ProjectionMappingCentral}},
  title = {History of projection mapping},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Qing-xi2009,
  author = {Qing-xi, H and Tao, L and Yuan, Y},
  title = {An Easy System of Spatial Points Collection Based On {ARtoolKit}},
  booktitle = {2009 {WRI} World Congress on Computer Science and Information Engineering},
  year = {2009},
  volume = {1},
  pages = {582--586},
  month = {\#mar\#},
  abstract = {In this paper, we propose and develop an interactive system based
	on ARtoolKit, which can be employed to pick up points in spatial
	environment. This system is composed of four parts: Detection Pen
	(DP), single marker, webcam and computer. It is tracked using markers
	and the system translates the center position of DPpsila s leading
	marker to the location of pen-point within the webcam coordinate
	system. Therefore, the positions in physical world can be detected
	by acquiring the pen-point coordinate within the single marker coordinate
	system. As the markers-based image segmentation for a small region
	is swift, the process is a real-time. The experimental result indicates
	that it is able to pick-up points steadily. In addition, the system
	is easy and quite convenient to operate. So it has good potential
	in 3D interaction design.},
  keywords = {biology computing;computers;image segmentation;medical image processing;spatial
	points collection;ARtoolKit;detection pen;computer;webcam coordinate
	system;pen-point coordinate;single marker coordinate system;marker-based
	image segmentation;3D interaction design;Bones;Surgery;Interactive
	systems;Costs;Computer science;Systems engineering and theory;Computer
	aided manufacturing;Pulp manufacturing;Image segmentation;Focusing;Augmented
	Reality;3D design;interactive;ARtoolKit;litsurvey.bib}
}

@INPROCEEDINGS{Radovan2006,
  author = {Radovan, Mauricio and Pretorius, Laurette},
  title = {Facial animation in a nutshell: past, present and future},
  booktitle = {Proceedings of the 2006 annual research conference of the South African
	institute of computer scientists and information technologists on
	{IT} research in developing countries},
  year = {2006},
  series = {SAICSIT '06},
  pages = {71--79},
  address = {ZAF},
  month = {\#oct\#},
  publisher = {South African Institute for Computer Scientists and Information Technologists},
  institution = {South African Institute for Computer Scientists and Information Technologists},
  keywords = {HCI, animation, computer graphics;litsurvey.bib},
  location = {Somerset West, South Africa}
}

@INPROCEEDINGS{Rae2013,
  author = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
  title = {In-body experiences: embodiment, control, and trust in robot-mediated
	communication},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {1921--1930},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {computer-mediated communication, videoconferencing, robot-mediated
	communication, control, trust, embodiment, computer-supported collaborative
	work;litsurvey.bib},
  location = {Paris, France}
}

@INPROCEEDINGS{Rae2012,
  author = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
  title = {One of the gang: supporting in-group behavior for embodied mediated
	communication},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {3091--3100},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {in-group behavior, embodied mediated communication, remote presence;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@ARTICLE{Rae2001,
  author = {Rae, John},
  title = {Organizing Participation in Interaction: Doing Participation Framework},
  journal = {Research on Language and Social Interaction},
  year = {2001},
  volume = {34},
  pages = {253--278},
  number = {2},
  month = {\#apr\#},
  abstract = {Goffman (1981) introduced the terms participation status and participation
	framework to differentiate how people involved in an interactional
	setting participate in that setting. In this article, I examine a
	particular work context in which participants in an interaction reorganize
	their participation such that, although remaining physically copresent,
	one of them makes or receives telephone calls to or from a non-copresent
	party. I show how this is a major site of body movement, including
	synchronous postural change (Kendon, 1990) before and after the call,
	and I examine the participants' vocal and nonvocal resources for
	entry into involvement with the phone call. Examination of these
	resources leads to a critical assessment of the concept of participation
	frameworks.},
  keywords = {litsurvey.bib},
  publisher = {Routledge}
}

@INPROCEEDINGS{Ramanathan2000,
  author = {Ramanathan, Prashant and Steinbach, Eckehard G and Girod, Bernd},
  title = {{Silhouette-Based} {Multiple-View} Camera Calibration},
  booktitle = {{VMV}},
  year = {2000},
  pages = {3--10},
  keywords = {litsurvey.bib}
}

@ARTICLE{Ramesh2004,
  author = {Ramesh, V and Glass, Robert L and Vessey, Iris},
  title = {{Research in computer science: an empirical study}},
  journal = {J. Syst. Softw.},
  year = {2004},
  volume = {70},
  pages = {165--176},
  number = {1},
  month = {\#feb\#},
  abstract = {In this paper, we examine the state of computer science (CS) research
	from the point of view of the following research questions:1.What
	topics do CS researchers address?2.What research approaches do CS
	researchers use?3.What research methods do CS researchers use?4.On
	what reference disciplines does CS research depend?5.At what levels
	of analysis do CS researchers conduct research? To answer these questions,
	we examined 628 papers published between 1995 and 1999 in 13 leading
	research journals in the CS field. Our results suggest that while
	CS research examines a variety of technical topics it is relatively
	focused in terms of the level at which research is conducted as well
	as the research techniques used. Further, CS research seldom relies
	on work outside the discipline for its theoretical foundations. We
	present our findings as an evaluation of the state of current research
	and as groundwork for future CS research efforts.},
  keywords = {Topic=Computing research; Research Approach=Evaluative-Other; Research
	Method=Literature analysis; Reference Discipline=Not applicable;
	Level of Analysis=Profession;litsurvey.bib}
}

@INPROCEEDINGS{Ranjan2007,
  author = {Ranjan, Abhishek and Birnholtz, Jeremy P and Balakrishnan, Ravin},
  title = {Dynamic shared visual spaces: experimenting with automatic camera
	control in a remote repair task},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {1177--1186},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {camera control, empirical studies, video mediated communication, video
	conferencing, computer-supported cooperative work, collaboration,
	motion tracking;litsurvey.bib},
  location = {San Jose, California, USA}
}

@INPROCEEDINGS{Rappoport1997,
  author = {Rappoport, Ari and Spitz, Steven},
  title = {{Interactive Boolean operations for conceptual design of {3-D} solids}},
  booktitle = {Proceedings of the 24th annual conference on Computer graphics and
	interactive techniques},
  year = {1997},
  series = {SIGGRAPH '97},
  pages = {269--278},
  address = {USA},
  month = {\#aug\#},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  keywords = {solid modeling, convex differences aggregate, geometric modeling,
	Boolean operations, convex differences, convex polyhedra, conceptual
	design;litsurvey.bib}
}

@InProceedings{Raskar1998,
  author    = {Raskar, Ramesh and Welch, Greg and Cutts, Matt and Lake, Adam and Stesin, Lev and Fuchs, Henry},
  booktitle = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques},
  title     = {The office of the future: A unified approach to image-based modeling and spatially immersive displays},
  year      = {1998},
  pages     = {179--188},
}

@INCOLLECTION{Raskar2001,
  author = {Raskar, Ramesh and Welch, Greg and Low, Kok-Lim and Bandyopadhyay,
	Deepak},
  title = {Shader Lamps: Animating Real Objects With {Image-Based} Illumination:
	Proceedings of the Eurographics Workshop in London, United Kingdom,
	June 25--27, 2001},
  booktitle = {Rendering Techniques 2001},
  publisher = {Springer Vienna},
  year = {2001},
  editor = {Gortler, Steven J and Myszkowski, Karol},
  volume = {20},
  series = {Eurographics},
  pages = {89--102},
  address = {Vienna},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Raskar2001,
  author = {Raskar, Ramesh and Welch, Greg and Low, Kok-Lim and Bandyopadhyay,
	Deepak},
  title = {Shader lamps},
  booktitle = {Proc. Eurographics Workshop on Rendering},
  year = {2001},
  keywords = {litsurvey.bib}
}

@ARTICLE{Reflecmedia_undated,
  author = {{Reflecmedia}},
  title = {Reflecmedia Chromatte information},
  keywords = {litsurvey.bib}
}

@ARTICLE{Regenbrecht2015,
  author = {Regenbrecht, Holger and Langlotz, Tobias},
  title = {Mutual Gaze Support in Videoconferencing Reviewed},
  journal = {Communications of the Association for Information Systems},
  year = {2015},
  volume = {37},
  pages = {45},
  number = {1},
  abstract = {Videoconferencing allows geographically dispersed parties to communicate
	by simultaneous audio and video transmissions. It is used in a variety
	of application scenarios with a wide range of coordination needs
	and efforts, such as private chat, discussion meetings, and negotiation
	tasks. In particular, in scenarios requiring certain levels of trust
	and judgement non-verbal communication, cues are highly important
	for effective communication. Mutual gaze support plays a central
	role in those high coordination need scenarios but generally lacks
	adequate technical support from videoconferencing systems. In this
	paper, we review technical concepts and implementations for mutual
	gaze support in videoconferencing, classify them, evaluate them according
	to a defined set of criteria, and give recommendations for future
	developments. Our review gives decision makers, researchers, and
	developers a tool to systematically apply and further develop videoconferencing
	systems in ``serious'' settings requiring mutual gaze. This should
	lead to well-informed decisions regarding the use and development
	of this technology and to a more widespread exploitation of the benefits
	of videoconferencing in general. For example, if videoconferencing
	systems supported high-quality mutual gaze in an easy-to-set-up and
	easy-to-use way, we could hold more effective and efficient recruitment
	interviews, court hearings, or contract negotiations.},
  keywords = {litsurvey.bib}
}

@InProceedings{Regenbrecht2002,
  author    = {Regenbrecht, Holger T and Wagner, Michael T},
  booktitle = {{CHI} '02 Extended Abstracts on Human Factors in Computing Systems},
  title     = {{Interaction in a collaborative augmented reality environment}},
  year      = {2002},
  address   = {New York, NY, USA},
  month     = {\#apr\#},
  pages     = {504--505},
  publisher = {Association for Computing Machinery},
  series    = {CHI EA '02},
  keywords  = {augmented reality, collaboration, cscw, tangible user; 3DUI; tangible user interfaces;litsurvey.bib},
  location  = {Minneapolis, Minnesota, USA},
}

@INPROCEEDINGS{Regenbrecht2002,
  author = {Regenbrecht, Holger T and Wagner, Michael T},
  title = {Interaction in a collaborative augmented reality environment},
  booktitle = {{CHI} '02 Extended Abstracts on Human Factors in Computing Systems},
  year = {2002},
  series = {CHI EA '02},
  pages = {504--505},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {augmented reality, 3DUI, tangible user interfaces, CSCW, collaboration;litsurvey.bib},
  location = {Minneapolis, Minnesota, USA}
}

@INPROCEEDINGS{Reitmaier2013,
  author = {Reitmaier, Thomas and Benz, Pierre and Marsden, Gary},
  title = {Designing and theorizing co-located interactions},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {381--390},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {co-located interaction, design research, theory, co-presence;litsurvey.bib},
  location = {Paris, France}
}

@ARTICLE{Remondino2006,
  author = {Remondino, Fabio and El-Hakim, Sabry},
  title = {Image-based {3D} Modelling: A Review},
  journal = {The Photogrammetric Record},
  year = {2006},
  volume = {21},
  pages = {269--291},
  number = {115},
  month = {\#aug\#},
  abstract = {Abstract In this paper the main problems and the available solutions
	are addressed for the generation of 3D models from terrestrial images.
	Close range photogrammetry has dealt for many years with manual or
	automatic image measurements for precise 3D modelling. Nowadays 3D
	scanners are also becoming a standard source for input data in many
	application areas, but image-based modelling still remains the most
	complete, economical, portable, flexible and widely used approach.
	In this paper the full pipeline is presented for 3D modelling from
	terrestrial image data, considering the different approaches and
	analysing all the steps involved.},
  keywords = {litsurvey.bib},
  publisher = {Wiley Online Library}
}

@ARTICLE{Remondino2006,
  author = {Remondino, Fabio and El-Hakim, Sabry},
  title = {{Image-based {3D} Modelling: A Review}},
  journal = {The Photogrammetric Record},
  year = {2006},
  volume = {21},
  pages = {269--291},
  number = {115},
  month = {\#aug\#},
  abstract = {Abstract In this paper the main problems and the available solutions
	are addressed for the generation of 3D models from terrestrial images.
	Close range photogrammetry has dealt for many years with manual or
	automatic image measurements for precise 3D modelling. Nowadays 3D
	scanners are also becoming a standard source for input data in many
	application areas, but image-based modelling still remains the most
	complete, economical, portable, flexible and widely used approach.
	In this paper the full pipeline is presented for 3D modelling from
	terrestrial image data, considering the different approaches and
	analysing all the steps involved.},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Rienks2010,
  author = {Rienks, Rutger and Poppe, Ronald and Heylen, Dirk},
  title = {Differences in head orientation behavior for speakers and listeners:
	An experiment in a virtual environment},
  month = {\#jan\#},
  year = {2010},
  keywords = {perception of gaze, virtual environments, gaze behavior, focus of
	attention, multiparty conversation, Head orientation;litsurvey.bib},
  number = {Article 2}
}

@ARTICLE{Risko2011,
  author = {Risko, Evan F and Kingstone, Alan},
  title = {Eyes wide shut: implied social presence, eye tracking and attention},
  journal = {Atten. Percept. Psychophys.},
  year = {2011},
  volume = {73},
  pages = {291--296},
  number = {2},
  month = {\#feb\#},
  abstract = {People often behave differently when they know they are being watched.
	Here, we report the first investigation of whether such social presence
	effects also influence looking behavior--a popular measure of attention
	allocation. We demonstrate that wearing an eye tracker, an implied
	social presence, leads individuals to avoid looking at particular
	stimuli. These results demonstrate that an implied social presence,
	here an eye tracker, can alter looking behavior. These data provide
	a new manipulation of social attention, as well as presenting a methodological
	challenge to researchers using eye tracking.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Springer}
}

@ARTICLE{Rittenbruch2015,
  author = {Rittenbruch, Markus},
  title = {Supporting Collaboration on Very {Large-Scale} Interactive Wall Surfaces},
  journal = {Comput. Support. Coop. Work},
  year = {2015},
  volume = {24},
  pages = {121--147},
  number = {2},
  month = {\#jun\#},
  abstract = {In this paper we describe CubIT, a multi-user presentation and collaboration
	system installed at the Queensland University of Technology's (QUT)
	Cube facility. The `Cube' is an interactive visualisation facility
	made up of five very large-scale interactive multi-panel wall displays,
	each consisting of up to twelve 55-inch multi-touch screens (48 screens
	in total) and massive projected display screens situated above the
	display panels. The paper outlines the unique design challenges,
	features, implementation and evaluation of CubIT. The system was
	built to make the Cube facility accessible to QUT's academic and
	student population. CubIT enables users to easily upload and share
	their own media content, and allows multiple users to simultaneously
	interact with the Cube's wall displays. The features of CubIT are
	implemented via three user interfaces, a multi-touch interface working
	on the wall displays, a mobile phone and tablet application and a
	web-based content management system. Each of these interfaces offers
	different interaction mechanisms. Together they support a wide range
	of collaborative features including multi-user shared workspaces,
	drag and drop upload and sharing between users, session management
	and dynamic state control between different parts of the system.
	The results of our evaluation study showed that CubIT was successfully
	used for a variety of tasks, but also highlighted specific challenges
	with regards to user expectations as well as issues arising from
	public use.},
  keywords = {litsurvey.bib},
  publisher = {Springer}
}

@Article{Rivera-Gutierrez2012,
  author   = {Rivera-Gutierrez, Diego and Welch, Greg and Lincoln, Peter and Whitton, Mary and Cendan, Juan and Chesnutt, David A and Fuchs, Henry and Lok, Benjamin},
  journal  = {Stud. Health Technol. Inform.},
  title    = {Shader Lamps Virtual Patients: the physical manifestation of virtual patients},
  year     = {2012},
  pages    = {372--378},
  volume   = {173},
  abstract = {We introduce the notion of Shader Lamps Virtual Patients (SLVP) -
	the combination of projector-based Shader Lamps Avatars and interactive
	virtual humans. This paradigm uses Shader Lamps Avatars technology
	to give a 3D physical presence to conversational virtual humans,
	improving their social interactivity and enabling them to share the
	physical space with the user. The paradigm scales naturally to multiple
	viewers, allowing for scenarios where an instructor and multiple
	students are involved in the training. We have developed a physical-virtual
	patient for medical students to conduct ophthalmic exams, in an interactive
	training experience. In this experience, the trainee practices multiple
	skills simultaneously, including using a surrogate optical instrument
	in front of a physical head, conversing with the patient about his
	fears, observing realistic head motion, and practicing patient safety.
	Here we present a prototype system and results from a preliminary
	formative evaluation of the system.},
  keywords = {Clinical Competence, Computer Simulation, Diagnostic Techniques, Ophthalmological, Humans, Imaging, Three-Dimensional, Patients, User-Computer Interface;litsurvey.bib},
  language = {en},
}

@ARTICLE{Roberts2009,
  author = {Roberts, David},
  title = {{Talking with the Furniture}},
  year = {2009},
  abstract = {Telethrone paper},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Roberts2005,
  author = {Roberts, D and Al-Liabi, M and Wolff, R and Otto, O and Al-Khalifah,
	A},
  title = {Reducing Fragmentation in Telecollaboration by Using {IPT} Interfaces},
  booktitle = {{IPT/EGVE}},
  year = {2005},
  pages = {211--216},
  institution = {Eurographics Association},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Roberts2009,
  author = {Roberts, D and Duckworth, T and Moore, C and Wolff, R and O'Hare,
	J},
  title = {Comparing the End to End Latency of an Immersive Collaborative Environment
	and a Video Conference},
  booktitle = {2009 13th {IEEE/ACM} International Symposium on Distributed Simulation
	and Real Time Applications},
  year = {2009},
  pages = {89--94},
  month = {\#oct\#},
  abstract = {Latency in a communication system can result in confusing a conversation
	through loss of causality as people exchange verbal and non-verbal
	nuances. This paper compares true end-to-end latencies across an
	immersive virtual environment and a video conference link using the
	same approach to measure both. Our approach is to measure end-to-end
	latency through filming the movements of a participant and their
	remote representation through synchronised cameras. We also compare
	contemporary and traditional immersive display and capture devices,
	whilst also measuring event latency taken from log files. We compare
	an immersive collaborative virtual environment to a video conference
	as both attempt to reproduce different aspects of the face-to- face
	meeting, the former favouring appearance and the latter attention.
	Results inform not only the designers of both approaches but also
	set the requirements for future developments for 3D video which has
	the potential to faithfully reproduce both appearance and attention.},
  institution = {IEEE Computer Society},
  keywords = {teleconferencing;video communication;virtual reality;end to end latency;immersive
	collaborative environment;video conference;immersive virtual environment;synchronised
	cameras;immersive display devices;capture devices;event latency;log
	files;face-to-face meeting;Delay;Collaboration;Videoconference;Virtual
	environment;Cameras;Virtual reality;Analytical models;Aerospace simulation;Computational
	modeling;Computer displays;David Roberts;Toby Duckworth;Carl Moore;Robin
	Wolff and John O'Hare;litsurvey.bib}
}

@INPROCEEDINGS{Roberts2009,
  author = {Roberts, D and Duckworth, T and Moore, C and Wolff, R and O'Hare,
	J},
  title = {Comparing the End to End Latency of an Immersive Collaborative Environment
	and a Video Conference},
  booktitle = {2009 13th {IEEE/ACM} International Symposium on Distributed Simulation
	and Real Time Applications},
  year = {2009},
  pages = {89--94},
  month = {\#oct\#},
  abstract = {Latency in a communication system can result in confusing a conversation
	through loss of causality as people exchange verbal and non-verbal
	nuances. This paper compares true end-to-end latencies across an
	immersive virtual environment and a video conference link using the
	same approach to measure both. Our approach is to measure end-to-end
	latency through filming the movements of a participant and their
	remote representation through synchronised cameras. We also compare
	contemporary and traditional immersive display and capture devices,
	whilst also measuring event latency taken from log files. We compare
	an immersive collaborative virtual environment to a video conference
	as both attempt to reproduce different aspects of the face-to- face
	meeting, the former favouring appearance and the latter attention.
	Results inform not only the designers of both approaches but also
	set the requirements for future developments for 3D video which has
	the potential to faithfully reproduce both appearance and attention.},
  keywords = {teleconferencing;video communication;virtual reality;end to end latency;immersive
	collaborative environment;video conference;immersive virtual environment;synchronised
	cameras;immersive display devices;capture devices;event latency;log
	files;face-to-face meeting;Delay;Collaboration;Videoconference;Virtual
	environment;Cameras;Virtual reality;Analytical models;Aerospace simulation;Computational
	modeling;Computer displays;David Roberts;Toby Duckworth;Carl Moore;Robin
	Wolff and John O'Hare;litsurvey.bib}
}

@ARTICLE{Roberts2003,
  author = {Roberts, David and Wolff, Robin and Otto, Oliver and Steed, Anthony},
  title = {Constructing a Gazebo: Supporting Teamwork in a Tightly Coupled,
	Distributed Task in Virtual Reality},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2003},
  volume = {12},
  pages = {644--657},
  number = {6},
  month = {\#dec\#},
  abstract = {Many tasks require teamwork. Team members may work concurrently, but
	there must be some occasions of coming together. Collaborative virtual
	environments (CVEs) allow distributed teams to come together across
	distance to share a task. Studies of CVE systems have tended to focus
	on the sense of presence or copresence with other people. They have
	avoided studying close interaction between us-ers, such as the shared
	manipulation of objects, because CVEs suffer from inherent network
	delays and often have cumbersome user interfaces. Little is known
	about the ef-fectiveness of collaboration in tasks requiring various
	forms of object sharing and, in particular, the concurrent manipu-lation
	of objects. This paper investigates the effectiveness of supporting
	teamwork among a geographically distributed group in a task that
	requires the shared manipulation of objects. To complete the task,
	users must share objects through con-current manipulation of both
	the same and distinct at-tributes. The effectiveness of teamwork
	is measured in terms of time taken to achieve each step, as well
	as the impression of users. The effect of interface is examined by
	comparing various combinations of walk-in cubic immersive projection
	technology (IPT) displays and desktop devices.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Roberts2009,
  author = {Roberts, D and Wolff, R and Rae, J and Steed, A and Aspin, R and
	McIntyre, M and Pena, A and Oyekoya, O and Steptoe, W},
  title = {Communicating Eye-gaze Across a Distance: Comparing an Eye-gaze enabled
	Immersive Collaborative Virtual Environment, Aligned Video Conferencing,
	and Being Together},
  booktitle = {2009 {IEEE} Virtual Reality Conference},
  year = {2009},
  pages = {135--142},
  month = {\#mar\#},
  abstract = {Eye gaze is an important and widely studied non-verbal resource in
	co-located social interaction. When we attempt to support tele-presence
	between people, there are two main technologies that can be used
	today: video-conferencing (VC) and collaborative virtual environments
	(CVEs). In VC, one can observe eye-gaze behaviour but practically
	the targets of eye-gaze are only correct if the participants remain
	relatively still. We attempt to support eye-gaze behaviour in an
	unconstrained manner by integrating eye-trackers into an Immersive
	CVE (ICVE) system. This paper aims to show that while both ICVE and
	VC allow people to discern being looked at and what else is looked
	at, when someone gazes into their space from another location, ICVE
	alone can continue to do this as people move. The conditions of aligned
	VC, ICVE, eye-gaze enabled ICVE and co-location are compared. The
	impact of factors of alignment, lighting, resolution, and perspective
	distortion are minimised through a set of pilot experiments, before
	a formal experiment records results for optimal settings. Results
	show that both VC and ICVE support eye-gaze in constrained situations,
	but only ICVE supports movement of the observer. We quantify the
	mis-judgements that are made and discuss how our findings might inform
	research into supporting eye-gaze through interpolated free viewpoint
	video based methods.},
  institution = {IEEE},
  keywords = {groupware;teleconferencing;video communication;virtual reality;eye-gaze
	enabled immersive collaborative virtual environment;video conferencing;nonverbal
	resource;colocated social interaction;telepresence;eye-trackers;Collaboration;Virtual
	environment;Videoconference;Virtual colonoscopy;Cameras;Avatars;Computer
	graphics;Displays;Video sharing;Head;Immersive Collaborative Virtual
	Environments;Eye-Tracking;Gaze-Tracking;Video Conferencing;Tele-presence;H.5.1
	[Communications Applications]: Computer conferencing, teleconferencing,
	and videoconferencing;I.3.7 [Computer Graphics]: Three-Dimensional
	Graphics and Realism: Virtual Reality;I.3.7 [Computer Graphics]:
	Three-Dimensional Graphics and Realism: Animation;litsurvey.bib}
}

@ARTICLE{Roberts2015,
  author = {Roberts, D J and Fairchild, A J and Campion, S P and O'Hare, J and
	Moore, C M and Aspin, R and Duckworth, T and Gasparello, P and Tecchia,
	F},
  title = {withyou---An Experimental {End-to-End} Telepresence System Using
	{Video-Based} Reconstruction},
  journal = {IEEE J. Sel. Top. Signal Process.},
  year = {2015},
  volume = {9},
  pages = {562--574},
  number = {3},
  month = {\#apr\#},
  abstract = {Supporting a wide set of linked non-verbal resources remains an evergreen
	challenge for communication technology, limiting effectiveness in
	many applications. Interpersonal distance, gaze, posture and facial
	expression, are interpreted together to manage and add meaning to
	most conversations. Yet today's technologies favor some above others.
	This induces confusion in conversations, and is believed to limit
	both feelings of togetherness and trust, and growth of empathy and
	rapport. Solving this problem will allow technologies to support
	most rather than a few interactional scenarios. It is likely to benefit
	teamwork and team cohesion, distributed decision-making and health
	and wellbeing applications such as tele-therapy, tele-consultation,
	and isolation. We introduce withyou, our telepresence research platform.
	This paper describes the end-to-end system including the psychology
	of human interaction and how this drives requirements throughout
	the design and implementation. Our technology approach is to combine
	the winning characteristics of video conferencing and immersive collaborative
	virtual environments. This is to allow, for example, people walking
	past each other to exchange a glance and smile. A systematic explanation
	of the theory brings together the linked nature of non-verbal communication
	and how it is influenced by technology. This leads to functional
	requirements for telepresence, in terms of the balance of visual,
	spatial and temporal qualities. The first end-to-end description
	of withyou describes all major processes and the display and capture
	environment. An unprecedented characterization of our approach is
	given in terms of the above qualities and what influences them. This
	leads to non-functional requirements in terms of number and place
	of cameras and the avoidance of resultant bottlenecks. Proposals
	are given for improved distribution of processes across networks,
	computers, and multi-core CPU and GPU. Simple conservative estimation
	shows that both approaches should meet our requirements. One is implemented
	and shown to meet minimum and come close to desirable requirements.},
  keywords = {groupware;teleconferencing;virtual reality;end-to-end telepresence
	system;video-based reconstruction;human interaction psychology;video
	conferencing;immersive collaborative virtual environments;nonverbal
	communication;functional requirements;temporal qualities;spatial
	qualities;visual qualities;resultant bottlenecks;withyou;Visualization;Avatars;Cameras;Three-dimensional
	displays;Context;Image reconstruction;Collaboration;Computer supported
	cooperative working;computer vision;virtual reality;litsurvey.bib},
  publisher = {IEEE}
}

@ARTICLE{Roberts2013,
  author = {Roberts, David J and Rae, John and Duckworth, Tobias W and Moore,
	Carl M and Aspin, Rob},
  title = {Estimating the gaze of a virtuality human},
  journal = {IEEE Trans. Vis. Comput. Graph.},
  year = {2013},
  volume = {19},
  pages = {681--690},
  number = {4},
  month = {\#apr\#},
  abstract = {The aim of our experiment is to determine if eye-gaze can be estimated
	from a virtuality human: to within the accuracies that underpin social
	interaction; and reliably across gaze poses and camera arrangements
	likely in every day settings. The scene is set by explaining why
	Immersive Virtuality Telepresence has the potential to meet the grand
	challenge of faithfully communicating both the appearance and the
	focus of attention of a remote human participant within a shared
	3D computer-supported context. Within the experiment n=22 participants
	rotated static 3D virtuality humans, reconstructed from surround
	images, until they felt most looked at. The dependent variable was
	absolute angular error, which was compared to that underpinning social
	gaze behaviour in the natural world. Independent variables were 1)
	relative orientations of eye, head and body of captured subject;
	and 2) subset of cameras used to texture the form. Analysis looked
	for statistical and practical significance and qualitative corroborating
	evidence. The analysed results tell us much about the importance
	and detail of the relationship between gaze pose, method of video
	based reconstruction, and camera arrangement. They tell us that virtuality
	can reproduce gaze to an accuracy useful in social interaction, but
	with the adopted method of Video Based Reconstruction, this is highly
	dependent on combination of gaze pose and camera arrangement. This
	suggests changes in the VBR approach in order to allow more flexible
	camera arrangements. The work is of interest to those wanting to
	support expressive meetings that are both socially and spatially
	situated, and particular those using or building Immersive Virtuality
	Telepresence to accomplish this. It is also of relevance to the use
	of virtuality humans in applications ranging from the study of human
	interactions to gaming and the crossing of the stage line in films
	and TV.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {IEEE}
}

@ARTICLE{Roberts2012,
  author = {Roberts, David J and Wolff, Robin and Otto, Oliver},
  title = {Supporting a Closely Coupled Task between a Distributed Team: Using
	Immersive Virtual Reality Technology},
  journal = {Comput. Inform.},
  year = {2012},
  volume = {24},
  pages = {7--29},
  number = {1},
  month = {\#mar\#},
  abstract = {Collaboration and teamwork is important in many areas of our lives.
	People come together to share and discuss ideas, split and distribute
	work or help and support each other. The sharing of information and
	artefacts is a central part of collaboration. This often involves
	the manipulation of shared objects, both sequentially as well as
	concurrently. For coordinating an efficient collaboration, communication
	between the team members is necessary. This can happen verbally in
	form of speech or text and non-verbally through gesturing, pointing,
	gaze or facial expressions and the referencing and manipulation of
	shared objects. Collaborative Virtual Environments (CVE) allow remote
	users to come together and interact with each other and virtual objects
	within a computer simulated environment. Immersive display interfaces,
	such as a walk-in display (e.g. CAVE), that place a human physically
	into the synthetic environment, lend themselves well to support a
	natural manipulation of objects as well a set of natural non-verbal
	human communication, as they can both capture and display human movement.
	Communication of tracking data, however, can saturate the network
	and result in delay or loss of messages vital to the manipulation
	of shared objects. This paper investigates the reality of shared
	object manipulation between remote users collaborating through linked
	walk-in displays and extends our research in [27]. Various forms
	of shared interaction are examined through a set of structured sub
	tasks within a representative construction task. We report on extensive
	user-trials between three walk-in displays in the UK and Austria
	linked over the Internet using a CVE, and demonstrate such effects
	on a naive implementation of a benchmark application, the Gazebo
	building task. We then present and evaluate application-level workarounds
	and conclude by suggesting solutions that may be implemented within
	next-generation CVE infrastructures.},
  keywords = {litsurvey.bib},
  language = {en}
}

@INPROCEEDINGS{Robinson2002,
  author = {Robinson, Nigel and Shapcott, Mary},
  title = {Data mining information visualisation-beyond charts and graphs},
  booktitle = {Proceedings Sixth International Conference on Information Visualisation},
  year = {2002},
  pages = {577--583},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/01028832.pdf:PDF}
}

@INPROCEEDINGS{Romano2001,
  author = {Romano, N C and Nunamaker, J F},
  title = {Meeting analysis: findings from research and practice},
  booktitle = {Proceedings of the 34th Annual Hawaii International Conference on
	System Sciences},
  year = {2001},
  pages = {13 pp.--},
  month = {\#jan\#},
  abstract = {Meeting analysis, that is the study of meeting expenses, productivity,
	processes, and outcomes, is relevant to GSS practice and research
	for several reasons. Many reviews and surveys reveal that meetings
	dominate workers' and managers' time and yet are considered to be
	costly, unproductive and dissatisfying. Studies show that meetings
	are essential and that the number of meetings and their duration
	has been steadily increasing. Studies of managers and knowledge workers
	reveal that they spend between 25\%-80\% of their time in meetings,
	suggesting that meetings are an important part of one's working life.
	Estimates of meeting expenses range from costs of $30 million to
	over 100 million per year to losses between $54 million and 3.7 billion
	annually! Self estimates of meeting productivity by managers in many
	different functional areas range from 33\%-47\%.},
  institution = {IEEE},
  keywords = {group decision support systems;meeting analysis;meeting expenses;productivity;GSS
	practice;knowledge workers;meeting productivity;group support systems;Productivity;Meeting
	planning;Teleworking;Business communication;Educational institutions;Information
	management;Knowledge management;Costs;Collaboration;Design methodology;litsurvey.bib}
}

@INPROCEEDINGS{Romano2001,
  author = {Romano, N C and Nunamaker, J F},
  title = {Meeting analysis: findings from research and practice},
  booktitle = {Proceedings of the 34th Annual Hawaii International Conference on
	System Sciences},
  year = {2001},
  pages = {13 pp.--},
  month = {\#jan\#},
  abstract = {Meeting analysis, that is the study of meeting expenses, productivity,
	processes, and outcomes, is relevant to GSS practice and research
	for several reasons. Many reviews and surveys reveal that meetings
	dominate workers' and managers' time and yet are considered to be
	costly, unproductive and dissatisfying. Studies show that meetings
	are essential and that the number of meetings and their duration
	has been steadily increasing. Studies of managers and knowledge workers
	reveal that they spend between 25\%-80\% of their time in meetings,
	suggesting that meetings are an important part of one's working life.
	Estimates of meeting expenses range from costs of $30 million to
	over 100 million per year to losses between $54 million and 3.7 billion
	annually! Self estimates of meeting productivity by managers in many
	different functional areas range from 33\%-47\%.},
  institution = {IEEE},
  keywords = {group decision support systems;meeting analysis;meeting expenses;productivity;GSS
	practice;knowledge workers;meeting productivity;group support systems;Productivity;Meeting
	planning;Teleworking;Business communication;Educational institutions;Information
	management;Knowledge management;Costs;Collaboration;Design methodology;litsurvey.bib}
}

@INPROCEEDINGS{Romano2001,
  author = {Romano, N C and Nunamaker, J F},
  title = {Meeting analysis: findings from research and practice},
  booktitle = {Proceedings of the 34th Annual Hawaii International Conference on
	System Sciences},
  year = {2001},
  pages = {13 pp.--},
  month = {\#jan\#},
  abstract = {Meeting analysis, that is the study of meeting expenses, productivity,
	processes, and outcomes, is relevant to GSS practice and research
	for several reasons. Many reviews and surveys reveal that meetings
	dominate workers' and managers' time and yet are considered to be
	costly, unproductive and dissatisfying. Studies show that meetings
	are essential and that the number of meetings and their duration
	has been steadily increasing. Studies of managers and knowledge workers
	reveal that they spend between 25\%-80\% of their time in meetings,
	suggesting that meetings are an important part of one's working life.
	Estimates of meeting expenses range from costs of $30 million to
	over 100 million per year to losses between $54 million and 3.7 billion
	annually! Self estimates of meeting productivity by managers in many
	different functional areas range from 33\%-47\%.},
  institution = {IEEE},
  keywords = {group decision support systems;meeting analysis;meeting expenses;productivity;GSS
	practice;knowledge workers;meeting productivity;group support systems;Productivity;Meeting
	planning;Teleworking;Business communication;Educational institutions;Information
	management;Knowledge management;Costs;Collaboration;Design methodology;litsurvey.bib}
}

@MISC{Rosenthal1947,
  author = {Rosenthal, Adolph H},
  title = {Two-way television communication unit},
  year = {1947},
  keywords = {litsurvey.bib},
  publisher = {Google Patents}
}

@Article{Rovira2009,
  author    = {Rovira, Aitor and Swapp, David and Spanlang, Bernhard and Slater, Mel},
  journal   = {Front. Behav. Neurosci.},
  title     = {{The Use of Virtual Reality in the Study of People's Responses to Violent Incidents}},
  year      = {2009},
  month     = {\#dec\#},
  number    = {December},
  pages     = {59},
  volume    = {3},
  abstract  = {This paper reviews experimental methods for the study of the responses
	of people to violence in digital media, and in particular considers
	the issues of internal validity and ecological validity or generalisability
	of results to events in the real world. Experimental methods typically
	involve a significant level of abstraction from reality, with participants
	required to carry out tasks that are far removed from violence in
	real life, and hence their ecological validity is questionable. On
	the other hand studies based on field data, while having ecological
	validity, cannot control multiple confounding variables that may
	have an impact on observed results, so that their internal validity
	is questionable. It is argued that immersive virtual reality may
	provide a unification of these two approaches. Since people tend
	to respond realistically to situations and events that occur in virtual
	reality, and since virtual reality simulations can be completely
	controlled for experimental purposes, studies of responses to violence
	within virtual reality are likely to have both ecological and internal
	validity. This depends on a property that we call 'plausibility'
	- including the fidelity of the depicted situation with prior knowledge
	and expectations. We illustrate this with data from a previously
	published experiment, a virtual reprise of Stanley Milgram's 1960s
	obedience experiment, and also with pilot data from a new study being
	developed that looks at bystander responses to violent incidents.},
  keywords  = {bystander, obedience, presence, stanley milgram, violence, virtual reality;litsurvey.bib},
  language  = {en},
  publisher = {Frontiers Research Foundation},
}

@INPROCEEDINGS{Rusinkiewicz2002,
  author = {Rusinkiewicz, Szymon and Hall-Holt, Olaf and Levoy, Marc},
  title = {{Real-time {3D} model acquisition}},
  booktitle = {Proceedings of the 29th annual conference on Computer graphics and
	interactive techniques - {SIGGRAPH} '02},
  year = {2002},
  pages = {438},
  address = {New York, New York, USA},
  publisher = {ACM Press},
  conference = {the 29th annual conference},
  keywords = {litsurvey.bib},
  location = {San Antonio, Texas}
}

@INPROCEEDINGS{Sadagic2001,
  author = {Sadagic, Amela and Towles, Herman and Holden, Loring and Daniilidis,
	Kostas and Zeleznik, Bob},
  title = {Tele-immersion portal: Towards an ultimate synthesis of computer
	graphics and computer vision systems},
  booktitle = {4th Annual International Workshop on Presence},
  year = {2001},
  pages = {21--23},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Sakamoto2007,
  author = {Sakamoto, Daisuke and Kanda, Takayuki and Ono, Tetsuo and Ishiguro,
	Hiroshi and Hagita, Norihiro},
  title = {Android as a telecommunication medium with a human-like presence},
  booktitle = {Proceedings of the {ACM/IEEE} international conference on Human-robot
	interaction},
  year = {2007},
  series = {HRI '07},
  pages = {193--200},
  address = {New York, NY, USA},
  month = {\#mar\#},
  publisher = {Association for Computing Machinery},
  institution = {IEEE},
  keywords = {android science, telepresence, telecommunication, humanoid robot;litsurvey.bib},
  location = {Arlington, Virginia, USA}
}

@Misc{salinCosts,
  author    = {Salin, Phil},
  title     = {Costs and Computers},
  year      = {1991},
  owner     = {its352},
  timestamp = {2021.12.02},
  url       = {http://cdn.oreillystatic.com/radar/r1/11-91.pdf},
}

@ARTICLE{sangster2015earliest,
  author = {Sangster, Alan},
  title = {The earliest known treatise on double entry bookkeeping by Marino
	de Raphaeli},
  journal = {Accounting Historians Journal},
  year = {2015},
  volume = {42},
  pages = {1--33},
  number = {2},
  publisher = {American Accounting Association}
}

@INPROCEEDINGS{Sassa2019,
  author = {Sassa, Hinako and Itoh, Takayuki and Toyoda, Mitsuo},
  title = {3D Visualization of Network Including Nodes with Labels},
  booktitle = {2019 23rd International Conference Information Visualisation (IV)},
  year = {2019},
  pages = {19--24},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08812066.pdf:PDF}
}

@ARTICLE{Sauer2016,
  author = {Sauer, Nils Christian and Kauffeld, Simone},
  title = {The Structure of Interaction at Meetings: A Social Network Analysis},
  journal = {Zeitschrift f{\"u}r Arbeits- und Organisationspsychologie A\&O},
  year = {2016},
  volume = {60},
  pages = {33--49},
  number = {1},
  month = {\#jan\#},
  abstract = {Abstract. Which factors contribute to effective meetings? The interaction
	among participants plays a key role. Interaction is a relational,
	interdependent process that constitutes social structure. Applying
	a network perspective to meeting interactions allows us to take account
	of the social structure. The aim of this study was to use social
	network analysis to distinguish functional and dysfunctional interaction
	structures and gain insight into the facilitation of meetings by
	analyzing antecedents and consequences of functional interaction
	structures. Data were based on a field study in which 51 regular
	meetings were videotaped and coded with act4teams. Analyses revealed
	that compared with dysfunctional networks, functional interaction
	is less centralized and has a positive effect on team performance.
	Social similarity has a crucial effect on functional interaction
	because participants significantly interact with others who are similar
	in personal initiative and self-efficacy. Our results provide important
	information about how to assist the interaction process and promote
	team success.},
  keywords = {litsurvey.bib},
  publisher = {Hogrefe Verlag}
}

@ARTICLE{Schegloff1998,
  author = {Schegloff, Emanuel A},
  title = {Body torque},
  journal = {Soc. Res.},
  year = {1998},
  pages = {535--596},
  keywords = {litsurvey.bib},
  publisher = {JSTOR}
}

@INPROCEEDINGS{Schiano2004,
  author = {Schiano, Diane J and Ehrlich, Sheryl M and Sheridan, Kyle},
  title = {Categorical imperative {NOT}: facial affect is perceived continuously},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2004},
  series = {CHI '04},
  pages = {49--56},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {nonverbal communication, affective computing, naturalistic computing,
	face, video compression, avatars, VMC, facial affect, affect, emotion,
	facial expression of emotion;litsurvey.bib},
  location = {Vienna, Austria}
}

@INPROCEEDINGS{Schrammel2007,
  author = {Schrammel, Johann and Geven, Arjan and Sefelin, Reinhard and Tscheligi,
	Manfred},
  title = {``Look!'': using the gaze direction of embodied agents},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {1187--1190},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {gaze direction, embodied agent, computer vision;litsurvey.bib},
  location = {San Jose, California, USA}
}

@ARTICLE{Schreer2001,
  author = {Schreer, Oliver and Brandenburg, Nicole and Askar, Serap and Kauff,
	Peter},
  title = {Hybrid recursive matching and segmentation-based postprocessing in
	real-time immersive video conferencing},
  journal = {Proceedings of VMV2001},
  year = {2001},
  pages = {383--390},
  abstract = {We present a novel, real-time disparity analysis frame work developed
	for immersive teleconferencing. This two-stage method computes a
	limited number of highly reliable disparities in the first step and
	then, filling the remaining holes based on segmentation …},
  keywords = {litsurvey.bib},
  publisher = {researchgate.net}
}

@INPROCEEDINGS{Schreer2008,
  author = {Schreer, O and Feldmann, I and Atzpadin, N and Eisert, P and Kauff,
	P and Belt, H J W},
  title = {{3D} presence - a system concept for multi-user and multi-party immersive
	{3D} video conferencing},
  booktitle = {{IET} 5th European Conference on Visual Media Production ({CVMP}
	2008)},
  year = {2008},
  pages = {10--10},
  publisher = {IEE},
  conference = {IET 5th European Conference on Visual Media Production (CVMP 2008)},
  keywords = {litsurvey.bib},
  location = {London, UK}
}

@INCOLLECTION{Schreer2005,
  author = {Schreer, Oliver and Tanger, Ralf and Eisert, Peter and Kauff, Peter
	and Kaspar, Bernhard and Englert, Roman},
  title = {{Real-Time} Avatar Animation Steered by Live Body Motion},
  booktitle = {Image Analysis and Processing -- {ICIAP} 2005},
  publisher = {Springer Berlin Heidelberg},
  year = {2005},
  editor = {Roli, Fabio and Vitulano, Sergio},
  volume = {3617},
  series = {Lecture Notes in Computer Science},
  pages = {147--154},
  address = {Berlin, Heidelberg},
  keywords = {litsurvey.bib}
}

@ARTICLE{Schroeder2001,
  author = {Schroeder, Ralph and Steed, Anthony and Axelsson, Ann-Sofie and Heldal,
	Ilona and Abelin, {\AA}sa and Widestr{\"o}m, Josef and Nilsson, Alexander
	and Slater, Mel},
  title = {Collaborating in networked immersive spaces: as good as being there
	together?},
  journal = {Comput. Graph.},
  year = {2001},
  volume = {25},
  pages = {781--788},
  number = {5},
  month = {\#oct\#},
  abstract = {In this paper we present the results of a trial in which two participants
	collaborated on a puzzle-solving task in networked virtual environments.
	The task was a Rubik's cube type puzzle, and this meant that the
	two participants had to interact with the space and with each other
	very intensively---and they did this successfully despite the limitation
	of the networked situation. We compare collaboration in networked
	immersive projection technology (IPT's) systems with previous results
	concerning collaboration in an IPT system linked with a desktop computer,
	and also with collaboration on the same task in the real world. Our
	findings show that the task performance in networked IPT's and in
	the real scenario are very similar to each other---whereas IPT-to-desktop
	performance is much poorer. Results about participants' experience
	of `presence', `co-presence' and collaboration shed further light
	on these findings.},
  keywords = {Virtual environments; Immersive projection technology systems; Collaboration;
	Presence; Co-presence;litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Schuemie2001,
  author = {Schuemie, M J and van der Straaten, P and Krijn, M and van der Mast,
	C A},
  title = {Research on presence in virtual reality: a survey},
  journal = {Cyberpsychol. Behav.},
  year = {2001},
  volume = {4},
  pages = {183--201},
  number = {2},
  month = {\#apr\#},
  abstract = {Virtual Reality (VR) is starting to be used in psychological therapy
	around the world. However, a thorough understanding of the reason
	why VR is effective and what effect it has on the human psyche is
	still missing. Most research on this subject is related to the concept
	of presence. This paper gives an up-to-date overview of research
	in this diverse field. It starts with the most prevailing definitions
	and theories on presence, most of which attribute special roles for
	the mental process of attention and for mental models of the virtual
	space. A review of the phenomena thought to be effected by presence
	shows that there is still a strong need for research on this subject
	because little conclusive evidence exists regarding the relationship
	between presence and phenoma such as emotional responses to virtual
	stimuli. An investigation shows there has been substantial research
	for developing methods for measuring presence and research regarding
	factors that contribute to presence. Knowledge of these contributing
	factors can play a vital role in development of new VR applications,
	but key knowledge elements in this area are still missing.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Mary Ann Liebert, Inc.}
}

@ARTICLE{Schwartzman1986,
  author = {Schwartzman, Helen B},
  title = {The meeting as a neglected social form in organizational studies},
  journal = {Research in Organizational Behavior},
  year = {1986},
  volume = {8},
  pages = {233--258},
  abstract = {Discusses the use of meetings and the available studies of meetings
	that have been conducted by anthropologists, psychologists, sociologists,
	political scientists, business administrators, and others. It is
	argued that researchers have made meetings a tool of analysis, when
	they should have been the topic of investigation. A framework for
	a theory of meetings is presented, which sees meetings as rituals,
	social metaphors, and homeostats as prerequisite to the study of
	meetings in organizations. (PsycINFO Database Record (c) 2016 APA,
	all rights reserved)},
  keywords = {litsurvey.bib},
  publisher = {JAI Press, Inc.}
}

@ARTICLE{Scott2012,
  author = {Scott, Cliff W and Shanock, Linda Rhoades and Rogelberg, Steven G},
  title = {Meetings at Work: Advancing the Theory and Practice of Meetings},
  journal = {Small Group Research},
  year = {2012},
  volume = {43},
  pages = {127--129},
  number = {2},
  month = {\#apr\#},
  abstract = {Although advances in communication technology were once expected to
	diminish the need for synchronous work meetings, meeting activity
	in organizations continues to rise. Regrettably, the time and energy
	employees spend in work meetings is not matched by the amount of
	direct attention group and organizational scholars have paid to meeting
	phenomena. This special issue of Small Group Research helps to address
	this gap by presenting empirical studies of work meetings that explore
	the theory and practice of work meetings.},
  keywords = {litsurvey.bib},
  publisher = {SAGE Publications Inc}
}

@INPROCEEDINGS{Sellen1992,
  author = {Sellen, Abigail and Buxton, Bill and Arnott, John},
  title = {{Using spatial cues to improve videoconferencing}},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1992},
  series = {CHI '92},
  pages = {651--652},
  address = {New York, NY, USA},
  month = {\#jun\#},
  publisher = {Association for Computing Machinery},
  keywords = {litsurvey.bib},
  location = {Monterey, California, USA}
}

@INPROCEEDINGS{Sellen1992,
  author = {Sellen, Abigail and Buxton, Bill and Arnott, John},
  title = {Using spatial cues to improve videoconferencing},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1992},
  series = {CHI '92},
  pages = {651--652},
  address = {New York, NY, USA},
  month = {\#jun\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {litsurvey.bib},
  location = {Monterey, California, USA}
}

@ARTICLE{Sellen1995,
  author = {Sellen, Abigail J},
  title = {Remote Conversations: The Effects of Mediating Talk With Technology},
  journal = {Human--Computer Interaction},
  year = {1995},
  volume = {10},
  pages = {401--444},
  number = {4},
  month = {\#dec\#},
  abstract = {Three different videoconferencing systems for supporting multiparty,
	remote conversations are described and evaluated experimentally.
	The three systems differed by how many participants were visible
	at once, their spatial arrangement, and control over who was seen.
	Conversations using these systems were compared to same-room (Experiment
	1) and audio-only (Experiment 2) conversations. Specialized speech-tracking
	equipment recorded the on-off patterns of speech that allowed objective
	measurement of structural aspects of the conversations, such as turn
	length, pauses, and interruptions. Questionnaires and interviews
	also documented participants' opinions and perceptions in the various
	settings. Contrary to expectation, systems in which visual cues such
	as selective gaze were absent produced no differences in turn-taking
	or in any other aspect of the structure of conversation. In fact,
	turn-taking was unaffected even when visual information was completely
	absent. Overall, only the same-room condition showed any significant
	differences from any other condition; people in the same room produced
	more interruptions and fewer formal handovers of the floor than in
	any of the technology-mediated conditions. In this respect, the audio-only
	and video systems examined in these studies were equivalent. However,
	analyses of participants' perceptions showed that participants felt
	that visual access in mediated conversations was both important and
	beneficial in conversation. Further, there were indications that
	the particular design of the different video systems did affect some
	aspects of conversational behavior, such as the ability to hold side
	and parallel conversations.},
  keywords = {litsurvey.bib},
  publisher = {Taylor \& Francis}
}

@ARTICLE{Sellen1995,
  author = {Sellen, Abigail J},
  title = {Remote Conversations: The Effects of Mediating Talk With Technology},
  journal = {Human--Computer Interaction},
  year = {1995},
  volume = {10},
  pages = {401--444},
  number = {4},
  month = {\#dec\#},
  abstract = {Three different videoconferencing systems for supporting multiparty,
	remote conversations are described and evaluated experimentally.
	The three systems differed by how many participants were visible
	at once, their spatial arrangement, and control over who was seen.
	Conversations using these systems were compared to same-room (Experiment
	1) and audio-only (Experiment 2) conversations. Specialized speech-tracking
	equipment recorded the on-off patterns of speech that allowed objective
	measurement of structural aspects of the conversations, such as turn
	length, pauses, and interruptions. Questionnaires and interviews
	also documented participants' opinions and perceptions in the various
	settings. Contrary to expectation, systems in which visual cues such
	as selective gaze were absent produced no differences in turn-taking
	or in any other aspect of the structure of conversation. In fact,
	turn-taking was unaffected even when visual information was completely
	absent. Overall, only the same-room condition showed any significant
	differences from any other condition; people in the same room produced
	more interruptions and fewer formal handovers of the floor than in
	any of the technology-mediated conditions. In this respect, the audio-only
	and video systems examined in these studies were equivalent. However,
	analyses of participants' perceptions showed that participants felt
	that visual access in mediated conversations was both important and
	beneficial in conversation. Further, there were indications that
	the particular design of the different video systems did affect some
	aspects of conversational behavior, such as the ability to hold side
	and parallel conversations.},
  keywords = {litsurvey.bib},
  publisher = {Taylor \& Francis}
}

@INPROCEEDINGS{Sellen1992,
  author = {Sellen, Abigail J},
  title = {Speech patterns in video-mediated conversations},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {1992},
  series = {CHI '92},
  pages = {49--59},
  address = {New York, NY, USA},
  month = {\#jun\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {videoconferencing, conversation patterns, CSCW;litsurvey.bib},
  location = {Monterey, California, USA}
}

@INPROCEEDINGS{Sellis1987,
  author = {Sellis, Timos K and Roussopoulos, Nick and Faloutsos, Christos},
  title = {{The {R+-Tree}: A Dynamic Index for {Multi-Dimensional} Objects}},
  booktitle = {Proceedings of the 13th International
	Conference on Very Large Data Bases ({VLDB} '87)},
  year = {1987},
  address = {Brighton},
  publisher = {Morgan Kaufmann Publishers Inc},
  keywords = {litsurvey.bib}
}

@ARTICLE{Sermon2016,
  author = {Sermon, Paul},
  title = {Over one hundred years of telepresence},
  year = {2016},
  keywords = {litsurvey.bib},
  publisher = {Plymouth University}
}

@ARTICLE{Sermon2000,
  author = {Sermon, Paul},
  title = {Telematic Dreaming},
  journal = {Leonardo},
  year = {2000},
  volume = {33},
  pages = {90--90},
  number = {2},
  month = {\#apr\#},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Sermon2013,
  author = {Sermon, Paul and Gould, Charlotte},
  title = {Occupy the screen},
  year = {2013},
  keywords = {litsurvey.bib}
}

@ARTICLE{Shahid2012,
  author = {Shahid, Suleman and Krahmer, Emiel and Swerts, Marc},
  title = {Video-mediated and co-present gameplay: Effects of mutual gaze on
	game experience, expressiveness and perceived social presence},
  journal = {Interact. Comput.},
  year = {2012},
  volume = {24},
  pages = {292--305},
  number = {4},
  month = {\#jul\#},
  abstract = {Abstract. We study how pairs of children interact socially and express
	their emotions while playing games in different communicative settings.
	In particular, w},
  keywords = {litsurvey.bib},
  publisher = {Oxford Academic}
}

@Book{Shaw2001,
  author    = {Shaw, Chris and Wang, Wenping},
  publisher = {A.C.M.},
  title     = {Proceedings of the [eighth Annual] {ACM} Symposium on Virtual Reality Software and Technology, {VRST} 2001, Banff, Alberta, Canada, 15-17.11.2001: Organized and Sponsored by {ACM} [et Al.]},
  year      = {2001},
  address   = {New York, New York, USA},
  keywords  = {augmented, diorama, immersive visualization, multiprojector display system, shader lamp, spatially-augmented reality, user, virtual environment, virtual reality, virtuality;litsurvey.bib},
  language  = {en},
  pages     = {93},
}

@INPROCEEDINGS{Shen2008,
  author = {Shen, Rui and Cheng, Irene and Basu, Anup},
  title = {Multi-camera calibration using a globe},
  booktitle = {8\textbackslashtextsuperscript{th} Workshop on Omnidirectional Vision,
	Camera Networks and Non-classical Cameras ({OMNIVIS} '08)},
  year = {2008},
  address = {Marseille},
  keywords = {litsurvey.bib}
}

@ARTICLE{Shlyakhter2001,
  author = {Shlyakhter, I and Rozenoer, M and Dorsey, J and Teller, S},
  title = {{Reconstruction of plausible {3D} tree models from instrumented photographs}},
  journal = {IEEE Comput. Graph. Appl.},
  year = {2001},
  volume = {21},
  pages = {53--61},
  number = {3},
  keywords = {litsurvey.bib}
}

@BOOK{Short1976,
  title = {The Social Psychology of Telecommunications},
  publisher = {Wiley},
  year = {1976},
  author = {Short, John and Williams, Ederyn and Christie, Bruce},
  month = {\#jan\#},
  keywords = {litsurvey.bib},
  language = {en}
}

@InProceedings{Sibert2000,
  author    = {Sibert, Linda E and Jacob, Robert J K},
  booktitle = {Proceedings of the {SIGCHI} conference on Human Factors in Computing Systems},
  title     = {{Evaluation of eye gaze interaction}},
  year      = {2000},
  address   = {New York, NY, USA},
  month     = {\#apr\#},
  pages     = {281--288},
  publisher = {Association for Computing Machinery},
  series    = {CHI '00},
  keywords  = {eye movements, eye tracking, interaction techniques, user interfaces;litsurvey.bib},
  location  = {The Hague, The Netherlands},
}

@ARTICLE{Sicat2018,
  author = {Sicat, Ronell and Li, Jiabao and Choi, JunYoung and Cordeil, Maxime
	and Jeong, Won-Ki and Bach, Benjamin and Pfister, Hanspeter},
  title = {Dxr: A toolkit for building immersive data visualizations},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {715--725},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440858.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Simanek_undated,
  author = {Simanek., Donald E},
  title = {The illusion of reality in stereoscopy},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Sinha2004,
  author = {Sinha, S N and Pollefeys, M},
  title = {Synchronization and calibration of camera networks from silhouettes},
  booktitle = {Proceedings of the 17th International Conference on Pattern Recognition,
	2004. {ICPR} 2004.},
  year = {2004},
  volume = {1},
  pages = {116--119 Vol.1},
  address = {Cambridge},
  month = {\#aug\#},
  abstract = {We propose an automatic approach to synchronize a network of uncalibrated
	and unsynchronized video cameras, and recover the complete calibration
	of all these cameras. In this paper, we extend recent work on computing
	the epipolar geometry from dynamic silhouettes, to deal with unsynchronized
	sequences and find the temporal offset between them. This is used
	to compute the fundamental matrices and the temporal offsets between
	many view-pairs in the network. Knowing the time-shifts between enough
	view-pairs allows us to robustly synchronize the whole network. The
	calibration of all the cameras is recovered from these fundamental
	matrices. The dynamic shape of the object can then be recovered using
	a visual-hull algorithm. Our method is especially useful for multi-camera
	shape-from-silhouette systems, as visual hulls can now be reconstructed
	without the need for a specific calibration session.},
  keywords = {image reconstruction;image sequences;video cameras;synchronisation;calibration;matrix
	algebra;video signal processing;camera network synchronization;camera
	network calibration;unsynchronized video cameras;uncalibrated video
	cameras;epipolar geometry;dynamic silhouettes;unsynchronized sequences;fundamental
	matrices;visual hull algorithm;multicamera shape;silhouette systems;temporal
	offsets;image reconstruction;Calibration;Cameras;Image reconstruction;Video
	sequences;Character generation;Computational geometry;Transmission
	line matrix methods;Robustness;Shape;Computer networks;litsurvey.bib}
}

@ARTICLE{Slater2004,
  author = {Slater, Mel},
  title = {How Colorful Was Your Day? Why Questionnaires Cannot Assess Presence
	in Virtual Environments},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2004},
  volume = {13},
  pages = {484--493},
  number = {4},
  month = {\#aug\#},
  abstract = {This paper argues that a scientific basis for ?presence? as it's usually
	understood in virtual environments research, can not be established
	on the basis of postexperience presence questionnaires alone. To
	illustrate the point, an arbitrary mental attribute called ?colorfulness
	of the experience? is conjured up, and a set of questions administered
	to 74 respondents with an online questionnaire. The results suggested
	that colorfulness of yesterday's experiences was associated with
	the extent to which a person accomplished their tasks, and also associated
	with yesterday being a ?good?, ?pleasant?, but not frustrating day.
	The meaning lessness of this analysis illustrates that the equivalent
	methodology used by presence researchers, may, similarly, bring into
	being the idea of presence in the minds of VE participants. However,
	it is argued that there can be no evidence on this methodological
	basis that presence played any role in their actual mental activity
	or behavior at the time of the experience. It is concluded that presence
	researchers must move away from heavy reliance on questionnaires
	in order to make any progress in this area.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Slater1999,
  author = {Slater, Mel},
  title = {Measuring Presence: A Response to the Witmer and Singer Presence
	Questionnaire},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {1999},
  volume = {8},
  pages = {560--565},
  number = {5},
  month = {\#oct\#},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Slater1999,
  author = {Slater, Mel},
  title = {Measuring Presence: A Response to the Witmer and Singer Presence
	Questionnaire},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {1999},
  volume = {8},
  pages = {560--565},
  number = {5},
  month = {\#oct\#},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Slater2000,
  author = {Slater, Mel and Sadagic, Amela and Usoh, Martin and Schroeder, Ralph},
  title = {{Small-Group} Behavior in a Virtual and Real Environment: A Comparative
	Study},
  year = {2000},
  volume = {9},
  pages = {37--51},
  publisher = {MIT Press},
  abstract = {This paper describes an experiment that compares behavior in small
	groups when its members carry out a task in a virtual environment
	(VE) and then continue the same task in a similar, real-world environment.
	The purpose of the experiment was not to examine task performance,
	but to compare various aspects of the social relations among the
	group members in the two environments. Ten groups of three people
	each, who had never met before, met first in a shared VE and carried
	out a task that required the identification and solution of puzzles
	that were presented on pieces of paper displayed around the walls
	of a room. The puzzle involved identifying that the same-numbered
	words across all the pieces of paper formed a riddle or saying. The
	group continued this task for fifteen minutes, and then stopped to
	answer a questionnaire. The group then reconvened in the real world
	and continued the same task. The experiment also required one of
	the group members to continually monitor a particular one of the
	others in order to examine whether social discomfort could be generated
	within a VE. In each group, there was one immersed person with a
	head-mounted display and head-tracking and two non-immersed people
	who experienced the environment on a workstation display. The results
	suggest that the immersed person tended to emerge as the leader in
	the virtual group, but not in the real meeting. Group accord tended
	to be higher in the real meeting than in the virtual meeting. Socially
	conditioned responses such as embarrassment could be generated in
	the virtual meeting, even though the individuals were presented to
	one another by very simple avatars. The study also found a positive
	relationship between presence of being in a place and copresence
	- the sense of being with the other people. Accord in the group increased
	with presence, the performance of the group, and the presence of
	women in the group. The study is seen as part of a much larger planned
	study, for which this experiment was used to begin to understand
	the issues involved in comparing real and virtual meetings. ABSTRACT
	FROM AUTHOR},
  keywords = {litsurvey.bib}
}

@ARTICLE{Slater2000,
  author = {Slater, Mel and Sadagic, Amela and Usoh, Martin and Schroeder, Ralph},
  title = {{Small-Group} Behavior in a Virtual and Real Environment: A Comparative
	Study},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2000},
  volume = {9},
  pages = {37--51},
  number = {1},
  month = {\#feb\#},
  abstract = {This paper describes an experiment that compares behavior in small
	groups when its members carry out a task in a virtual environment
	(VE) and then continue the same task in a similar, real-world environment.
	The purpose of the experiment was not to examine task performance,
	but to compare various aspects of the social relations among the
	group members in the two environments. Ten groups of three people
	each, who had never met before, met first in a shared VE and carried
	out a task that required the identification and solution of puzzles
	that were presented on pieces of paper displayed around the walls
	of a room. The puzzle involved identifying that the same-numbered
	words across all the pieces of paper formed a riddle or saying. The
	group continued this task for fifteen minutes, and then stopped to
	answer a questionnaire. The group then reconvened in the real world
	and continued the same task. The experiment also required one of
	the group members to continually monitor a particular one of the
	others in order to examine whether social discomfort could be generated
	within a VE. In each group, there was one immersed person with a
	head-mounted display and head-tracking and two non-immersed people
	who experienced the environment on a workstation display. The results
	suggest that the immersed person tended to emerge as the leader in
	the virtual group, but not in the real meeting. Group accord tended
	to be higher in the real meeting than in the virtual meeting. Socially
	conditioned responses such as embarrassment could be generated in
	the virtual meeting, even though the individuals were presented to
	one another by very simple avatars. The study also found a positive
	relationship between presence of being in a place and copresence?the
	sense of being with the other people. Accord in the group increased
	with presence, the performance of the group, and the presence of
	women in the group. The study is seen as part of a much larger planned
	study, for which this experiment was used to begin to understand
	the issues involved in comparing real and virtual meetings.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Slater1958,
  author = {Slater, Philip E},
  title = {Contrasting Correlates of Group Size},
  journal = {Sociometry},
  year = {1958},
  volume = {21},
  pages = {129--139},
  number = {2},
  keywords = {litsurvey.bib},
  publisher = {[American Sociological Association, Sage Publications, Inc.]}
}

@ARTICLE{Slessor2008,
  author = {Slessor, Gillian and Phillips, Louise H and Bull, Rebecca},
  title = {Age-related declines in basic social perception: evidence from tasks
	assessing eye-gaze processing},
  journal = {Psychol. Aging},
  year = {2008},
  volume = {23},
  pages = {812--822},
  number = {4},
  month = {\#dec\#},
  abstract = {Previous research has investigated age differences in complex social
	perception tasks such as theory of mind and emotion recognition,
	with predominant findings of age-related declines. The present study
	investigated whether there are also age-related changes in basic
	aspects of social perception. Individuals' ability both to detect
	subtle differences in eye-gaze direction (e.g., where someone is
	looking in the environment) and to subsequently use these gaze cues
	to engage in joint attention with others was assessed. Age-related
	declines were found in the detection of the most subtle differences
	in gaze aversion. The ability to engage in joint attention by following
	gaze cues also declined with age. These age differences were not
	solely attributable to age impairments in visual perception and visual
	attention. The potential role of age-related neural declines in social
	perception problems was considered, along with the implications that
	age deficits in these basic social skills may have for older adults'
	social perception.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {American Psychological Association}
}

@INCOLLECTION{Slovak2009,
  author = {Slov{\'a}k, Petr and Troubil, Pavel and Holub, Petr},
  title = {{GColl}: A Flexible Videoconferencing Environment for {Group-to-Group}
	Interaction},
  booktitle = {{Human-Computer} Interaction -- {INTERACT} 2009},
  publisher = {Springer Berlin Heidelberg},
  year = {2009},
  editor = {Gross, Tom and Gulliksen, Jan and Kotz{\'e}, Paula and Oestreicher,
	Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler,
	Marco},
  volume = {5727},
  series = {Lecture Notes in Computer Science},
  pages = {165--168},
  address = {Berlin, Heidelberg},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Smith1997,
  author = {Smith, Gareth and Mariani, John},
  title = {Using subjective views to enhance 3D applications},
  booktitle = {Proceedings of the ACM symposium on Virtual reality software and
	technology},
  year = {1997},
  pages = {139--146},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/p139-smith.pdf:PDF}
}

@ARTICLE{Snowdon1995,
  author = {Snowdon, Dave and Greenhalgh, Chris and Benford, Steve},
  title = {What you see is not what {I} see: Subjectivity in virtual environments},
  journal = {Framework for Immersive Virtual Environments (FIVE'95)},
  year = {1995},
  abstract = {This paper discusses the issue of subjectivity in collaborative virtual
	environments. First, we identify current uses of subjectivity in
	virtual reality systems. We then examine three existing and representative
	collaborative applications to identify potential benefits of subjectivity.
	A …},
  keywords = {litsurvey.bib},
  publisher = {researchgate.net}
}

@INPROCEEDINGS{Sodhi2013,
  author = {Sodhi, Rajinder S and Jones, Brett R and Forsyth, David and Bailey,
	Brian P and Maciocci, Giuliano},
  title = {{BeThere}: {3D} mobile collaboration with spatial input},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {179--188},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {depth sensors, around device interaction, collaboration, augmented
	reality;litsurvey.bib},
  location = {Paris, France}
}

@INPROCEEDINGS{Song_Zhang2004,
  author = {{Song Zhang} and {Peisen Huang}},
  title = {{{High-Resolution}, Real-time {3D} Shape Acquisition}},
  booktitle = {2004 Conference on Computer Vision and Pattern Recognition Workshop},
  year = {2004},
  pages = {28--28},
  address = {Washington},
  month = {\#jun\#},
  abstract = {In this paper we describe a high-resolution, real-time 3D shape acquisition
	system based on structured light techniques. This system uses a color
	pattern whose RGB channels are coded with either sinusoidal or trapezoidal
	fringe patterns. When projected by a modified DLP projector (color
	filters removed), this color pattern results in three grayscale patterns
	projected sequentially at a frequency of 240 Hz. A high-speed B/W
	CCD camera synchronized with the projector captures the three images,
	from which the 3D shape of the object is reconstructed. A color CCD
	camera is also used to capture images for texture mapping. The maximum
	3D shape acquisition speed is 120 Hz (532 $\times$ 500 pixels), which
	is high enough for capturing the 3D shapes of moving objects. Two
	coding methods, sinusoidal phase-shifting method and trapezoidal
	phase-shifting method, were tested and results with good accuracy
	were obtained. The trapezoidal phase-shifting algorithm also makes
	real-time 3D reconstruction possible.},
  institution = {State University of New York},
  keywords = {Shape;Stereo vision;Image reconstruction;Charge-coupled image sensors;Charge
	coupled devices;Real time systems;Cameras;Stereo image processing;Mechanical
	engineering;Filters;litsurvey.bib}
}

@ARTICLE{Song2019,
  author = {Song, Jimmy},
  title = {Programming Bitcoin: Learn How to Program Bitcoin from Scratch},
  year = {2019},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/Jimmy Song - Programming Bitcoin_ Learn How to Program Bitcoin from Scratch (2019, OReilly Media).pdf:PDF},
  publisher = {O'Reilly Media, Inc.}
}

@ARTICLE{Sonnenwald1995,
  author = {Sonnenwald, Diane H},
  title = {Contested collaboration: A descriptive model of intergroup communication
	in information system design},
  journal = {Inf. Process. Manag.},
  year = {1995},
  volume = {31},
  pages = {859--877},
  number = {6},
  month = {\#nov\#},
  abstract = {Many information system design situations today include users, designers,
	and developers who, with their own unique group and individual perspectives,
	need to interact so that they can come to a working understanding
	of how the information system being developed will coexist with and
	ideally support patterns of work activities, social groups, and personal
	beliefs. In these situations, design is fundamentally an interactive
	process that requires communication among users, designers, and developers.
	However, communication among these groups is often difficult although
	of paramount importance to design outcomes. Through a qualitative
	analysis of a house, expert system, and telecommunications network
	architecture and management system design situations, a descriptive
	model of design that characterizes communication among users, designers,
	and developers as they create an artifact was developed. The model
	describes design phases, roles, themes, and intergroup communication
	networks as they evolve throughout the design process and characterizes
	design as a process of ``contested collaboration''. It is a first
	step towards a predictive design model that suggests strategies which
	may help participants interact more effectively and ultimately improve
	the quality of design outcomes and the design process.},
  keywords = {litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Sorapure2019,
  author = {Sorapure, Madeleine},
  title = {Text, Image, Data, Interaction: Understanding Information Visualization},
  journal = {Computers and Composition},
  year = {2019},
  volume = {54},
  pages = {102519},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S875546151830032X-main.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{St_John2001,
  author = {St John, M and Cowen, M B and Smallman, H S and Oonk, H M},
  title = {The use of {2D} and {3D} displays for shape-understanding versus
	relative-position tasks},
  journal = {Hum. Factors},
  year = {2001},
  volume = {43},
  pages = {79--98},
  number = {1},
  abstract = {Research on when and how to use three-dimensional (3D) perspective
	views on flat screens for operational tasks such as air traffic control
	is complex. We propose a functional distinction between tasks: those
	that require shape understanding versus those that require precise
	judgments of relative position. The distortions inherent in 3D displays
	hamper judging relative positions, whereas the integration of dimensions
	in 3D displays facilitates shape understanding. We confirmed these
	hypotheses with two initial experiments involving simple block shapes.
	The shape-understanding tasks were identification or mental rotation.
	The relative-position tasks were locating shadows and determining
	directions and distances between objects. We then extended the results
	to four experiments involving complex natural terrain. We compare
	our distinction with the integral/separable task distinction of Haskel
	and Wickens (1993). Applications for this research include displays
	for air traffic control, geoplots for military command and control,
	and potentially, any display of 3D information.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {SAGE Publications}
}

@INPROCEEDINGS{Standaert2013,
  author = {Standaert, W and Muylle, S and Basu, A},
  title = {Assessing the effectiveness of telepresence for business meetings},
  booktitle = {2013 46th Hawaii International Conference on System Sciences},
  year = {2013},
  pages = {549--558},
  month = {\#jan\#},
  abstract = {Business meetings conducted using fully-immersive telepresence systems
	provide participants with the lifelike-experience of a face-to-face
	meeting and offer the cost- and time-saving advantages of computer-mediated
	communication. However, telepresence systems are still much more
	expensive than simpler computer-mediated meeting modes, which makes
	the choice of this technology for business meetings a non-trivial
	decision problem. In this study, drawing upon the literature on social
	presence, media richness, and media appropriateness that relate media
	choice to task characteristics and objectives, we identify 19 objectives
	for business meetings. We then present hypotheses on the effectiveness
	of various meeting modes for achieving these objectives, focusing
	on the social presence dimension of four meeting modes (audio-conferencing,
	video-conferencing, telepresence, and face-to-face). We test these
	hypotheses using survey data from a large company in which all the
	technologies are available on a relatively broad basis.},
  institution = {IEEE},
  keywords = {business communication;computer mediated communication;teleconferencing;virtual
	reality;business meetings;telepresence systems;lifelike-experience;face-to-face
	meeting;cost-saving advantages;time-saving advantages;computer-mediated
	communication;computer-mediated meeting modes;media richness;media
	appropriateness;task characteristics;social presence dimension;audio-conferencing;video-conferencing;Media;Electronic
	mail;Computer mediated communication;Companies;Meetings;Telepresence;Social
	presence;Media richness;Media appropriateness;Meeting modes;Meeting
	objectives;litsurvey.bib}
}

@ARTICLE{Starck2008,
  author = {Starck, Jonathan and Hilton, Adrian},
  title = {Model-based human shape reconstruction from multiple views},
  journal = {Comput. Vis. Image Underst.},
  year = {2008},
  volume = {111},
  pages = {179--194},
  number = {2},
  month = {\#aug\#},
  abstract = {Image-based modelling allows the reconstruction of highly realistic
	digital models from real-world objects. This paper presents a model-based
	approach to recover animated models of people from multiple view
	video images. Two contributions are made, a multiple resolution model-based
	framework is introduced that combines multiple visual cues in reconstruction.
	Second, a novel mesh parameterisation is presented to preserve the
	vertex parameterisation in the model for animation. A prior humanoid
	surface model is first decomposed into multiple levels of detail
	and represented as a hierarchical deformable model for image fitting.
	A novel mesh parameterisation is presented that allows propagation
	of deformation in the model hierarchy and regularisation of surface
	deformation to preserve vertex parameterisation and animation structure.
	The hierarchical model is then used to fuse multiple shape cues from
	silhouette, stereo and sparse feature data in a coarse-to-fine strategy
	to recover a model that reproduces the appearance in the images.
	The framework is compared to physics-based deformable surface fitting
	at a single resolution, demonstrating an improved reconstruction
	accuracy against ground-truth data with a reduced model distortion.
	Results demonstrate realistic modelling of real people with accurate
	shape and appearance while preserving model structure for use in
	animation.},
  keywords = {Image-based modelling; Deformable model; Multiple resolution mesh;
	Shape-from-silhouette; Stereo vision; Character animation;litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Starck2008,
  author = {Starck, Jonathan and Hilton, Adrian},
  title = {Model-based human shape reconstruction from multiple views},
  journal = {Comput. Vis. Image Underst.},
  year = {2008},
  volume = {111},
  pages = {179--194},
  number = {2},
  month = {\#aug\#},
  abstract = {Image-based modelling allows the reconstruction of highly realistic
	digital models from real-world objects. This paper presents a model-based
	approach to recover animated models of people from multiple view
	video images. Two contributions are made, a multiple resolution model-based
	framework is introduced that combines multiple visual cues in reconstruction.
	Second, a novel mesh parameterisation is presented to preserve the
	vertex parameterisation in the model for animation. A prior humanoid
	surface model is first decomposed into multiple levels of detail
	and represented as a hierarchical deformable model for image fitting.
	A novel mesh parameterisation is presented that allows propagation
	of deformation in the model hierarchy and regularisation of surface
	deformation to preserve vertex parameterisation and animation structure.
	The hierarchical model is then used to fuse multiple shape cues from
	silhouette, stereo and sparse feature data in a coarse-to-fine strategy
	to recover a model that reproduces the appearance in the images.
	The framework is compared to physics-based deformable surface fitting
	at a single resolution, demonstrating an improved reconstruction
	accuracy against ground-truth data with a reduced model distortion.
	Results demonstrate realistic modelling of real people with accurate
	shape and appearance while preserving model structure for use in
	animation.},
  keywords = {Image-based modelling; Deformable model; Multiple resolution mesh;
	Shape-from-silhouette; Stereo vision; Character animation;litsurvey.bib},
  publisher = {Elsevier}
}

@PHDTHESIS{Starck2003,
  author = {Starck, J R},
  title = {Human modelling from multiple views},
  school = {Citeseer},
  year = {2003},
  keywords = {litsurvey.bib}
}

@BOOK{Steinmeyer2013,
  title = {The Science Behind the Ghost!: A Brief History of Pepper's Ghost},
  publisher = {Hahne},
  year = {2013},
  author = {Steinmeyer, Jim},
  keywords = {litsurvey.bib}
}

@PHDTHESIS{Steptoe2010,
  author = {Steptoe, William Arthur Hugh},
  title = {Eye tracking and avatar-mediated communication in immersive collaborative
	virtual environments},
  school = {University College London (University of London)},
  year = {2010},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Steptoe2009,
  author = {Steptoe, W and Oyekoya, O and Murgia, A and Wolff, R and Rae, J and
	Guimaraes, E and Roberts, D and Steed, A},
  title = {Eye Tracking for Avatar Eye Gaze Control During {Object-Focused}
	Multiparty Interaction in Immersive Collaborative Virtual Environments},
  booktitle = {2009 {IEEE} Virtual Reality Conference},
  year = {2009},
  pages = {83--90},
  month = {\#mar\#},
  abstract = {In face-to-face collaboration, eye gaze is used both as a bidirectional
	signal to monitor and indicate focus of attention and action, as
	well as a resource to manage the interaction. In remote interaction
	supported by immersive collaborative virtual environments (ICVEs),
	embodied avatars representing and controlled by each participant
	share a virtual space. We report on a study designed to evaluate
	methods of avatar eye gaze control during an object-focused puzzle
	scenario performed between three networked CAVEtrade-like systems.
	We compare tracked gaze, in which avatars' eyes are controlled by
	head-mounted mobile eye trackers worn by participants, to a gaze
	model informed by head orientation for saccade generation, and static
	gaze featuring non-moving eyes. We analyse task performance, subjective
	user experience, and interactional behaviour. While not providing
	statistically significant benefit over static gaze, tracked gaze
	is observed as the highest performing condition. However, the gaze
	model resulted in significantly lower task performance and increased
	error rate.},
  institution = {IEEE},
  keywords = {avatars;groupware;human computer interaction;avatar eye gaze control;object-focused
	multiparty interaction;immersive collaborative virtual environment;face-to-face
	collaboration;remote interaction;puzzle scenario;head-mounted mobile
	eye tracking;saccade generation;Avatars;Collaboration;Virtual environment;Eyes;Remote
	monitoring;Resource management;Design methodology;Control systems;Performance
	evaluation;Performance analysis;Immersive Collaborative Virtual Environments;Eye
	Tracking;Avatars;Eye Gaze;Behavioural Realism;I.3.7 [Computer Graphics]:
	Three-Dimensional Graphics and Realism\?\`Virtual Reality;H.4.3 [Information
	Systems Applications]: Communications Applications\?\`Computer conferencing,
	teleconferencing, and videoconferencing;I.3.7 [Computer Graphics]:
	Three-Dimensional Graphics and Realism\?\`Animation;litsurvey.bib}
}

@InProceedings{Steptoe2010,
  author    = {Steptoe, William and Steed, Anthony and Rovira, Aitor and Rae, John},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
  title     = {Lie tracking: social presence, truth and deception in avatar-mediated telecommunication},
  year      = {2010},
  address   = {New York, NY, USA},
  month     = {\#apr\#},
  pages     = {1039--1048},
  publisher = {Association for Computing Machinery},
  series    = {CHI '10},
  abstract  = {The success of visual telecommunication systems depends on their ability
	to transmit and display users' natural nonverbal behavior. While
	video-mediated communication (VMC) is the most widely used form of
	interpersonal remote interaction, avatar-mediated communication (AMC)
	in shared virtual environments is increasingly common. This paper
	presents two experiments investigating eye tracking in AMC. The first
	experiment compares the degree of social presence experienced in
	AMC and VMC during truthful and deceptive discourse. Eye tracking
	data (gaze, blinking, and pupil size) demonstrates that oculesic
	behavior is similar in both mediation types, and uncovers systematic
	differences between truth telling and lying. Subjective measures
	show users' psychological arousal to be greater in VMC than AMC.
	The second experiment demonstrates that observers of AMC can more
	accurately detect truth and deception when viewing avatars with added
	oculesic behavior driven by eye tracking. We discuss implications
	for the design of future visual telecommunication media interfaces.},
  keywords  = {avatar video mediated communication, behavior, communication, cues, deception, design, eye tracking, information, social presence, trust, virtual environments; avatar-mediated communication; video-mediated communication;litsurvey.bib},
  location  = {Atlanta, Georgia, USA},
}

@INPROCEEDINGS{Steptoe2008,
  author = {Steptoe, William and Wolff, Robin and Murgia, Alessio and Guimaraes,
	Estefania and Rae, John and Sharkey, Paul and Roberts, David and
	Steed, Anthony},
  title = {{Eye-tracking for avatar eye-gaze and interactional analysis in immersive
	collaborative virtual environments}},
  booktitle = {Proceedings of the 2008 {ACM} conference on Computer supported cooperative
	work},
  year = {2008},
  series = {CSCW '08},
  pages = {197--200},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  keywords = {social presence, eye-tracking, eye-gaze, immersive collaborative virtual
	environments, telecommunication, avatars;litsurvey.bib},
  location = {San Diego, CA, USA}
}

@ARTICLE{Steuer2006,
  author = {Steuer, Jonathan},
  title = {{Defining virtual reality: Dimensions determining telepresence}},
  journal = {J. Commun.},
  year = {2006},
  pages = {1--25},
  keywords = {litsurvey.bib}
}

@ARTICLE{Steuer1992,
  author = {Steuer, Jonathan},
  title = {Defining Virtual Reality: Dimensions Determining Telepresence},
  journal = {J. Commun.},
  year = {1992},
  volume = {42},
  pages = {73--93},
  number = {4},
  month = {\#dec\#},
  abstract = {Jonathan Steuer; Defining Virtual Reality: Dimensions Determining
	Telepresence, Journal of Communication, Volume 42, Issue 4, 1 December
	1992, Pages 73--93, htt},
  keywords = {virtual reality;litsurvey.bib},
  publisher = {Oxford Academic}
}

@INPROCEEDINGS{Stiefelhagen2002,
  author = {Stiefelhagen, R},
  title = {Tracking focus of attention in meetings},
  booktitle = {Proceedings. Fourth {IEEE} International Conference on Multimodal
	Interfaces},
  year = {2002},
  pages = {273--280},
  month = {\#oct\#},
  abstract = {The author presents an overview of his work on tracking focus of attention
	in meeting situations. He has developed a system capable of estimating
	participants' focus of attention from multiple cues. In the system
	he employs an omni-directional camera to simultaneously track the
	faces of participants sitting around a meeting table and uses neural
	networks to estimate their head poses. In addition, he uses microphones
	to detect who is speaking. The system predicts participants' focus
	of attention from acoustic and visual information separately, and
	then combines the output of the audio- and video-based focus of attention
	predictors. In addition he reports recent experimental results: In
	order to determine how well we can predict a subject's focus of attention
	solely on the basis of his or her head orientation, he has conducted
	an experiment in which he recorded head and eye orientations of participants
	in a meeting using special tracking equipment. The results demonstrate
	that head orientation was a sufficient indicator of the subjects'
	focus target in 89\% of the time. Furthermore he discusses how the
	neural networks used to estimate head orientation can be adapted
	to work in new locations and under new illumination conditions.},
  institution = {IEEE},
  keywords = {tracking;image motion analysis;neural nets;speech recognition;lighting;user
	interfaces;focus of attention tracking;meetings;multiple cues;omni-directional
	camera;neural networks;head pose estimation;microphones;visual information;head
	orientation;illumination;acoustic information;attention predictors;video;audio;experimental
	results;Head;Face detection;Focusing;Cameras;Lighting;Competitive
	intelligence;Humans;Layout;Interactive systems;Laboratories;litsurvey.bib}
}

@INPROCEEDINGS{Stiefelhagen2001,
  author = {Stiefelhagen, Rainer and Yang, Jie and Waibel, Alex},
  title = {Estimating focus of attention based on gaze and sound},
  booktitle = {Proceedings of the 2001 workshop on Perceptive user interfaces},
  year = {2001},
  series = {PUI '01},
  pages = {1--9},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {intelligent environments, meeting analysis, focus of attention, gaze
	tracking;litsurvey.bib},
  location = {Orlando, Florida, USA}
}

@INPROCEEDINGS{Stiefelhagen2002,
  author = {Stiefelhagen, Rainer and Zhu, Jie},
  title = {Head orientation and gaze direction in meetings},
  booktitle = {{CHI} '02 Extended Abstracts on Human Factors in Computing Systems},
  year = {2002},
  series = {CHI EA '02},
  pages = {858--859},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  keywords = {attention-based interfaces, gaze tracking, head pose;litsurvey.bib},
  location = {Minneapolis, Minnesota, USA}
}

@ARTICLE{Stockman1988,
  author = {Stockman, G C and -. Chen, S and Hu, G and Shrikhande, N},
  title = {{Sensing and recognition of rigid objects using structured light}},
  journal = {IEEE Control Syst. Mag.},
  year = {1988},
  volume = {8},
  pages = {14--22},
  number = {3},
  month = {\#jun\#},
  abstract = {Word directed toward the development of a vision system for bin picking
	of rigid 3D objects is reported. Any such system must have components
	for sensing, feature extraction, modeling, and matching. A structured
	light system which attempts to deliver a rich 2/sup 1///sub 2/D representation
	of the scene is described. Surface patches are evident as connected
	sets of stripes whose 3D coordinates are computed by means of triangulation
	and constraint propagation. Object edges are detected by the intersection
	of surface patches or by backprojecting image edges to intersect
	with the patches. Two matching paradigms are given for drawing correspondence
	between structures in the scene representation and structures in
	models. Three major contributions are reported: a method for sensing
	object surface patches without having to solve uniquely for stripe
	labels; the use of both an intensity image and a striped image, allowing
	scenes to be represented by detected edges along with 3D surface
	patches; and a pose-clustering algorithm, a uniform technique to
	accumulate matching evidence for recognition while averaging out
	substantial errors of pose.},
  keywords = {computer vision;computerised pattern recognition;computer vision;edge
	detection;object recognition;feature matching;pose errors;rigid objects;structured
	light;bin picking;feature extraction;triangulation;constraint propagation;surface
	patches;backprojecting;matching paradigms;intensity image;striped
	image;pose-clustering algorithm;Layout;Image edge detection;Machine
	vision;Feature extraction;Object detection;Clustering algorithms;Robot
	sensing systems;Robot kinematics;Data mining;Computer vision;litsurvey.bib}
}

@INPROCEEDINGS{Strait2014,
  author = {Strait, M and Scheutz, M},
  title = {Measuring users' responses to humans, robots, and human-like robots
	with functional near infrared spectroscopy},
  booktitle = {The 23rd {IEEE} International Symposium on Robot and Human Interactive
	Communication},
  year = {2014},
  pages = {1128--1133},
  month = {\#aug\#},
  abstract = {The Uncanny Valley Hypothesis (UVH) describes the sudden change in
	a person's affect from affinity to aversion that is evoked by robots
	that border a human-like appearance. The portion of the human-likeness
	spectrum in which such aversion is posited to occur is referred to
	as the ``uncanny valley''. However, evidence in support of the UVH
	is primarily based on subjectively assessed evaluations. Thus it
	remains an open question as to whether there are behavioral or neurophysiological
	manifestations of uncanny valley effects. To address this gap in
	literature, we investigated the activation of the anterior prefrontal
	cortex (PFC) - a region of the brain associated with emotion regulation
	- in response to a series of robots with varying human-likeness.
	We hypothesized that highly human-like robots - which have been found
	to receive negative subjective attributions - will also elicit increased
	activity in the PFC versus humans or robots with lesser degrees of
	human-likeness in accordance with the UVH. Our results show a ``valley''
	in brain activity in the PFC corresponding to the valley observed
	via subjective measures alone, thus suggesting one neural manifestation
	(the PFC) of uncanny valley effects and further supporting the affective
	response (aversion) posited to occur by the UVH. However, the results
	also reveal a second ``uncanny valley'' in prefrontal hemodynamics,
	which suggests that the effects (and the contributing factors) are
	more complex than previously understood.},
  institution = {IEEE},
  keywords = {humanoid robots;infrared spectroscopy;prefrontal hemodynamics;affective
	response;neural manifestation;brain activity;PFC versus humans;emotion
	regulation;anterior prefrontal cortex;uncanny valley effects;neurophysiological
	manifestations;human-likeness spectrum;human-like appearance;UVH;uncanny
	valley hypothesis;functional near infrared spectroscopy;human-like
	robots;user responses;Robots;Hemodynamics;Atmospheric measurements;Particle
	measurements;Spectroscopy;Visualization;Face;litsurvey.bib}
}

@INPROCEEDINGS{Sugimoto2004,
  author = {Sugimoto, Masanori and Hosoi, Kazuhiro and Hashizume, Hiromichi},
  title = {Caretta: a system for supporting face-to-face collaboration by integrating
	personal and shared spaces},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2004},
  series = {CHI '04},
  pages = {41--48},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {PDA, face-to-face collaboration, personal and shared spaces, sensing
	board;litsurvey.bib},
  location = {Vienna, Austria}
}

@ARTICLE{Sullivan1998,
  author = {Sullivan, S and Ponce, J},
  title = {{Automatic Model Construction, Pose Estimation, and Object Recognition
	from Photographs Using Triangular Splines}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {1998},
  volume = {20},
  pages = {1091--1096},
  keywords = {litsurvey.bib}
}

@ARTICLE{Sundaram2000,
  author = {Sundaram, D S and Webster, Cynthia},
  title = {The role of nonverbal communication in service encounters},
  journal = {J. Prof. Serv. Mark.},
  year = {2000},
  volume = {14},
  pages = {378--391},
  number = {5},
  month = {\#jan\#},
  abstract = {Although the verbal components of service encounters have been investigated,
	the nonverbal aspects of employee ?customer interactions have remained
	virtually unexplored in the marketing literature. Thus, the purpose
	of this paper is to explore the importance of service employees'
	nonverbal communication during service interactions. Specifically,
	a conceptual model is presented that links nonverbal communication
	(kinesics, paralanguage, proxemics, and physical appearance), customer
	affect, and consumers' evaluations of service providers (with respect
	to credibility, friendliness, competence, empathy, courtesy, and
	trustworthiness). Further, the importance of nonverbal elements is
	discussed and managerial implications are given.},
  keywords = {litsurvey.bib},
  publisher = {MCB UP Ltd}
}

@ARTICLE{Surman2015,
  author = {Surman, Phil and Day, Sally and Liu, Xianzi and Benjamin, Joshua
	and Urey, Hakan and Aksit, Kaan},
  title = {Head tracked retroreflecting {3D} display},
  journal = {Jnl Soc Info Display},
  year = {2015},
  volume = {23},
  pages = {56--68},
  number = {2},
  month = {\#feb\#},
  abstract = {Abstract In this paper, we describe a single-user glasses-free (autostereoscopic)
	3D display where images from a pair of picoprojectors are projected
	on to a retroreflecting screen. Real images of the projector lenses
	formed at the viewer's eyes produce exit pupils that follow the eye
	positions by the projectors moving laterally under the control of
	a head tracker. This provides the viewer with a comfortable degree
	of head movement. The retroreflecting screen, display hardware, infrared
	head tracker, and means of stabilizing the image position on the
	screen are explained. The performance of the display in terms of
	crosstalk, resolution, image distortion, and other parameters is
	described. Finally, applications of this display type are suggested.},
  keywords = {autostereoscopic, retroreflector, picoprojector, exit pupils, head
	tracking, infrared;litsurvey.bib}
}

@ARTICLE{Suzuki2012,
  author = {Suzuki, Keisuke and Wakisaka, Sohei and Fujii, Naotaka},
  title = {Substitutional reality system: a novel experimental platform for
	experiencing alternative reality},
  journal = {Sci. Rep.},
  year = {2012},
  volume = {2},
  pages = {459},
  month = {\#jun\#},
  abstract = {We have developed a novel experimental platform, referred to as a
	substitutional reality (SR) system, for studying the conviction of
	the perception of live reality and related metacognitive functions.
	The SR system was designed to manipulate people's reality by allowing
	them to experience live scenes (in which they were physically present)
	and recorded scenes (which were recorded and edited in advance) in
	an alternating manner without noticing a reality gap. All of the
	na{\"\i}ve participants (n = 21) successfully believed that they
	had experienced live scenes when recorded scenes had been presented.
	Additional psychophysical experiments suggest the depth of visual
	objects does not affect the perceptual discriminability between scenes,
	and the scene switch during head movement enhance substitutional
	performance. The SR system, with its reality manipulation, is a novel
	and affordable method for studying metacognitive functions and psychiatric
	disorders.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Nature Publishing Group}
}

@BOOK{swammycrypto,
  title = {Crypto Uncovered},
  publisher = {Springer},
  author = {Swammy, Sarah and Thompson, Richard and Loh, Marvin},
  file = {:../../../literature_repository/bitcoin/Sarah_Swammy,_Richard_Thompson,.pdf:PDF}
}

@InProceedings{Symons2004,
  author   = {Symons, Lawrence A and Lee, Kang and Cedrone, Caroline C and Nishimura, Mayu},
  title    = {What are you looking at? Acuity for triadic eye gaze},
  year     = {2004},
  pages    = {451--469},
  volume   = {131},
  abstract = {The authors measured observers' ability to determine direction of
	gaze toward an object in space. In Experiment 1, they determined
	the difference threshold for determining whether a live ``looker''
	was looking to the left or right of a target point. Acuity for eye
	direction was quite high (approximately 30 s arc). Viewing the movement
	of the looker's eyes did not improve acuity. When one of the looker's
	eyes was occluded, the observers' acuity was disrupted and their
	point of subjective equality was shifted away from the exposed eye.
	Experiment 2 was a replication of Experiment 1, but digitized gaze
	displays were used. The results of Experiment 3 showed that the acuity
	for direction of gaze depended on the position of the looker's target.
	Overall, the results indicated that humans are highly sensitive to
	gaze direction and that information from both eyes is used to determine
	direction of regard.},
  keywords = {Adult, Eye Movements, Female, Humans, Interpersonal Relations, Visual Acuity, Visual Perception;litsurvey.bib},
}

@ARTICLE{Systems_undated-ps,
  author = {Systems, Cisco},
  title = {Here's Looking at You: Eye Contact and Gaze Perspectivein the Two
	Dimensional World of {TelePresence}},
  keywords = {litsurvey.bib}
}

@ARTICLE{szabo1997formalizing,
  author = {Szabo, Nick},
  title = {Formalizing and securing relationships on public networks},
  journal = {First monday},
  year = {1997}
}

@ARTICLE{Szeliski1993,
  author = {Szeliski, R},
  title = {Rapid Octree Construction from Image Sequences},
  journal = {Comput. Vis. Image Underst.},
  year = {1993},
  volume = {58},
  pages = {23--32},
  number = {1},
  month = {\#jul\#},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Tachi2003,
  author = {Tachi, Susumu},
  title = {Telexistence and retro-reflective projection technology ({RPT})},
  booktitle = {Proceedings of the 5th Virtual Reality International Conference ({VRIC2003})
	pp},
  year = {2003},
  volume = {69},
  pages = {1--69},
  keywords = {litsurvey.bib}
}

@ARTICLE{Tachi2004,
  author = {Tachi, Susumu and Kawakami, Naoki and Inami, Masahiko and Zaitsu,
	Yoshitaka},
  title = {{MUTUAL} {TELEXISTENCE} {SYSTEM} {USING} {RETRO-REFLECTIVE} {PROJECTION}
	{TECHNOLOGY}},
  journal = {Int. J. Humanoid Rob.},
  year = {2004},
  volume = {01},
  pages = {45--64},
  number = {01},
  month = {\#mar\#},
  abstract = {Telexistence is fundamentally a concept named for the technology that
	enables a human being to have a real-time sensation of being at a
	place other than where he or she actually is, and to interact with
	the remote environment, which may be real, virtual, or a combination
	of both. It also refers to an advanced type of teleoperation system
	that enables an operator at the controls to perform remote tasks
	dexterously with the feeling of existing in a surrogate robot. Although
	conventional telexistence systems provide an operator the real-time
	sensation of being in a remote environment, persons in the remote
	environment have only the sensation that a surrogate robot is present,
	not the operator. Mutual telexistence aims to solve this problem
	so that the existence of the operator is apparent to persons in the
	remote environment by providing mutual sensations of presence. This
	paper proposes a method of mutual telexistence using projection technology
	with retro-reflective objects, and describes experimental hardware
	constructed to demonstrate the feasibility of the proposed method.},
  keywords = {litsurvey.bib},
  publisher = {World Scientific Publishing Co.}
}

@INPROCEEDINGS{Tang2010,
  author = {Tang, Anthony and Pahud, Michel and Inkpen, Kori and Benko, Hrvoje
	and Tang, John C and Buxton, Bill},
  title = {Three's company: understanding communication channels in three-way
	distributed collaboration},
  booktitle = {Proceedings of the 2010 {ACM} conference on Computer supported cooperative
	work},
  year = {2010},
  series = {CSCW '10},
  pages = {271--280},
  address = {New York, NY, USA},
  month = {\#feb\#},
  publisher = {Association for Computing Machinery},
  conference = {the 2010 ACM conference},
  institution = {ACM},
  keywords = {tabletop, media space, video-mediated communication, shared workspace;litsurvey.bib},
  location = {Savannah, Georgia, USA}
}

@INPROCEEDINGS{Tang2006,
  author = {Tang, Anthony and Tory, Melanie and Po, Barry and Neumann, Petra
	and Carpendale, Sheelagh},
  title = {Collaborative coupling over tabletop displays},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2006},
  series = {CHI '06},
  pages = {1181--1190},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {mixed focus collaboration, coordination, collaborative coupling, collaborative
	tabletop displays, single display groupware;litsurvey.bib},
  location = {Montr{\'e}al, Qu{\'e}bec, Canada}
}

@INPROCEEDINGS{Tang2013,
  author = {Tang, John C and Xiao, Robert and Hoff, Aaron and Venolia, Gina and
	Therien, Patrick and Roseway, Asta},
  title = {{HomeProxy}: exploring a physical proxy for video communication in
	the home},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {1339--1342},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {asynchronous video, home, physical proxies, video chat;litsurvey.bib},
  location = {Paris, France}
}

@ARTICLE{Tay2008,
  author = {Tay, Sava{\c s} and Blanche, P-A and Voorakaranam, R and Tun{\c c},
	A V and Lin, W and Rokutanda, S and Gu, T and Flores, D and Wang,
	P and Li, G and St Hilaire, P and Thomas, J and Norwood, R A and
	Yamamoto, M and Peyghambarian, N},
  title = {An updatable holographic three-dimensional display},
  journal = {Nature},
  year = {2008},
  volume = {451},
  pages = {694--698},
  number = {7179},
  month = {\#feb\#},
  abstract = {Holographic three-dimensional (3D) displays provide realistic images
	without the need for special eyewear, making them valuable tools
	for applications that require situational awareness, such as medical,
	industrial and military imaging. Currently commercially available
	holographic 3D displays use photopolymers that lack image-updating
	capability, resulting in restricted use and high cost. Photorefractive
	polymers are dynamic holographic recording materials that allow updating
	of images and have a wide range of applications, including optical
	correlation, imaging through scattering media and optical communication.
	To be suitable for 3D displays, photorefractive polymers need to
	have nearly 100\% diffraction efficiency, fast writing time, hours
	of image persistence, rapid erasure, and large area-a combination
	of properties that has not been shown before. Here, we report an
	updatable holographic 3D display based on photorefractive polymers
	with such properties, capable of recording and displaying new images
	every few minutes. This is the largest photorefractive 3D display
	to date (4 x 4 inches in size); it can be recorded within a few minutes,
	viewed for several hours without the need for refreshing, and can
	be completely erased and updated with new images when desired.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Nature Publishing Group}
}

@INPROCEEDINGS{Teixeira2013,
  author = {Teixeira, Lucas and Raposo, Alberto B and Gattass, Marcelo},
  title = {Indoor localization using {SLAM} in parallel with a natural marker
	detector},
  booktitle = {Proceedings of the 28th Annual {ACM} Symposium on Applied Computing},
  year = {2013},
  series = {SAC '13},
  pages = {27--33},
  address = {New York, NY, USA},
  month = {\#mar\#},
  publisher = {Association for Computing Machinery},
  keywords = {picking, SLAM, indoor localization, tracking, computer vision;litsurvey.bib},
  location = {Coimbra, Portugal}
}

@Book{Terveen2003,
  author    = {Terveen, Loren},
  publisher = {Association for Computing Machinery},
  title     = {Conference Proceedings: Conference on Human Factors in Computing Systems : Changing the World, Changing Ourselves},
  year      = {2003},
  keywords  = {attentive user interfaces, conferencing, eye contact, eye tracking, gaze, multiparty video;litsurvey.bib},
  language  = {en},
  pages     = {521--528},
}

@BOOK{Ting-Toomey2012,
  title = {Understanding intercultural communication},
  publisher = {Oxford University Press New York, NY},
  year = {2012},
  author = {Ting-Toomey, Stella and Chung, Leeva C},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Tory2004,
  author = {Tory, Melanie and Moller, Torsten and Atkins, M Stella and Kirkpatrick,
	Arthur E},
  title = {Combining {2D} and {3D} views for orientation and relative position
	tasks},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2004},
  series = {CHI '04},
  pages = {73--80},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {empirical study, display design, orientation and relative position
	tasks, 2D and 3D visualization, experiment;litsurvey.bib},
  location = {Vienna, Austria}
}

@INPROCEEDINGS{Towles2003,
  author = {Towles, Herman and Kum, Sang-Uok and Sparks, Travis and Sinha, Sudipta
	and Larsen, Scott and Beddes, Nathan},
  title = {Transport and rendering challenges of multi-stream {3D} tele-immersion
	data},
  booktitle = {{NSF} Lake Tahoe Workshop on Collaborative Virtual Reality and Visualization},
  year = {2003},
  pages = {1--6},
  address = {Lake Tahoe},
  keywords = {litsurvey.bib}
}

@UNPUBLISHED{Trends_undated,
  author = {Trends, Google},
  title = {Google Trends for Projection Mapping},
  keywords = {litsurvey.bib}
}

@ARTICLE{Troje1998,
  author = {Troje, N F and Siebeck, U},
  title = {Illumination-induced apparent shift in orientation of human heads},
  journal = {Perception},
  year = {1998},
  volume = {27},
  pages = {671--680},
  number = {6},
  abstract = {Changing the position of a light source illuminating a human face
	induces an apparent shift of the perceived orientation of that face.
	The direction of this apparent shift is opposite to the shift of
	the light source. We demonstrated the illumination-induced apparent
	orientation shift (IAOS), quantified it in terms of the physical
	orientation shift needed to compensate for it, and evaluated the
	results in the context of possible mechanisms underlying orientation
	judgment. Results indicate that IAOS depends not only on the angle
	between the two light source positions, but also on the mean orientation
	of the face. Availability of cues coded in the visual texture of
	the face did not affect IAOS. The most effective cue was the location
	of the visible outline of the face. IAOS seems to be due to a shift
	of this outline when shadowed areas on the face merge with the black
	background. We conclude that an important mechanism for orientation
	judgment is based on a comparison of visible parts left and right
	of the profile line.},
  keywords = {litsurvey.bib},
  language = {en},
  publisher = {Sage Publications}
}

@ARTICLE{Tsai1987,
  author = {Tsai, R},
  title = {A versatile camera calibration technique for high-accuracy {3D} machine
	vision metrology using off-the-shelf {TV} cameras and lenses},
  journal = {IEEE Journal on Robotics and Automation},
  year = {1987},
  volume = {3},
  pages = {323--344},
  number = {4},
  month = {\#aug\#},
  abstract = {A new technique for three-dimensional (3D) camera calibration for
	machine vision metrology using off-the-shelf TV cameras and lenses
	is described. The two-stage technique is aimed at efficient computation
	of camera external position and orientation relative to object reference
	coordinate system as well as the effective focal length, radial lens
	distortion, and image scanning parameters. The two-stage technique
	has advantage in terms of accuracy, speed, and versatility over existing
	state of the art. A critical review of the state of the art is given
	in the beginning. A theoretical framework is established, supported
	by comprehensive proof in five appendixes, and may pave the way for
	future research on 3D robotics vision. Test results using real data
	are described. Both accuracy and speed are reported. The experimental
	results are analyzed and compared with theoretical prediction. Recent
	effort indicates that with slight modification, the two-stage calibration
	can be done in real time.},
  keywords = {Calibration;Machine vision;Measurement;Cameras;Calibration;Machine
	vision;Metrology;TV;Lenses;Robot vision systems;Robotic assembly;Robot
	kinematics;Application software;litsurvey.bib},
  publisher = {IEEE}
}

@INPROCEEDINGS{Tse2007,
  author = {Tse, Edward and Shen, Chia and Greenberg, Saul and Forlines, Clifton},
  title = {How pairs interact over a multimodal digital table},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {215--218},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {digital tables, speech, gestures, multimodal interaction;litsurvey.bib},
  location = {San Jose, California, USA}
}

@INPROCEEDINGS{Tsui2012,
  author = {Tsui, Katherine M and Desai, Munjal and Yanco, Holly A},
  title = {Towards measuring the quality of interaction: communication through
	telepresence robots},
  booktitle = {Proceedings of the Workshop on Performance Metrics for Intelligent
	Systems},
  year = {2012},
  series = {PerMIS '12},
  pages = {101--108},
  address = {New York, NY, USA},
  month = {\#mar\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {human-computer interaction, embodied video-mediated communication,
	human-robot interaction;litsurvey.bib},
  location = {College Park, Maryland}
}

@INPROCEEDINGS{Tsui2011,
  author = {Tsui, Katherine M and Desai, Munjal and Yanco, Holly A and Uhlik,
	Chris},
  title = {Exploring use cases for telepresence robots},
  booktitle = {Proceedings of the 6th international conference on Human-robot interaction},
  year = {2011},
  series = {HRI '11},
  pages = {11--18},
  address = {New York, NY, USA},
  month = {\#mar\#},
  publisher = {Association for Computing Machinery},
  institution = {IEEE},
  keywords = {video conferencing, teleoperation, remote presence;litsurvey.bib},
  location = {Lausanne, Switzerland}
}

@INPROCEEDINGS{Tsui2011,
  author = {Tsui, Katherine M and Desai, Munjal and Yanco, Holly A and Uhlik,
	Chris},
  title = {Exploring use cases for telepresence robots},
  booktitle = {Proceedings of the 6th international conference on Human-robot interaction},
  year = {2011},
  series = {HRI '11},
  pages = {11--18},
  address = {New York, NY, USA},
  month = {\#mar\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {video conferencing, teleoperation, remote presence;litsurvey.bib},
  location = {Lausanne, Switzerland}
}

@INPROCEEDINGS{Tuddenham2009,
  author = {Tuddenham, Philip and Robinson, Peter},
  title = {Territorial coordination and workspace awareness in remote tabletop
	collaboration},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2009},
  series = {CHI '09},
  pages = {2139--2148},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {fluidity, coupling, territoriality, remote tabletop interfaces;litsurvey.bib},
  location = {Boston, MA, USA}
}

@INPROCEEDINGS{Uddin2014,
  author = {Uddin, Muhammad Fahim and Gupta, Navarun and others},
  title = {Seven V's of Big Data understanding Big Data to extract value},
  booktitle = {Proceedings of the 2014 zone 1 conference of the American Society
	for Engineering Education},
  year = {2014},
  pages = {1--5},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Seven V___s of Big Data_Understanding Big Data.pdf:PDF}
}

@ARTICLE{UNstats_undated,
  author = {{UNstats}},
  title = {Deputy {UN} chief calls for urgent action to tackle global sanitation
	crisis},
  keywords = {litsurvey.bib}
}

@MISC{Usoh2000,
  author = {Usoh, Martin and Catena, Ernest and Arman, Sima and Slater, Mel},
  title = {{Using Presence Questionnaires in Reality. (Usoh et al, 2000).pdf}},
  year = {2000},
  abstract = {A between-group experiment was carried out to assess whether two different
	presence questionnaires can distinguish between real and virtual
	experiences. One group of ten subjects searched for a box in a real
	office environment. A second group of ten subjects carried out the
	same task in a virtual environment that simulated the same office.
	Immediately after their experience, subjects were given two different
	presence questionnaires in randomized order: the Witmer and Singer
	Presence (WS), and the questionnaire developed by Slater, Usoh, and
	Steed (SUS). The paper argues that questionnaires should be able
	to pass a ``reality test,'' whereby under current conditions the
	presence scores should be higher for real experiences than for virtual
	ones. Nevertheless, only the SUS had a marginally higher mean score
	for the real compared to the virtual, and there was no significant
	difference at all between the WS mean scores. It is concluded that,
	although such questionnaires may be useful when all subjects experience
	the same type of environment, their utility is doubtful for the comparison
	of experiences across environments, such as immersive virtual compared
	to real, or desktop compared to immersive virtual. ABSTRACT FROM
	AUTHOR Copyright of Presence: Teleoperators \& Virtual Environments
	is the property of MIT Press and its content may not be copied or
	emailed to multiple sites or posted to a listserv without the copyright
	holder's express written permission. However, users may print, download,
	or email articles for individual use. This abstract may be abridged.
	No warranty is given about the accuracy of the copy. Users should
	refer to the original published version of the material for the full
	abstract. (Copyright applies to all Abstracts)},
  booktitle = {Presence Teleoperators Virtual Environments},
  keywords = {litsurvey.bib},
  number = {5},
  pages = {497--503},
  publisher = {MIT Press},
  volume = {9}
}

@ARTICLE{Usoh2000,
  author = {Usoh, Martin and Catena, Ernest and Arman, Sima and Slater, Mel},
  title = {Using Presence Questionnaires in Reality},
  journal = {Presence: Teleoperators and Virtual Environments},
  year = {2000},
  volume = {9},
  pages = {497--503},
  number = {5},
  month = {\#oct\#},
  abstract = {A between-group experiment was carried out to assess whether two different
	presence questionnaires can distinguish between real and virtual
	experiences. One group of ten subjects searched for a box in a real
	office environment. A second group of ten subjects carried out the
	same task in a virtual environment that simulated the same office.
	Immediately after their experience, subjects were given two different
	presence questionnaires in randomized order: the Witmer and Singer
	Presence (WS), and the questionnaire developed by Slater, Usoh, and
	Steed (SUS). The paper argues that questionnaires should be able
	to pass a ?reality test? whereby under current conditions the presence
	scores should be higher for real experiences than for virtual ones.
	Nevertheless, only the SUS had a marginally higher mean score for
	the real compared to the virtual, and there was no significant difference
	at all between the WS mean scores. It is concluded that, although
	such questionnaires may be useful when all subjects experience the
	same type of environment, their utility is doubtful for the comparison
	of experiences across environments, such as immersive virtual compared
	to real, or desktop compared to immersive virtual.},
  keywords = {litsurvey.bib},
  publisher = {MIT Press}
}

@ARTICLE{Vadera2010,
  author = {Vadera, Sunil},
  title = {CSNL: A cost-sensitive non-linear decision tree algorithm},
  journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
  year = {2010},
  volume = {4},
  pages = {6},
  number = {2},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/clustering/1754428.1754429.pdf:PDF},
  publisher = {ACM}
}

@BOOK{Van_Baren2004,
  title = {Measuring presence: A guide to current measurement approaches},
  year = {2004},
  author = {Van Baren, Joy and IJsselsteijn, Wijnand},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Van_den_Bergh2009,
  author = {Van den Bergh, Michael and Halatsch, Jan and Kunze, Antje and Bosch{\'e},
	Fr{\'e}d{\'e}ric},
  title = {A novel camera-based system for collaborative interaction with multi-dimensional
	data models},
  booktitle = {{CONVR} Conference Proceedings, University of Sydney},
  year = {2009},
  pages = {19--28},
  keywords = {litsurvey.bib}
}

@Misc{cypherPunkMailList,
  author    = {Various},
  title     = {Cypher Punks Mailing List Archives},
  year      = {1990},
  owner     = {its352},
  timestamp = {2021.12.02},
  url       = {https://mailing-list-archive.cryptoanarchy.wiki},
}

@BOOK{Various2002,
  title = {Distributed Work},
  publisher = {MIT Press},
  year = {2002},
  editor = {Pamela J Hinds, Sara Kiesler},
  author = {{Various}},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Venolia2010,
  author = {Venolia, Gina and Tang, John and Cervantes, Ruy and Bly, Sara and
	Robertson, George and Lee, Bongshin and Inkpen, Kori},
  title = {Embodied social proxy: mediating interpersonal connection in hub-and-satellite
	teams},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2010},
  series = {CHI '10},
  pages = {1049--1058},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {distributed collaboration, telepresence, embodied video conferencing,
	empirical study;litsurvey.bib},
  location = {Atlanta, Georgia, USA}
}

@InProceedings{Vertegaal1999,
  author    = {Vertegaal, Roel},
  booktitle = {Proceedings of the {SIGCHI} conference on Human Factors in Computing Systems},
  title     = {The {GAZE} groupware system: mediating joint attention in multiparty communication and collaboration},
  year      = {1999},
  address   = {New York, NY, USA},
  month     = {\#may\#},
  pages     = {294--301},
  publisher = {Association for Computing Machinery},
  series    = {CHI '99},
  keywords  = {cscw, multiparty; VRML 2; attention; gaze direction; awareness; multiparty videoconferencing; eyetracking;litsurvey.bib},
  location  = {Pittsburgh, Pennsylvania, USA},
}

@INPROCEEDINGS{Vertegaal1999,
  author = {Vertegaal, Roel},
  title = {{The {GAZE} groupware system: mediating joint attention in multiparty
	communication and collaboration}},
  booktitle = {Proceedings of the {SIGCHI} conference on Human Factors in Computing
	Systems},
  year = {1999},
  series = {CHI '99},
  pages = {294--301},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  keywords = {gaze direction, eyetracking, VRML 2, awareness, CSCW, attention, multiparty
	videoconferencing;litsurvey.bib},
  location = {Pittsburgh, Pennsylvania, USA}
}

@INPROCEEDINGS{Vertegaal1997,
  author = {Vertegaal, Roel},
  title = {Catching the eye: management of joint attention in cooperative work},
  year = {1997},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Vertegaal2002,
  author = {Vertegaal, Roel and Ding, Yaping},
  title = {Explaining effects of eye gaze on mediated group conversations: amount
	or synchronization?},
  booktitle = {Proceedings of the 2002 {ACM} conference on Computer supported cooperative
	work},
  year = {2002},
  series = {CSCW '02},
  pages = {41--48},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  institution = {IEEE},
  keywords = {gaze, eye tracking, avatars, attentive interfaces, agents, multiparty
	mediated communication;litsurvey.bib},
  location = {New Orleans, Louisiana, USA}
}

@InProceedings{Vertegaal2002,
  author    = {Vertegaal, Roel and Ding, Yaping},
  booktitle = {Proceedings of the 2002 {ACM} conference on Computer supported cooperative work},
  title     = {Explaining effects of eye gaze on mediated group conversations: amount or synchronization?},
  year      = {2002},
  address   = {New York, NY, USA},
  month     = {\#nov\#},
  pages     = {41--48},
  publisher = {Association for Computing Machinery},
  series    = {CSCW '02},
  keywords  = {agents, attentive interfaces, avatars, communication, eye tracking, gaze, multiparty mediated; multiparty mediated communication;litsurvey.bib},
  location  = {New Orleans, Louisiana, USA},
}

@InProceedings{Vertegaal2001,
  author    = {Vertegaal, Roel and Slagter, Robert and van der Veer, Gerrit and Nijholt, Anton},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
  title     = {Eye gaze patterns in conversations: there is more to conversational agents than meets the eyes},
  year      = {2001},
  address   = {New York, NY, USA},
  month     = {\#mar\#},
  pages     = {301--308},
  publisher = {Association for Computing Machinery},
  series    = {CHI '01},
  keywords  = {attention-based interfaces, attentive agents, communication, conversational attention, eye tracking, gaze, multiparty; multiparty communication; tracking;litsurvey.bib},
  location  = {Seattle, Washington, USA},
}

@INPROCEEDINGS{Vertegaal2000,
  author = {Vertegaal, Roel and Van der Veer, Gerrit and Vons, Harro},
  title = {Effects of gaze on multiparty mediated communication},
  booktitle = {Graphics interface},
  year = {2000},
  pages = {95--102},
  publisher = {Morgan Kaufmann},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Vetere2005,
  author = {Vetere, Frank and Gibbs, Martin R and Kjeldskov, Jesper and Howard,
	Steve and Mueller, Florian 'floyd' and Pedell, Sonja and Mecoles,
	Karen and Bunyan, Marcus},
  title = {Mediating intimacy: designing technologies to support strong-tie
	relationships},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2005},
  series = {CHI '05},
  pages = {471--480},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {intimacy, intimate technology, participatory design, tactile interfaces,
	cultural probes, ethnography;litsurvey.bib},
  location = {Portland, Oregon, USA}
}

@INPROCEEDINGS{Vidal2019,
  author = {Vidal, Maria-Esther and Jozashoori, Samaneh},
  title = {Semantic Data Integration Techniques for Transforming Big Biomedical
	Data into Actionable Knowledge},
  booktitle = {2019 IEEE 32nd International Symposium on Computer-Based Medical
	Systems (CBMS)},
  year = {2019},
  pages = {563--566},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08787394.pdf:PDF}
}

@BOOK{Vigna2016,
  title = {The age of cryptocurrency: how bitcoin and the blockchain are challenging
	the global economic order},
  publisher = {Macmillan},
  year = {2016},
  author = {Vigna, Paul and Casey, Michael J},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/The Age of Cryptocurrency _ How - Michael J. Casey.pdf:PDF}
}

@BOOK{Vince1995,
  title = {{Virtual reality systems}},
  publisher = {Pearson Education India},
  year = {1995},
  author = {Vince, John},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Vishwanath2005,
  author = {Vishwanath, Dhanraj and Girshick, Ahna R and Banks, Martin S},
  title = {Why pictures look right when viewed from the wrong place},
  year = {2005},
  volume = {8},
  pages = {1401--1410},
  publisher = {Nature Publishing Group},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Voida2012,
  author = {Voida, Amy and Bos, Nathan and Olson, Judith and Olson, Gary and
	Dunning, Lauren},
  title = {Cross-cutting faultlines of location and shared identity in the intergroup
	cooperation of partially distributed groups},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {3101--3110},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {shared identity, faultline, partially distributed work, intergroup
	cooperation;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@MISC{w3cSemantic,
  author = {W3C},
  title = {Semantic Web Standard pages},
  year = {2015},
  owner = {its352},
  timestamp = {2021.12.02},
  url = {https://www.w3.org/standards/semanticweb/@MISC{w3cSemantic, author = {W3C}, title = {Semantic Web Standard pages}, year = {2015}, owner = {its352}, timestamp = {2021.12.02}, url = {https://www.w3.org/standards/semanticweb/} }}
}

@INPROCEEDINGS{Wada2000,
  author = {Wada, T and {Xiaojun Wu} and Tokai, S and Matsuyama, T},
  title = {Homography based parallel volume intersection: toward real-time volume
	reconstruction using active cameras},
  booktitle = {Proceedings Fifth {IEEE} International Workshop on Computer Architectures
	for Machine Perception},
  year = {2000},
  pages = {331--339},
  address = {Padova},
  month = {\#sep\#},
  abstract = {Silhouette volume intersection is one of the most popular ideas for
	reconstructing the 3D volume of an object from multi-viewpoint silhouette
	images. This paper presents a novel parallel volume intersection
	method based on plane-to-plane homography for real-time 3D volume
	reconstruction using active cameras. This paper mainly focuses on
	the acceleration of back-projection from silhouette images to 3D
	space without using any sophisticated software technique, such as
	octree volume representation, or look-up table based projection acceleration.
	Also this paper presents a parallel intersection method of projected
	silhouette images. From the preliminary experimental results we estimate
	near frame-rate volume reconstruction for a life-sized mannequin
	can be achieved at 3 cm spatial resolution on our PC cluster system.},
  keywords = {image reconstruction;real-time volume reconstruction;active cameras;parallel
	volume intersection;back-projection;silhouette images;octree volume
	representation;projection acceleration;projected silhouette images;frame-rate
	volume reconstruction;Cameras;Image reconstruction;Optical sensors;Spatial
	resolution;Biomedical optical imaging;Magnetic field measurement;Shape
	measurement;Acceleration;Humans;Magnetic sensors;litsurvey.bib}
}

@INPROCEEDINGS{Waizenegger2011,
  author = {Waizenegger, W and Atzpadin, N and Schreer, O and Feldmann, I},
  title = {Patch-sweeping with robust prior for high precision depth estimation
	in real-time systems},
  booktitle = {2011 18th {IEEE} International Conference on Image Processing},
  year = {2011},
  pages = {881--884},
  month = {\#sep\#},
  abstract = {This paper presents a novel real-time approach for robust high precision
	and high quality depth estimation. It extends recent work on real-time
	Patch-Sweeping by combining the advantages of a robust hybrid stereo-based
	disparity estimator with the high accuracy of the Patch-Sweeping
	approach. It over- comes limitations of the existing Patch-Sweep
	approach, such as limited search range. Further, it implicitly benefits
	from the high robustness as well as time consistency of the disparity
	estimator. The presented overall algorithmic system concept introduces
	a powerful alternative to traditional real-time depth estimation
	approaches. Additionally, the proposed algorithmic structures allow
	a high degree of parallelization. Based on this, the computational
	effort could be efficiently balanced between GPU and CPU processing.
	The target platform of the proposed algorithmic chain is a real-time
	immersive 3D video communication system which requires highly accurate
	3D estimation results for a high quality virtual eye contact generation.},
  institution = {IEEE},
  keywords = {estimation theory;graphics processing units;multiprocessing systems;real-time
	systems;solid modelling;stereo image processing;video communication;robust
	high precision;robust high quality depth estimation;real-time patch
	sweeping approach;robust hybrid stereo-based disparity estimator;search
	range;time consistency;overall algorithmic system;high parallelization
	degree;GPU processing;CPU processing;real-time immersive 3D video
	communication system;high quality virtual eye contact generation;3D
	estimation;Three dimensional displays;Real time systems;Streaming
	media;Estimation;Robustness;Cameras;Conferences;Patch sweeping;HRM;Depth
	estimation;3D Video Communication;Real-time;GPGPU;Cuda;litsurvey.bib}
}

@ARTICLE{Walther2002,
  author = {Walther, Joseph B and Parks, Malcolm R},
  title = {Cues filtered out, cues filtered in},
  journal = {Handbook of interpersonal communication},
  year = {2002},
  volume = {3},
  pages = {529--563},
  abstract = {Iii---``August 1998, news of the results of a dy soon to be published
	in the American Psychologist sent shock waves through the Internet
	community and, to no small extent, through public discourse about
	the social impact of the Internet. Robert Kraut and his colleagues
	(1998) had found that Internet use in a sample of 93 families had
	resulted in small but significant increases in loneliness, social
	isolation, and depression over a 2-year period. The researchers asserted
	that the},
  keywords = {litsurvey.bib},
  publisher = {researchgate.net}
}

@INCOLLECTION{Walther2002,
  author = {Walther, J B and Parks, M R and Knapp, I M L and Daly, J A},
  title = {{Cues filtered out, cues filtered in: Computer-mediated communication
	and relationships}},
  booktitle = {Handbook of Interpersonal Communication},
  publisher = {Sage Publications},
  year = {2002},
  editor = {Knapp, Mark L and Daly, John A},
  volume = {3\textbackslashtextsuperscriptrd},
  pages = {529--563},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Wang2014,
  author = {Wang, Fei and Yuan, Bo},
  title = {Parallel frequent pattern mining without candidate generation on
	GPUs},
  booktitle = {2014 IEEE International Conference on Data Mining Workshop},
  year = {2014},
  pages = {1046--1052},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/GPU - accelerated/07022712.pdf:PDF}
}

@ARTICLE{Wang2018,
  author = {Wang, Yichuan and Kung, LeeAnn and Byrd, Terry Anthony},
  title = {Big data analytics: Understanding its capabilities and potential
	benefits for healthcare organizations},
  journal = {Technological Forecasting and Social Change},
  year = {2018},
  volume = {126},
  pages = {3--13},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0040162516000500-main.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Watanabe2017,
  author = {Watanabe, Ayaka and Itoh, Takayuki and Chiba, Kazuhisa and Kanazaki,
	Masahiro},
  title = {A Scatterplots Selection Technique for Multi-Dimensional Data Visualization
	Combining with Parallel Coordinate Plots},
  booktitle = {2017 21st International Conference Information Visualisation (IV)},
  year = {2017},
  pages = {78--83},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08107951.pdf:PDF}
}

@ARTICLE{Watson1966,
  author = {Watson, O Michael and Graves, Theodore D},
  title = {{Quantitative Research in Proxemic Behavior}},
  journal = {Am. Anthropol.},
  year = {1966},
  volume = {68},
  pages = {971--985},
  number = {4},
  month = {\#aug\#},
  abstract = {Proxemics is the study of how man structures microspace, how he relates
	physically to other persons with whom he is interacting, and what
	is communicated by these physical relationships. Edward Hall, who
	coined the term ?proxemics? and devised a system of notation for
	recording proxemic behavior, reports many impressionistic observations
	on Arab and American proxemic differences. To test these hypotheses
	systematically, 32 Arab and American college students were observed
	under controlled conditions and their proxemic behavior recorded.
	The Arabs and Americans were found to differ significantly in proxemic
	behavior, the Arabs interacting with each other closer and more directly
	than Americans, as hypothesized.},
  keywords = {litsurvey.bib}
}

@INCOLLECTION{Weissig2012,
  author = {Weissig, Christian and Schreer, Oliver and Eisert, Peter and Kauff,
	Peter},
  title = {The Ultimate Immersive Experience: Panoramic {3D} Video Acquisition},
  booktitle = {Advances in Multimedia Modeling},
  publisher = {Springer Berlin Heidelberg},
  year = {2012},
  editor = {Schoeffmann, Klaus and Merialdo, Bernard and Hauptmann, Alexander
	G and Ngo, Chong-Wah and Andreopoulos, Yiannis and Breiteneder, Christian},
  volume = {7131},
  series = {Lecture Notes in Computer Science},
  pages = {671--681},
  address = {Berlin, Heidelberg},
  keywords = {litsurvey.bib}
}

@PHDTHESIS{Wen2013,
  author = {Wen, Jian},
  title = {Revisiting aggregation techniques for data intensive applications},
  school = {UC Riverside},
  year = {2013},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Revisiting Aggregation Techniques for Data Int.pdf:PDF}
}

@ARTICLE{Werkhoven2001,
  author = {Werkhoven, Peter J and Schraagen, Jan Maarten and Punte, Patrick
	A J},
  title = {Seeing is believing: communication performance under isotropic teleconferencing
	conditions},
  journal = {Displays},
  year = {2001},
  volume = {22},
  pages = {137--149},
  number = {4},
  month = {\#sep\#},
  abstract = {The visual component of conversational media such as videoconferencing
	systems communicates important non-verbal information such as facial
	expressions, gestures, posture and gaze. Unlike the other cues, selective
	gaze depends critically on the configuration of cameras and monitors.
	Under isotropic videoconferencing conditions people see each other
	in spatially consistent directions (shared video space). Isotropy
	is hypothesized to regulate the interactional process of conversation.
	Further, it is hypothesized that isotropy increases social nearness
	which increases persuasive force but decreases the exchange of information
	in group discussion tasks. We have studied the interactional process
	and task outcome of two discussion tasks under isotropic and (standard)
	non-isotropic videoconferencing conditions relative to face-to-face
	conditions. The communication of unshared information was tested
	in a `hidden profile' task by Stasser et al.[Journal of Experimental
	Social Psychology 31 (1995) 244]. Dominance and persuasive force
	were revealed using a prioritization game of survival items called
	`Lost at the moon', featuring a dominant confederate. The results
	support our hypotheses and have revealed that persuasive force (the
	ability to change another person's opinion) is significantly stronger
	under isotropic conditions (including face-to-face) than under non-isotropic
	conditions. In contrast, dominance (the ability to influence group
	solutions by dominant behavior) is similar for all conditions. Further,
	participants communicate almost twice as much unshared information
	under mediated conditions than under the face-to-face condition.},
  keywords = {Videoconferencing; Shared video space; Communication performance;
	Persuasive force; Information sharing;litsurvey.bib},
  publisher = {Elsevier}
}

@ARTICLE{Werner2016,
  author = {Werner, Richard A},
  title = {A lost century in economics: Three theories of banking and the conclusive
	evidence},
  journal = {International Review of Financial Analysis},
  year = {2016},
  volume = {46},
  pages = {361--379},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/1-s2.0-S1057521915001477-main.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Wheeler2018,
  author = {Wheeler, Gavin and Deng, Shujie and Toussaint, Nicolas and Pushparajah,
	Kuberan and Schnabel, Julia A and Simpson, John M and Gomez, Alberto},
  title = {Virtual interaction and visualisation of 3D medical imaging data
	with VTK and Unity},
  journal = {Healthcare technology letters},
  year = {2018},
  volume = {5},
  pages = {148--153},
  number = {5},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/volumeMedical/HTL.2018.5064.pdf:PDF},
  publisher = {IET}
}

@ARTICLE{Williams1977,
  author = {Williams, Ederyn},
  title = {Experimental comparisons of face-to-face and mediated communication:
	A review},
  journal = {Psychol. Bull.},
  year = {1977},
  volume = {84},
  pages = {963},
  number = {5},
  keywords = {litsurvey.bib},
  publisher = {American Psychological Association}
}

@INPROCEEDINGS{Wilson2012,
  author = {Wilson, Andrew and Benko, Hrvoje and Izadi, Shahram and Hilliges,
	Otmar},
  title = {Steerable augmented reality with the beamatron},
  booktitle = {Proceedings of the 25th annual {ACM} symposium on User interface
	software and technology},
  year = {2012},
  series = {UIST '12},
  pages = {413--422},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {steerable displays, ubiquitous computing, augmented reality, depth
	cameras;litsurvey.bib},
  location = {Cambridge, Massachusetts, USA}
}

@INPROCEEDINGS{Wilson2000,
  author = {Wilson, Hugh R and Wilkinson, Frances and Lin, Li-Ming and Castillo,
	Maja},
  title = {Perception of head orientation},
  year = {2000},
  volume = {40},
  pages = {459--472},
  publisher = {Elsevier},
  keywords = {litsurvey.bib}
}

@ARTICLE{Wolff2014,
  author = {Wolff, Robin and Preusche, Carsten and Gerndt, Andreas},
  title = {A modular architecture for an interactive real-time simulation and
	training environment for satellite on-orbit servicing},
  journal = {Journal of Simulation},
  year = {2014},
  volume = {8},
  pages = {50--63},
  number = {1},
  month = {\#feb\#},
  abstract = {AbstractMaintaining or repairing satellites in orbit is a delicate
	task that requires expert skills. The planning, training and analysis
	of on-orbit servicing (OOS) missions performed by astronauts or through
	remote operation using a robot is often time consuming and costly.
	Virtual Reality (VR) enables simulation and training in a flexible
	and safe environment. This paper describes an interactive real-time
	environment that supports a number of OOS tasks within an immersive
	VR environment. The system simulates the dynamic and kinematic behaviour
	of satellite components and provides photo-realistic visualization
	of satellite parts and the space environment. It integrates user
	interaction with haptic force feedback through a bi-manual haptic
	human machine interface, as well as simulates and interfaces to a
	humanoid robot for tele-operation.In order to provide a realistic
	experience at interactive frame rates, we propose a distributed system
	architecture, where the load of computing the physics simulation,
	haptic feedback and visualization of the complex scene is transferred
	to dedicated machines. The modular architecture is designed to allow
	the inclusion of further simulation processes. Several mechanisms
	for reducing the communication traffic have been implemented. This
	paper gives an overview of the system architecture, outlines the
	software implementation and documents an evaluation of the real-time
	performance of our system in detail. We describe how system performance
	was measured in terms of simulation timings and distribution load,
	as well as report on latencies at several stages. Results show that
	our distributed system is capable of providing visual and haptic
	feedback at high frame rates required for user interaction with end-to-end
	latencies of less than 8?ms and 3?ms, respectively.},
  keywords = {litsurvey.bib},
  publisher = {Taylor \& Francis}
}

@InProceedings{Wolff2008,
  author    = {Wolff, R and Roberts, D and Murgia, A and Murray, N and Rae, J and Steptoe, W and Steed, A and Sharkey, P},
  booktitle = {2008 12th {IEEE/ACM} International Symposium on Distributed Simulation and {Real-Time} Applications},
  title     = {Communicating Eye Gaze across a Distance without Rooting Participants to the Spot},
  year      = {2008},
  month     = {\#oct\#},
  pages     = {111--118},
  publisher = {Ieee},
  abstract  = {Eye gaze is an important conversational resource that until now could
	only be supported across a distance if people were rooted to the
	spot. We introduce EyeCVE, the worldpsilas first tele-presence system
	that allows people in different physical locations to not only see
	what each other are doing but follow each otherpsilas eyes, even
	when walking about. Projected into each space are avatar representations
	of remote participants, that reproduce not only body, head and hand
	movements, but also those of the eyes. Spatial and temporal alignment
	of remote spaces allows the focus of gaze as well as activity and
	gesture to be used as a resource for non-verbal communication. The
	temporal challenge met was to reproduce eye movements quick enough
	and often enough to interpret their focus during a multi-way interaction,
	along with communicating other verbal and non-verbal language. The
	spatial challenge met was to maintain communicational eye gaze while
	allowing free movement of participants within a virtually shared
	common frame of reference. This paper reports on the technical and
	especially temporal characteristics of the system.},
  keywords  = {biology computing;eye;virtual reality;eye gaze;EyeCVE;tele-presence system;avatar representations;nonverbal communication;physical locations;eye movements;Cameras;Videoconference;Avatars;Video sharing;Virtual environment;Humans;Eyes;Head;Focusing;Displays;litsurvey.bib},
}

@INPROCEEDINGS{Wollaston1824,
  author = {Wollaston, William Hyde},
  title = {On the apparent direction of eyes in a portrait},
  year = {1824},
  pages = {247--256},
  publisher = {JSTOR},
  keywords = {litsurvey.bib}
}

@ARTICLE{wonglimpiyarat2016s,
  author = {Wonglimpiyarat, Jarunee},
  title = {S-curve trajectories of electronic money innovations},
  journal = {The Journal of High Technology Management Research},
  year = {2016},
  volume = {27},
  pages = {1--9},
  number = {1},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Wu2003,
  author = {Wu, T and Matsuyama, T},
  title = {Real-time active 3d shape reconstruction for 3d video},
  booktitle = {Image and Signal Processing and Analysis, 2003. {ISPA} 2003. Proceedings
	of the 3\textbackslashtextsuperscript{rd} International Symposium
	on},
  year = {2003},
  volume = {1},
  pages = {186--191},
  institution = {IEEE},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Xiaojun_Wu2006,
  author = {{Xiaojun Wu} and Takizawa, O and Matsuyama, T},
  title = {{Parallel Pipeline Volume Intersection for {Real-Time} {3D} Shape
	Reconstruction on a {PC} Cluster}},
  booktitle = {Fourth {IEEE} International Conference on Computer Vision Systems
	({ICVS'06})},
  year = {2006},
  pages = {4--4},
  address = {New York},
  month = {\#jan\#},
  abstract = {The human activity monitoring is one of the major tasks in the field
	of computer vision. Recently, not only the 2D images but also 3D
	shapes of a moving person are desired in kinds of cases, such as
	motion analysis, security monitoring, 3D video creation and so on.
	In this paper, we propose a parallel pipeline system on a PC cluster
	for reconstructing the 3D shape of a moving person in real-time.
	For the 3D shape reconstruction, we have extended the volume intersection
	method to the 3-base-plane volume intersection. By thus extension,
	the computation is accelerated greatly for arbitrary camera layouts.
	We also parallelized the 3-base-plane method and implemented it on
	a PC cluster. On each node, the pipeline processing is adopted to
	improve the throughput. To decrease the CPU idle time caused by I/O
	processing, image capturing, communications over nodes and so on,
	we implement the pipeline using multiple threads. So that, all stages
	can be executed concurrently. However, there exists resource conflicts
	between stages in a real system. To avoid the conflicts while keeping
	high percentage of CPU running time, we propose a tree structured
	thread control model. As a result, We achieve the performance as
	obtaining the full 3D volumes of a moving person at about 12 frames
	per second, where the voxel size is 5$\times$5$\times$5 [mm^3]. The
	effectiveness of the thread tree model in such real-time computation
	is also proved by the experimental results.},
  keywords = {Shape;Pipeline processing;Image reconstruction;Yarn;Computerized monitoring;Humans;Computer
	vision;Motion analysis;Real time systems;Acceleration;litsurvey.bib}
}

@INPROCEEDINGS{Xu2012,
  author = {Xu, Anbang and Biehl, Jacob and Rieffel, Eleanor and Turner, Thea
	and van Melle, William},
  title = {Learning how to feel again: towards affective workplace presence
	and communication technologies},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2012},
  series = {CHI '12},
  pages = {839--848},
  address = {New York, NY, USA},
  month = {\#may\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {affect awareness, myunity, workplace communication, affect, presence,
	affect computing;litsurvey.bib},
  location = {Austin, Texas, USA}
}

@INPROCEEDINGS{Yamashita2008,
  author = {Yamashita, Naomi and Hirata, Keiji and Aoyagi, Shigemi and Kuzuoka,
	Hideaki and Harada, Yasunori},
  title = {Impact of seating positions on group video communication},
  booktitle = {Proceedings of the 2008 {ACM} conference on Computer supported cooperative
	work},
  year = {2008},
  series = {CSCW '08},
  pages = {177--186},
  address = {New York, NY, USA},
  month = {\#nov\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {empirical study, group-to-group meeting, computer-supported cooperative
	work, conversational analysis, seating position, video-mediated communication;litsurvey.bib},
  location = {San Diego, CA, USA}
}

@INPROCEEDINGS{Yang2016,
  author = {Yang, Tingting and Jia, Shuwen},
  title = {Research on Network Security Visualization under Big Data Environment},
  booktitle = {2016 International Computer Symposium (ICS)},
  year = {2016},
  pages = {660--662},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07858557.pdf:PDF}
}

@ARTICLE{Yang2018,
  author = {Yang, Yalong and Dwyer, Tim and Jenny, Bernhard and Marriott, Kim
	and Cordeil, Maxime and Chen, Haohui},
  title = {Origin-destination flow maps in immersive environments},
  journal = {IEEE transactions on visualization and computer graphics},
  year = {2018},
  volume = {25},
  pages = {693--703},
  number = {1},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440844.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Yee2007,
  author = {Yee, Nick and Bailenson, Jeremy N and Rickertsen, Kathryn},
  title = {A meta-analysis of the impact of the inclusion and realism of human-like
	faces on user experiences in interfaces},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {1--10},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {computer-mediated communication, embodied agents, meta-analysis, quantitative
	methods, realism;litsurvey.bib},
  location = {San Jose, California, USA}
}

@InProceedings{Yee2007,
  author   = {Yee, Nick and Bailenson, Jeremy N and Urbanek, Mark and Chang, Francis and Merget, Dan},
  title    = {The unbearable likeness of being digital: the persistence of nonverbal social norms in online virtual environments},
  year     = {2007},
  pages    = {115--121},
  volume   = {10},
  abstract = {Every day, millions of users interact in real-time via avatars in
	online environments, such as massively-multiplayer online role-playing
	games (MMORPGs). These online environments could potentially be unique
	research platforms for the social sciences and clinical therapy,
	but it is crucial to first establish that social behavior and norms
	in virtual environments are comparable to those in the physical world.
	In an observational study of Second Life, a virtual community, we
	collected data from avatars in order to explore whether social norms
	of gender, interpersonal distance (IPD), and eye gaze transfer into
	virtual environments even though the modality of movement is entirely
	different (i.e., via keyboard and mouse as opposed to eyes and legs).
	Our results showed that established findings of IPD and eye gaze
	transfer into virtual environments: (1) male-male dyads have larger
	IPDs than female-female dyads, (2) male-male dyads maintain less
	eye contact than female-female dyads, and (3) decreases in IPD are
	compensated with gaze avoidance as predicted by the Equilibrium Theory.
	We discuss implications for users of online games as well as for
	social scientists who seek to conduct research in virtual environments.},
  keywords = {Adult, Female, Humans, Internet, Internet: statistics \& numerical data, Male, Nonverbal Communication, Social Behavior, Social Distance, User-Computer Interface;litsurvey.bib},
}

@ARTICLE{Yendo2010,
  author = {Yendo, Tomohiro and Fujii, Toshiaki and Tanimoto, Masayuki and Panahpour
	Tehrani, Mehrdad},
  title = {The Seelinder: Cylindrical {3D} display viewable from 360 degrees},
  journal = {J. Vis. Commun. Image Represent.},
  year = {2010},
  volume = {21},
  pages = {586--594},
  number = {5},
  month = {\#jul\#},
  abstract = {We propose a 3D video display technique that allows multiple viewers
	to see 3D images from a 360-degree horizontal arc without wearing
	3D glasses. This technique uses a cylindrical parallax barrier and
	a one-dimensional light source array. We have developed an experimental
	display system using this technique. Since this technique is based
	on the parallax panoramagram, the parallax number and resolution
	are limited by the diffraction at the parallax barrier. In order
	to solve this problem, we improved the technique by revolving the
	parallax barrier. The improved technique was incorporated into two
	experimental display systems. The newer one is capable of displaying
	3D color video images within a 200-mm diameter and a 256-mm height.
	Images have a resolution of 1254 circumferential pixels and 256 vertical
	pixels, and are refreshed at 30Hz. Each pixel has a viewing angle
	of 60 degrees that is divided into over 70 views so that the angular
	parallax interval of each pixel is less than 1 degree. These pixels
	are arranged on a cylindrical surface to allow for the produced 3D
	images to be observed from all directions. In this case, observers
	may barely perceive the discrete parallax.},
  keywords = {Autostereoscopic display; Multi-view; Omnidirectional; Ray-space;
	Light field; Parallax barrier;litsurvey.bib},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Yoo2018,
  author = {Yoo, Soojeong and Parker, Callum and Kay, Judy},
  title = {Adapting Data from Physical Activity Sensors for Visualising Exertion
	in Virtual Reality Games},
  booktitle = {Proceedings of the 2018 ACM International Joint Conference and 2018
	International Symposium on Pervasive and Ubiquitous Computing and
	Wearable Computers},
  year = {2018},
  pages = {307--310},
  organization = {ACM},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/p307-Yoo.pdf:PDF}
}

@MISC{Yougov2020,
  author = {{Yougov}},
  title = {Yougov poll about returning to normal},
  howpublished = {\url{https://news.sky.com/story/coronavirus-only-9-of-britons-want-life-to-return-to-normal-once-lockdown-is-over-11974459}},
  year = {2020},
  keywords = {litsurvey.bib}
}

@ARTICLE{Young2006,
  author = {Young, Allan},
  title = {Remembering the evolutionary Freud},
  journal = {Sci. Context},
  year = {2006},
  volume = {19},
  pages = {175--189},
  number = {1},
  month = {\#mar\#},
  abstract = {Throughout his career as a writer, Sigmund Freud maintained an interest
	in the evolutionary origins of the human mind and its neurotic and
	psychotic disorders. In common with many writers then and now, he
	believed that the evolutionary past is conserved in the mind and
	the brain. Today the ``evolutionary Freud'' is nearly forgotten.
	Even among Freudians, he is regarded to be a red herring, relevant
	only to the extent that he diverts attention from the enduring achievements
	of the authentic Freud. There are three ways to explain these attitudes.
	First, the evolutionary Freud's key work is the ``Overview of the
	Transference Neurosis'' (1915). But it was published at an inopportune
	moment, forty years after the author's death, during the so-called
	``Freud wars.'' Second, Freud eventually lost interest in the ``Overview''
	and the prospect of a comprehensive evolutionary theory of psychopathology.
	The publication of The Ego and the Id (1923), introducing Freud's
	structural theory of the psyche, marked the point of no return. Finally,
	Freud's evolutionary theory is simply not credible. It is based on
	just-so stories and a thoroughly discredited evolutionary mechanism,
	Lamarckian use-inheritance. Explanations one and two are probably
	correct but also uninteresting. Explanation number three assumes
	that there is a fundamental difference between Freud's evolutionary
	narratives (not credible) and the evolutionary accounts of psychopathology
	that currently circulate in psychiatry and mainstream journals (credible).
	The assumption is mistaken but worth investigating.},
  keywords = {litsurvey.bib},
  language = {en}
}

@ARTICLE{Zagarskikh2015,
  author = {Zagarskikh, Aleksandr and Karsakov, Andrey and Bezgodov, Alexey},
  title = {Efficient Visualization of Urban Simulation Data Using Modern GPUs},
  journal = {Procedia Computer Science},
  year = {2015},
  volume = {51},
  pages = {2928--2932},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/82249012.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Zajonc1980,
  author = {Zajonc, Robert B},
  title = {Feeling and thinking: Preferences need no inferences},
  journal = {Am. Psychol.},
  year = {1980},
  volume = {35},
  pages = {151},
  number = {2},
  keywords = {litsurvey.bib},
  publisher = {American Psychological Association}
}

@ARTICLE{Zajonc1980,
  author = {Zajonc, Robert B},
  title = {Feeling and thinking: Preferences need no inferences},
  journal = {Am. Psychol.},
  year = {1980},
  volume = {35},
  pages = {151},
  number = {2},
  keywords = {litsurvey.bib},
  publisher = {American Psychological Association}
}

@INPROCEEDINGS{Zanbaka2007,
  author = {Zanbaka, Catherine Amine and Ulinski, Amy Catherine and Goolkasian,
	Paula and Hodges, Larry F},
  title = {Social responses to virtual humans: implications for future interface
	design},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2007},
  series = {CHI '07},
  pages = {1561--1570},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {virtual humans, experimental studies, interface agents, human-computer
	interaction, social facilitation and inhibition, social influence,
	avatars, social psychology;litsurvey.bib},
  location = {San Jose, California, USA}
}

@INPROCEEDINGS{zeng2019data,
  author = {Zeng, Yu-Ren and Chang, Yue Shan and Fang, You Hao},
  title = {Data Visualization for Air Quality Analysis on Bigdata Platform},
  booktitle = {2019 International Conference on System Science and Engineering (ICSSE)},
  year = {2019},
  pages = {313--317},
  organization = {IEEE},
  file = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08823437.pdf:PDF}
}

@INPROCEEDINGS{Zhang_Shujun2009,
  author = {{Zhang Shujun} and {Wang Cong} and {Shao Xuqiang} and {Wu Wei}},
  title = {{{DreamWorld}: {{CUDA}-accelerated} real-time {3D} modeling system}},
  booktitle = {2009 {IEEE} International Conference on Virtual Environments, {Human-Computer}
	Interfaces and Measurements Systems},
  year = {2009},
  pages = {168--173},
  address = {Hong Kong},
  month = {\#may\#},
  abstract = {3D modeling plays an important role in virtual reality interaction,
	immersive tele-presence and other applications. A CUDA-accelerated
	real-time 3D modeling system is presented in this paper. It captures
	multi-view images of objects and achieves real-time accurate visual
	hull reconstruction with texture mapping. The system includes off-line
	camera calibration and on-line visual hull modeling based on our
	DreamWorld hardware. The multi-camera based modeling process is composed
	of distributed image acquisition, silhouette extraction, data transmission,
	visual hull computation and rendering. Initially, the volumetric
	visual hull is computed through intersection test of voxels with
	each silhouette and then, a CUDA-based simplified exact marching
	cubes algorithm is put forward to get a polyhedral mesh model for
	texture mapping and rendering. Preliminary experimental results from
	both synthetic and real data show its accuracy, stability and real-time
	performance.},
  keywords = {calibration;cameras;computational geometry;image reconstruction;image
	texture;real-time systems;rendering (computer graphics);solid modelling;virtual
	reality;CUDA-accelerated real-time 3D modeling system;DreamWorld
	hardware;virtual reality interaction;immersive tele-presence;multiview
	object image;accurate visual hull reconstruction;texture mapping;offline
	camera calibration;online visual hull modeling;distributed image
	acquisition;silhouette extraction;data transmission;visual hull computation;rendering;volumetric
	visual hull;marching cube algorithm;Real time systems;Rendering (computer
	graphics);Virtual reality;Image reconstruction;Cameras;Calibration;Hardware;Data
	mining;Data communication;Distributed computing;3D modeling;visual
	hull;CUDA;marching cubes;litsurvey.bib}
}

@ARTICLE{Zhang2007,
  author = {Zhang, Hui and Wong, Kwan-Yee K and Zhang, Guoqiang},
  title = {Camera calibration from images of spheres},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2007},
  volume = {29},
  pages = {499--503},
  number = {3},
  month = {\#mar\#},
  abstract = {This paper introduces a novel approach for solving the problem of
	camera calibration from spheres. By exploiting the relationship between
	the dual images of spheres and the dual image of the absolute conic
	(IAC), it is shown that the common pole and polar with regard to
	the conic images of two spheres are also the pole and polar with
	regard to the IAC. This provides two constraints for estimating the
	IAC and, hence, allows a camera to be calibrated from an image of
	at least three spheres. Experimental results show the feasibility
	of the proposed approach.},
  keywords = {litsurvey.bib},
  language = {en}
}

@ARTICLE{Zhang2008,
  author = {Zhang, Song and Yau, Shing-Tung},
  title = {{Three-dimensional shape measurement using a structured light system
	with dual cameras}},
  journal = {Organ. Ethic.},
  year = {2008},
  volume = {47},
  pages = {013604},
  number = {1},
  month = {\#jan\#},
  abstract = {A structured light system for three-dimensional shape measurement
	with single camera has the shortcoming of camera occlusion. To alleviate
	this problem, this paper introduces a structured light system with
	dual cameras for three-dimensional shape measurement. We discuss
	(1) system description, (2) system calibration, (3) three-dimensional
	data registration using the iterative closest-point (ICP) algorithm,
	and (4) three-dimensional data merging using holoimage. The principle
	of the system is introduced, and experiments are presented to verify
	its performance.},
  keywords = {calibration; structured light; dual cameras; holoimage; registration;
	phase shifting; merging; Cameras; Imaging systems; Calibration; Projection
	systems; 3D image processing; 3D metrology; Structured light; 3D
	modeling; Optical engineering; Nose; ; ; ; ; ; ; ; ; ; ; ;litsurvey.bib},
  publisher = {International Society for Optics and Photonics}
}

@INPROCEEDINGS{Zhang2010,
  author = {Zhang, Xinyong and Ren, Xiangshi and Zha, Hongbin},
  title = {Modeling dwell-based eye pointing target acquisition},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2010},
  series = {CHI '10},
  pages = {2083--2092},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  keywords = {information theory, modeling, eye pointing, fitts' law;litsurvey.bib},
  location = {Atlanta, Georgia, USA}
}

@INPROCEEDINGS{Zhang2013,
  author = {Zhang, Yanxia and Bulling, Andreas and Gellersen, Hans},
  title = {{SideWays}: a gaze interface for spontaneous interaction with situated
	displays},
  booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing
	Systems},
  year = {2013},
  series = {CHI '13},
  pages = {851--860},
  address = {New York, NY, USA},
  month = {\#apr\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {spontaneous interaction, eye tracking, calibration-free, eye-based
	interaction, situated display;litsurvey.bib},
  location = {Paris, France}
}

@ARTICLE{Zhang2004,
  author = {Zhang, Zhengyou},
  title = {{Camera calibration with one-dimensional objects}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2004},
  volume = {26},
  pages = {892--899},
  number = {7},
  month = {\#jul\#},
  abstract = {Camera calibration has been studied extensively in computer vision
	and photogrammetry and the proposed techniques in the literature
	include those using 3D apparatus (two or three planes orthogonal
	to each other or a plane undergoing a pure translation, etc.), 2D
	objects (planar patterns undergoing unknown motions), and 0D features
	(self-calibration using unknown scene points). Yet, this paper proposes
	a new calibration technique using 1D objects (points aligned on a
	line), thus filling the missing dimension in calibration. In particular,
	we show that camera calibration is not possible with free-moving
	1D objects, but can be solved if one point is fixed. A closed-form
	solution is developed if six or more observations of such a 1D object
	are made. For higher accuracy, a nonlinear technique based on the
	maximum likelihood criterion is then used to refine the estimate.
	Singularities have also been studied. Besides the theoretical aspect,
	the proposed technique is also important in practice especially when
	calibrating multiple cameras mounted apart from each other, where
	the calibration objects are required to be visible simultaneously.},
  keywords = {litsurvey.bib},
  language = {en}
}

@INCOLLECTION{Zhao2011,
  author = {Zhao, Yong and Taubin, Gabriel},
  title = {Chapter 31 - {Real-Time} Stereo on {GPGPU} Using Progressive Multiresolution
	Adaptive Windows},
  booktitle = {{GPU} Computing Gems Emerald Edition},
  publisher = {Morgan Kaufmann},
  year = {2011},
  editor = {Hwu, Wen-Mei W},
  volume = {29},
  pages = {473--495},
  address = {Boston},
  month = {\#jan\#},
  abstract = {Publisher Summary This chapter presents a new GPGPU-based real-time
	dense stereo-matching algorithm. The algorithm is based on a progressive
	multiresolution pipeline that includes background modeling and dense
	matching with adaptive windows. For applications in which only moving
	objects are of interest, this approach effectively reduces the overall
	computation cost quite significantly and preserves the high definition
	details. Estimating depth from stereo is a classic computer vision
	problem, which has received tremendous attention since the early
	days. Recovering 3D information from a pair of stereo cameras has
	been a popular topic because the additional 3D information provided
	by this technology contains significantly more information than 2D
	information produced by traditional cameras. Some believe that this
	technology will fundamentally revolutionize the computer vision signal-processing
	pipeline, as well as how future cameras will be built. The current
	implementation achieves 36 Hz stereo matching on 1024 $\times$ 768
	stereo video with a fine 256-pixel disparity range. The focus of
	this work is to provide efficient high-resolution stereo algorithms
	for real-time applications in which only foreground moving objects
	are of interest, such as motion capture, object tracking, and recognition
	and identification in a surveillance scenario.},
  keywords = {litsurvey.bib}
}

@INPROCEEDINGS{Zillner2014,
  author = {Zillner, Jakob and Rhemann, Christoph and Izadi, Shahram and Haller,
	Michael},
  title = {3D-board: a whole-body remote collaborative whiteboard},
  booktitle = {Proceedings of the 27th annual {ACM} symposium on User interface
	software and technology},
  year = {2014},
  series = {UIST '14},
  pages = {471--479},
  address = {New York, NY, USA},
  month = {\#oct\#},
  publisher = {Association for Computing Machinery},
  institution = {ACM},
  keywords = {interactive whiteboard, reconstruction, remote collaboration, shared
	workspace, teleconferencing;litsurvey.bib},
  location = {Honolulu, Hawaii, USA}
}

@ARTICLE{zong2020interactive,
  author = {Zong, Wei and Chow, Yang-Wai and Susilo, Willy},
  title = {Interactive three-dimensional visualization of network intrusion
	detection data for machine learning},
  journal = {Future Generation Computer Systems},
  year = {2020},
  volume = {102},
  pages = {292--306},
  file = {:../../../literature_repository/Data Visualisation/1-s2.0-S0167739X18331091-main.pdf:PDF},
  publisher = {Elsevier}
}

@MISC{Zoom2020,
  author = {{Zoom}},
  title = {Zoom daily {200M} users message},
  howpublished = {\url{https://blog.zoom.us/wordpress/2020/04/01/a-message-to-our-users/}},
  year = {2020},
  keywords = {litsurvey.bib}
}

@ELECTRONIC{a,
  owner = {its352},
  timestamp = {2021.12.02}
}

@MISC{bitcoinMarketCap,
  title = {The market capitalisation of the bitcoin network compared to global
	nation state currencies},
  howpublished = {\url{https://fiatmarketcap.com/}},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@MISC{bitcoinScalability,
  title = {The Bitcoin Scalability Problem Wikipedia page},
  howpublished = {\url{https://en.wikipedia.org/wiki/Bitcoin_scalability_problem}},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@MISC{compareConfirmations,
  title = {Relative Security: Comparing equivalent conformation strength across
	different distributed ledger technologies},
  howpublished = {\url{https://howmanyconfs.com/}},
  note = {Accessed: 2021-02-10}
}

@MISC{etherWhitepaper,
  title = {Ethereum whitepaper},
  howpublished = {\url{https://ethereum.org/en/whitepaper/}},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@MISC{lightningWhitepaper,
  title = {The Bitcoin Lightning Network whitepaper pdf},
  howpublished = {\url{http://lightning.network/lightning-network-paper.pdf}},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@BOOK{noauthor_undated,
  keywords = {litsurvey.bib}
}

@MISC{RGBFAQ,
  title = {The RGB FAQ},
  howpublished = {\url{https://rgbfaq.com/}},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@MISC{whatIsBlockchain,
  title = {Investopedia description of blockchain},
  howpublished = {\url{https://www.investopedia.com/terms/b/blockchain.asp}},
  note = {Accessed: 2021-02-10},
  owner = {its352},
  timestamp = {2021.02.10}
}

@MISC{noauthor_2015,
  title = {Ericsson Mobility Report},
  howpublished = {\url{http://www.ericsson.com/res/docs/2015/mobility-report/ericsson-mobility-report-nov-2015.pdf}},
  year = {2015},
  keywords = {litsurvey.bib}
}

@ARTICLE{Allard2007,
  author = {Allard, J{\'e}r{\'e}mie and Menier, Cl{\'e}ment and Raffin, Bruno
	and Boyer, Edmond and Faure, Fran{\c c}ois},
  title = {{Grimage: markerless {3D} interactions}},
  journal = {Proceedings of the 34\textbackslashtextsuperscriptth annual conference
	on Computer Graphics and Interactive Techniques (SIGGRAPH '07)},
  year = {2007},
  keywords = {litsurvey.bib}
}

@Article{maurel2012keynesian,
  author    = {Maurel, Mathilde and Schnabl, Gunther},
  journal   = {Open Economies Review},
  title     = {Keynesian and Austrian perspectives on crisis, shock adjustment, exchange rate regime and (long-term) growth},
  year      = {2012},
  number    = {5},
  pages     = {847--868},
  volume    = {23},
  publisher = {Springer},
}

@InProceedings{ford2005peer,
  author    = {Ford, Bryan and Srisuresh, Pyda and Kegel, Dan},
  booktitle = {USENIX Annual Technical Conference, General Track},
  title     = {Peer-to-Peer Communication Across Network Address Translators.},
  year      = {2005},
  pages     = {179--192},
}

@Article{karaarslan2018blockchain,
  author    = {Karaarslan, Enis and Adiguzel, Eylul},
  journal   = {IEEE Communications Standards Magazine},
  title     = {Blockchain based DNS and PKI solutions},
  year      = {2018},
  number    = {3},
  pages     = {52--57},
  volume    = {2},
  publisher = {IEEE},
}

@Article{benetton2021cryptomining,
  author  = {Benetton, Matteo and Compiani, Giovanni and Morse, Adair},
  journal = {Available at SSRN 3779720},
  title   = {When Cryptomining Comes to Town: High Electricity-Use Spillovers to the Local Economy},
  year    = {2021},
}

@InProceedings{haber1990time,
  author       = {Haber, Stuart and Stornetta, W Scott},
  booktitle    = {Conference on the Theory and Application of Cryptography},
  title        = {How to time-stamp a digital document},
  year         = {1990},
  organization = {Springer},
  pages        = {437--455},
}

@Article{sant2009performance,
  author    = {Sant, Toni},
  journal   = {Learning and teaching in the virtual world of Second Life},
  title     = {Performance in Second Life: some possibilities for learning and teaching},
  year      = {2009},
  pages     = {145--166},
  publisher = {Trondheim, Norway: Tapir Academic Press},
}

@InProceedings{kemp2006putting,
  author       = {Kemp, Jeremy and Livingstone, Daniel},
  booktitle    = {Proceedings of the Second Life education workshop at the Second Life community convention},
  title        = {Putting a Second Life metaverse skin on learning management systems},
  year         = {2006},
  organization = {The University of Paisley CA, San Francisco},
  volume       = {20},
}

@Article{sermon2008they,
  author = {Sermon, Paul and others},
  title  = {They live (in Second Life)},
  year   = {2008},
}

@Article{marlatt2020capitalizing,
  author    = {Marlatt, Rick},
  journal   = {Journal of Education},
  title     = {Capitalizing on the craze of fortnite: Toward a conceptual framework for understanding how gamers construct communities of practice},
  year      = {2020},
  number    = {1},
  pages     = {3--11},
  volume    = {200},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
}

@Article{kirriemuir2008spring,
  author  = {Kirriemuir, John},
  journal = {Eduserv Virtual World Watch},
  title   = {A Spring 2008 snapshot of UK higher and further education developments in Second Life},
  year    = {2008},
  pages   = {58},
}

@Article{snowcrash1992,
  author  = {Stephenson, Neal},
  journal = {Spectra Books},
  title   = {Snow Crash},
  year    = {1992},
}

@Article{mclellan1993avatars,
  author    = {McLellan, Hilary},
  title     = {Avatars, Affordances, and Interfaces: Virtual Reality Tools for Learning.},
  year      = {1993},
  publisher = {ERIC},
}

@Article{baur2021bitcoin,
  author    = {Baur, Dirk G and Oll, Josua},
  journal   = {Finance Research Letters},
  title     = {Bitcoin investments and climate change: a financial and carbon intensity perspective},
  year      = {2021},
  pages     = {102575},
  publisher = {Elsevier},
}

@TechReport{makarov2021blockchain,
  author      = {Makarov, Igor and Schoar, Antoinette},
  institution = {National Bureau of Economic Research},
  title       = {Blockchain Analysis of the Bitcoin Market},
  year        = {2021},
}

@Article{golumbia2020cryptocurrency,
  author  = {Golumbia, David},
  journal = {So Is Blockchain.(June 16, 2020)},
  title   = {Cryptocurrency Is Garbage. So Is Blockchain.},
  year    = {2020},
}

@Article{zabka2022short,
  author = {Zabka, Philipp and Foerster, Klaus-Tycho and Decker, Christian and Schmid, Stefan},
  title  = {Short Paper: A Centrality Analysis of the Lightning Network},
  year   = {2022},
}

@Article{blandin20203rd,
  author  = {Blandin, Apolline and Pieters, Gina C and Wu, Yue and Dek, Anton and Eisermann, Thomas and Njoki, Damaris and Taylor, Sean},
  journal = {Available at SSRN 3700822},
  title   = {3rd global cryptoasset benchmarking study},
  year    = {2020},
}

@InProceedings{delgado2018analysis,
  author       = {Delgado-Segura, Sergi and P{\'e}rez-Sola, Cristina and Navarro-Arribas, Guillermo and Herrera-Joancomart{\'\i}, Jordi},
  booktitle    = {International Conference on Financial Cryptography and Data Security},
  title        = {Analysis of the bitcoin utxo set},
  year         = {2018},
  organization = {Springer},
  pages        = {78--91},
}

@Article{buterin2013ethereum,
  author  = {Buterin, Vitalik and others},
  journal = {GitHub repository},
  title   = {Ethereum white paper},
  year    = {2013},
  pages   = {22--23},
  volume  = {1},
}

@Misc{poon2016bitcoin,
  author = {Poon, Joseph and Dryja, Thaddeus},
  title  = {The bitcoin lightning network: Scalable off-chain instant payments},
  year   = {2016},
}

@InProceedings{croman2016scaling,
  author       = {Croman, Kyle and Decker, Christian and Eyal, Ittay and Gencer, Adem Efe and Juels, Ari and Kosba, Ahmed and Miller, Andrew and Saxena, Prateek and Shi, Elaine and Sirer, Emin G{\"u}n and others},
  booktitle    = {International conference on financial cryptography and data security},
  title        = {On scaling decentralized blockchains},
  year         = {2016},
  organization = {Springer},
  pages        = {106--125},
}

@Article{rauchs2018distributed,
  author  = {Rauchs, Michel and Glidden, Andrew and Gordon, Brian and Pieters, Gina C and Recanatini, Martino and Rostand, Francois and Vagneur, Kathryn and Zhang, Bryan Zheng},
  journal = {Available at SSRN 3230013},
  title   = {Distributed ledger technology systems: A conceptual framework},
  year    = {2018},
}

@Book{davies2010history,
  author    = {Davies, Glyn},
  publisher = {University of Wales Press},
  title     = {History of money},
  year      = {2010},
}

@Article{stroukal2018can,
  author    = {Stroukal, Dominik and others},
  journal   = {International Journal of Business and Management},
  title     = {Can Bitcoin become money? Its money functions and the regression theorem},
  year      = {2018},
  number    = {1},
  pages     = {36--53},
  volume    = {6},
  publisher = {International Institute of Social and Economic Sciences},
}

@Article{gainsford2017salt,
  author  = {Gainsford, Peter},
  journal = {Kiwi Hellenist: Modern Myths about the Ancient World. Retrieved},
  title   = {Salt and salary: were Roman soldiers paid in salt?},
  year    = {2017},
  volume  = {11},
}

@Article{goldberg2005famous,
  author    = {Goldberg, Dror},
  journal   = {Journal of Money, Credit and Banking},
  title     = {Famous myths of" fiat money"},
  year      = {2005},
  pages     = {957--967},
  publisher = {JSTOR},
}

@Article{krawisz2014hyperbitcoinization,
  author  = {Krawisz, Daniel},
  journal = {Online verf{\"u}gbar unter: https://nakamotoin},
  title   = {Hyperbitcoinization},
  year    = {2014},
}

@Article{filardo2012central,
  author  = {Filardo, Andrew J and Mohanty, Madhusudan S and Moreno, Ramon},
  journal = {BIS Paper},
  title   = {Central bank and government debt management: issues for monetary policy},
  year    = {2012},
  number  = {67d},
}

@Article{bordo1983some,
  author    = {Bordo, Michael David},
  journal   = {Journal of Monetary Economics},
  title     = {Some aspects of the monetary economics of Richard Cantillon},
  year      = {1983},
  number    = {2},
  pages     = {235--258},
  volume    = {12},
  publisher = {Elsevier},
}

@Book{cantillon1756essai,
  author    = {Cantillon, Richard},
  publisher = {{\'e}diteur non identifi{\'e}},
  title     = {Essai sur la nature du commerce en g{\'e}n{\'e}ral},
  year      = {1756},
}

@Book{prasad2021future,
  author    = {Prasad, Eswar S},
  publisher = {Harvard University Press},
  title     = {The Future of Money: How the Digital Revolution is Transforming Currencies and Finance},
  year      = {2021},
}

@Article{liu2022empirical,
  author  = {Liu, Yulin and Lu, Yuxuan and Nayak, Kartik and Zhang, Fan and Zhang, Luyao and Zhao, Yinhong},
  journal = {arXiv preprint arXiv:2201.05574},
  title   = {Empirical Analysis of EIP-1559: Transaction Fees, Waiting Time, and Consensus Security},
  year    = {2022},
}

@Article{lockwood2021exploring,
  author    = {Lockwood, Mick},
  journal   = {Frontiers in Blockchain},
  title     = {Exploring value propositions to drive Self-Sovereign Identity adoption},
  year      = {2021},
  pages     = {4},
  volume    = {4},
  publisher = {Frontiers},
}

@Article{prakash2020characteristic,
  author  = {Prakash, Shiv and Joshi, Sudhanshu and Bhatia, Tanvi and Sharma, Sadhna and Samadhiya, Durgesh and Shah, Rajiv Ratn and Kaiwartya, Omprakash and Prasad, Mukesh},
  journal = {International Journal of Business Intelligence and Data Mining},
  title   = {Characteristic of enterprise collaboration system and its implementation issues in business management},
  year    = {2020},
  number  = {1},
  pages   = {49--65},
  volume  = {16},
}

@InProceedings{katagiri2007aiduti,
  author    = {Katagiri, Yasuhiro},
  booktitle = {Proceedings of the Workshop on Embodied Language Processing},
  title     = {Aiduti in Japanese multi-party design conversations},
  year      = {2007},
  pages     = {9--16},
}

@Book{griffith2021electrify,
  author    = {Griffith, Saul},
  publisher = {MIT Press},
  title     = {Electrify: An Optimist's Playbook for Our Clean Energy Future},
  year      = {2021},
}

@Article{tomlinson2003third,
  author    = {Tomlinson, Brian Roger},
  journal   = {Journal of Contemporary History},
  title     = {What Was the Third World?},
  year      = {2003},
  number    = {2},
  pages     = {307--321},
  volume    = {38},
  publisher = {Sage Publications Sage UK: London, England},
}

@TechReport{caballero2008financial,
  author      = {Caballero, Ricardo J and Farhi, Emmanuel and Gourinchas, Pierre-Olivier},
  institution = {National Bureau of Economic Research},
  title       = {Financial crash, commodity prices and global imbalances},
  year        = {2008},
}

@Book{spiro2019hidden,
  author    = {Spiro, David E},
  publisher = {Cornell University Press},
  title     = {The hidden hand of American hegemony},
  year      = {2019},
}

@Article{mathews2018china,
  author  = {Mathews, John A and Selden, Mark},
  journal = {The Asia-Pacific Journal},
  title   = {China: The emergence of the Petroyuan and the challenge to US dollar hegemony},
  year    = {2018},
  number  = {22/3},
  pages   = {1--12},
  volume  = {16},
}

@Article{huang2016understanding,
  author    = {Huang, Yiping},
  journal   = {China Economic Review},
  title     = {Understanding China's Belt \& Road initiative: motivation, framework and assessment},
  year      = {2016},
  pages     = {314--321},
  volume    = {40},
  publisher = {Elsevier},
}

@InProceedings{carlsten2016instability,
  author    = {Carlsten, Miles and Kalodner, Harry and Weinberg, S Matthew and Narayanan, Arvind},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {On the instability of bitcoin without the block reward},
  year      = {2016},
  pages     = {154--167},
}

@INPROCEEDINGS{Hager_undated,
  author = {Hager, Joseph C and Ekman, Paul},
  title = {{Long-Distance} Signals Transmission of Facial Affect},
  pages = {77--82},
  keywords = {litsurvey.bib}
}

@Other{Chen,
  abstract   = {Journal of Visualization, https://doi.org/10.1007/s12650-019-00551-y},
  author     = {Yi Chen and Zeli Guan and Rong Zhang and Xiaomin Du and Yunhai Wang},
  doi        = {10.1007/s12650-019-00551-y},
  file       = {:C\:/Users/its352/Docear/projects/Big data/literature_repository/Data Visuaisation/s12650-019-00551-y.pdf:PDF},
  keywords   = {Association relationship, Graph analysis, Visual analytics, Graph simplification, Interaction techniques},
  publishers = {Springer Berlin Heidelberg},
  title      = {A survey on visualization approaches for exploring association relationships in graph data},
}

@Article{sayeed2019assessing,
  author    = {Sayeed, Sarwar and Marco-Gisbert, Hector},
  journal   = {Applied Sciences},
  title     = {Assessing blockchain consensus and security mechanisms against the 51\% attack},
  year      = {2019},
  number    = {9},
  pages     = {1788},
  volume    = {9},
  publisher = {Multidisciplinary Digital Publishing Institute},
}

@TechReport{stoeferle2018gold,
  author      = {Stoeferle, Ronald-Peter and Valek, Mark J},
  institution = {Technical report},
  title       = {Gold and the Turning of the Monetary Tides},
  year        = {2018},
}

@Article{piffaretti2009reshaping,
  author  = {Piffaretti, Nadia},
  journal = {World Bank Policy Research Working Paper},
  title   = {Reshaping the international monetary architecture: lessons from Keynes' plan},
  year    = {2009},
  number  = {5034},
}

@InProceedings{carney2019growing,
  author    = {Carney, Mark},
  booktitle = {Remarks at the Jackson Hole Symposium},
  title     = {The growing challenges for monetary policy in the current international monetary and financial system},
  year      = {2019},
  volume    = {23},
}

@Comment{jabref-meta: databaseType:bibtex;}
